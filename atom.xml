<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>指尖の岁月</title>
  <subtitle>世间点滴，莫忘于心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-07-25T04:08:11.421Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Eternal</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>利用LSTM模型进行手写识别</title>
    <link href="http://yoursite.com/2017/07/25/RNN/"/>
    <id>http://yoursite.com/2017/07/25/RNN/</id>
    <published>2017-07-25T04:03:41.000Z</published>
    <updated>2017-07-25T04:08:11.421Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Recurrent-Neural-Netword-RNN-Using-Tensorflow"><a href="#Recurrent-Neural-Netword-RNN-Using-Tensorflow" class="headerlink" title="Recurrent Neural Netword(RNN) Using Tensorflow"></a>Recurrent Neural Netword(RNN) Using Tensorflow</h1><h1 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>MNIST database of handwritten digits. <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">Click here</a><br>Input data: Image shape(28*28)<br>Output label: 0~9 </p>
<h2 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h2><ul>
<li>Data_Size<ul>
<li><code>Input_dimension</code>: Dimension of each image</li>
<li><code>Output_dimension</code>: Dimension of predicted label</li>
<li><code>Classes</code>: The number of different outputs</li>
</ul>
</li>
<li>Model_Parameter<ul>
<li><code>Training_iter</code>: The number of iterations for training</li>
<li><code>Batch_size</code>: The length of inputeach epoch</li>
</ul>
</li>
</ul>
<h2 id="Requirement"><a href="#Requirement" class="headerlink" title="Requirement"></a>Requirement</h2><ul>
<li><code>Python 2.7</code></li>
<li><code>Tensorflow 0.12.1</code></li>
</ul>
<h1 id="Model-RNN-LSTM"><a href="#Model-RNN-LSTM" class="headerlink" title="Model(RNN + LSTM)"></a>Model(RNN + LSTM)</h1><p>We use a Recurrent Neural Network with <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">LSTM</a> Cell to implement this model.</p>
<ul>
<li>LSTM (Long Short Term Memory):</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="http://upload-images.jianshu.io/upload_images/42741-b9a16a53d58ca2b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="LSTM_MODEL" title="">
                </div>
                <div class="image-caption">LSTM_MODEL</div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://json0071.gitbooks.io/deeplearning/content/LSTM.png" alt="LSTM" title="">
                </div>
                <div class="image-caption">LSTM</div>
            </figure>
<p>LSTM Composed of three gates which called INPUT_GATE, FORGET_GATE and OUTPUT_GATE.</p>
<p>More information about how to implement LSTM Model is <a href="https://www.tensorflow.org/tutorials/recurrent" target="_blank" rel="external">here</a>.</p>
<ul>
<li><strong>Initialize Step</strong></li>
</ul>
<p>First we should initialize the placeholder and weights of our neural network.<br><code>placeholder</code>: just like the <strong>x</strong> of the function:<br>$$<br>f(x) = x^2<br>$$<br><code>weights</code>: the weight for converting input data to output label.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</div><div class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</div><div class="line"></div><div class="line">weights = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden, n_classes]))</div><div class="line">&#125;</div><div class="line">biases = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><strong>Training Step</strong></li>
</ul>
<p><strong>First</strong> we define a RNN_Model function.<br>Using linear relationship to combine the output parameters.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def RNN_Model(x, weights, biases):</div><div class="line">    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias = 1.0)</div><div class="line">    output, states = tf.nn.rnn(lstm_cell, x, dtype = tf.float32)</div><div class="line">    return tf.matmul(output[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]</div></pre></td></tr></table></figure>
<p><strong>Second</strong> we have to define the loss function and optmizer of our model.<br><code>loss fuction</code>: softmax_cross_entropy<br><code>optimizer</code>: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">prediction = RNN_Model(x, weights, biases)</div><div class="line">result = tf.nn.softmax(prediction)</div><div class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))</div><div class="line">optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)</div></pre></td></tr></table></figure>
<p><strong>Third</strong> in order to evaluate the efficiency of this model, we define the function to calculate accuracy.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> we can start training after all the initialization.</p>
<ul>
<li>We can use session to run our tensorflow function.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    sess.run(init)</div><div class="line">    while &quot;./epoch&quot; &lt; training_iters</div><div class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">        batch_x = batch_x.reshape((batch_size, n_steps, n_input))</div><div class="line">        sess.run(optimizer, feed_dict = &#123;x: batch_x, y: batch_y&#125;</div><div class="line">        if &quot;./batch_size&quot;:</div><div class="line">            acc = sess.run(accuracy, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div><div class="line">            los = sess.run(loss, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div></pre></td></tr></table></figure>
<p><strong>Tips</strong>: “./“ represent the parameters defined by user own.</p>
<ul>
<li><strong>Testing Step</strong></li>
</ul>
<p>After training we get a weights in the tensorflow session which can be used to predict our test data.</p>
<p><strong>First</strong> generate the testing dataset from mnist generator.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">test_data = mnist.test.images[:&quot;./test_length&quot;].reshape(-1, n_steps, n_input)</div><div class="line">res = sess.run(result, feed_dict = &#123;x: test_data&#125;)</div><div class="line">predict_label = sess.run(tf.argmax(res, 1))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> because tensorflow mnist test dataset have its own ground-truth. So we can estimate if our “predict_label” is correct. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">test_label = mnist.test.labels[:&quot;./test_lenght&quot;]</div><div class="line">sess.run(accuracy, feed_dict = &#123;x: predict_label, y: test_label&#125;)</div></pre></td></tr></table></figure>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><ol>
<li><p>Install tensorflow.</p>
<ul>
<li>If we will run our model on GPU we have to install cuda and cuDNN.<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install tensorflow(-gpu)==0.12.1</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Import tensorflow package.</p>
</li>
<li>Import tensorflow mnist dataset and read the dataset as a generator.</li>
<li>Run our model<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python &quot;./model_name&quot;.py</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples/" target="_blank" rel="external">Googel Tensorflow Example</a></li>
</ul>
<h1 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h1><p>In this experiment we use a simple RNN(LSTM) model to predict the handwritten digits which also catch a good consequence in CNN.<br>RNN model is good for using in NLP processing. But how to explore the most useful <strong>determines</strong> whether our model can get an excellent result or not.</p>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Machine Learning</code> <code>RNN</code> <code>LSTM</code> <code>Tensorflow</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot;&gt;&lt;a href=&quot;#Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;Re
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
      <category term="Tensorflow" scheme="http://yoursite.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04遠端桌面（remote desktop）設置</title>
    <link href="http://yoursite.com/2017/07/25/Remote/"/>
    <id>http://yoursite.com/2017/07/25/Remote/</id>
    <published>2017-07-25T04:00:24.000Z</published>
    <updated>2017-07-25T04:08:02.329Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Ubuntu上的遠端鏈接比起windows系統自帶的Remote Desktop需要配置的條件更多。網上也有許多不同的版本，本人嘗試之後發現了一些常見的問題，特在此總結可行的一般流程與常見問題的解決方式。</p>
<h1 id="System-Config"><a href="#System-Config" class="headerlink" title="System Config"></a>System Config</h1><p><code>Ubuntu16.04</code> <code>Windows 10</code></p>
<h1 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h1><p>1、如果需要從Ubuntu連接到Windows系統，則可以安裝Desktop</p>
<ul>
<li>sudo apt-get install ubuntu-desktop</li>
</ul>
<p>2、若只是從Windows鏈接到Ubuntu則跳過第一步，直接安裝遠端桌面軟體xrdp</p>
<ul>
<li><p>sudo apt-get install xrdp</p>
<ul>
<li>此時若打開xrdp的配置文件，可以看到默認的xrdp協定，遠 端桌面則是根據這個來請求遠端服務的。</li>
</ul>
</li>
<li>sudo vim /etc/xrdp/xrdp.ini</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1tOoyic.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>其中port = -1表示默認port(5910)作為登錄的接口，之後的連接可通過這個port連入相同的session（因為遠端連接的port一般可以兼容port5900到5910）如果需要更改連接的port可以在xrdp.ini文檔中修改port為port = ask59XX來請求連接。</li>
</ul>
<p>修改完畢後記得重啟xrdp：</p>
<ul>
<li>sudo service xrdp restart</li>
</ul>
<p>3、此時可以查看service port看是否處於LISTEN的狀態。</p>
<ul>
<li>netstat -utl</li>
</ul>
<p><strong>Important : 必須確保三個port處於監聽狀態</strong></p>
<ul>
<li>port 3389</li>
<li>port 3350</li>
<li>port 59XX</li>
</ul>
<p><img src="https://i.imgur.com/0BgAP4w.png" alt=""></p>
<p>4、確保Ubuntu系統安裝了vnc服務，大部分系統會自行安裝，可以通過重複安裝確認。</p>
<ul>
<li>sudo apt-get install vnc4server<br>或</li>
<li>sudo apt-get install tightvncserver</li>
</ul>
<p>5、由於xrdp會開放3389的port作為遠端圖形化界面的窗口，因此還需要有相應的圖形化桌面套件。<br><strong>Ubuntu常用的桌面套件有三種，選擇一種安裝即可</strong></p>
<ul>
<li>安裝與設定Xfce<ul>
<li>sudo apt install xfce4</li>
<li>echo “xfce4-session” &gt; ~/.xsession </li>
</ul>
</li>
<li>安裝與設定Lxde<ul>
<li>sudo apt install lxde</li>
<li>echo “lxsession -s LXDE -e LXDE” &gt; ~/.xession </li>
</ul>
</li>
<li>安裝與設定Mate<ul>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/ppa</li>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/trusty-mate</li>
<li>sudo apt update</li>
<li>sudo apt install –no-install-recommends ubuntu-mate-core ubuntu-mate-desktop</li>
<li>echo “mate-session” &gt; ~/.xsession</li>
</ul>
</li>
</ul>
<p>6、之後就可以使用遠端桌面連接Windows和Ubuntu了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PBsp6Sc.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>结果如下（Mate）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a1PmzMs.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Common-Problem"><a href="#Common-Problem" class="headerlink" title="Common Problem"></a>Common Problem</h2><ul>
<li>遠端連接出現error-problem connecting：<ul>
<li>通常是因為vnc服務沒有架好，查看port的監聽狀態（詳見步驟3），如果只有3389和3350沒有5910的情況，則需要手動開啟相應的port進行連接。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>vncserver : 1~9 (引號兩邊都需要空格)</li>
<li>在xrdp設定檔中將prot從-1改為ask剛才開啟的port（vncserver設1則開啟5901以此類推）</li>
</ul>
</li>
<li>遠端桌面連接進入出現灰色網格，無圖像，滑鼠變成X：<ul>
<li>出現這種狀況通常是沒有安裝遠端桌面套件，導致圖形化界面無法呈現。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>安裝三種遠端桌面套件的一種（詳見步驟5）</li>
</ul>
</li>
</ul>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Ubuntu</code> <code>Remote Desktop</code> <code>xrdp</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;Ubuntu上的遠端鏈接比起windows系統自帶的Remo
    
    </summary>
    
    
      <category term="Ubuntu" scheme="http://yoursite.com/tags/Ubuntu/"/>
    
      <category term="Remote Desktop" scheme="http://yoursite.com/tags/Remote-Desktop/"/>
    
      <category term="xrdp" scheme="http://yoursite.com/tags/xrdp/"/>
    
  </entry>
  
  <entry>
    <title>Python字符編碼問題</title>
    <link href="http://yoursite.com/2017/07/25/Unicode/"/>
    <id>http://yoursite.com/2017/07/25/Unicode/</id>
    <published>2017-07-25T03:52:58.000Z</published>
    <updated>2017-07-25T04:08:25.789Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是编码"><a href="#什么是编码" class="headerlink" title="什么是编码"></a>什么是编码</h1><p>字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編程語言中，我們經常會處理文本編碼之間的轉化問題，因為文本可能存在不同的編碼格式，例如 ASCII、GBK、UTF-8等等。最近在做NN的過程中面臨Corpus的unicode編碼問題，因此需要弄清楚python不同版本對編碼問題的處理策略。</p>
<h2 id="字符的抽象概念"><a href="#字符的抽象概念" class="headerlink" title="字符的抽象概念"></a>字符的抽象概念</h2><p>看了一些網絡上的介紹，發現我們所謂的字符表示文本中單一的一個符號。然而一個字符不是一個字節，例如 “中” 這個字在文本中是一個基礎字符，但是在計算機中卻不是一個字節。一個字符有許多表示方法，不同的表示方法會使用不同的字節數，這就是所謂的編碼。<strong>字符就是文本中的最小單元</strong>。</p>
<h2 id="編碼的方式"><a href="#編碼的方式" class="headerlink" title="編碼的方式"></a>編碼的方式</h2><p>Unicode是一種編碼規範，用來統一表示世界上的各種語言。其作為Python語言中的一種中間轉換碼，如果要對不同編碼格式的文本進行轉換，就必須對字符串解碼（decode）成Unicode，再從Unicode編碼（encode）成另一種編碼格式：</p>
<p><code>decode</code> : 作用是將編碼的字符串轉換成Unicode。<br><code>encode</code> : 作用是將Unicode傳換成其他編碼格式。</p>
<h1 id="Python2-vs-Python3"><a href="#Python2-vs-Python3" class="headerlink" title="Python2 vs Python3"></a>Python2 vs Python3</h1><p>Python3的編碼形式默認為Unicode</p>
<ul>
<li>那麼Python3的文本可以通過encode傳換成bytes嗎？bytes和str一樣嗎？</li>
</ul>
<p>首先bytes不是字符串，那么b ‘a’ 和 ‘a’ 的区别是什么呢？在Python3运行输入出bytes的时候，它采取的原则是这样的：没读一个字节就和ascii码比对一下，如果符合ascii码的字符（特殊字符，字母和数字等除外），那这个字节就按照ascii码来表示，否则就按照十六进制‘\x’的形式来表示。</p>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ctGhV9P.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>因此bytes对象不能由超过0到127的ascii码范围的unicode字<br>符串表示。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8ou3vVE.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>bytes的表示方式为b + (字符串)，如果不用bytes表示，则直接用 ‘\x’ + 两位十六进制数表示一个字节。</p>
<ul>
<li>那么在Python2表示unicode的时候我们使用u + (字符串)的形式表示unicode编码，而Python3中则无需这么做。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2ji3C8E.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y2rtdQM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>注意在Python3中u‘字符串’和‘\u四位十六进制数’是等价的，而且都为str对象。而‘\u四位十六进制数’和‘\u四位十六进制数’却不相同。</li>
</ul>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RZD8Ptn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Python2</code> <code>Python3</code> <code>Unicode</code> <code>编码</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是编码&quot;&gt;&lt;a href=&quot;#什么是编码&quot; class=&quot;headerlink&quot; title=&quot;什么是编码&quot;&gt;&lt;/a&gt;什么是编码&lt;/h1&gt;&lt;p&gt;字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編
    
    </summary>
    
    
      <category term="Unicode" scheme="http://yoursite.com/tags/Unicode/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04如何安裝搜狗（Sogou）輸入法</title>
    <link href="http://yoursite.com/2017/07/25/Ubuntu-sogo/"/>
    <id>http://yoursite.com/2017/07/25/Ubuntu-sogo/</id>
    <published>2017-07-25T03:48:07.000Z</published>
    <updated>2017-07-25T04:08:20.329Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>目前Ubuntu常用的中文输入法有：</p>
<ul>
<li>搜狗拼音： 搜狗出品的面向Linux的输入法。</li>
<li>Fcitx： 这个是Ubuntu系统自带的Linux开源的输入法框架，提供了包括Google PinYin、ShuangPin、SunPinYin、Hong Kong和TaiWan繁体等一系列输入法。</li>
</ul>
<p>下面主要讲下如何在Ubuntu 16.04上安装搜狗输入法。</p>
<h2 id="安裝過程"><a href="#安裝過程" class="headerlink" title="安裝過程"></a>安裝過程</h2><p>下載安裝檔之前首先需要確認本機的Ubuntu系統是什麼樣的編碼位元。利用“uname -a”指令查詢系統資訊。</p>
<p>下載安裝包，sogou提供了32位和64位版本:<a href="http://pinyin.sogou.com/linux/?r=pinyin" target="_blank" rel="external">http://pinyin.sogou.com/linux/?r=pinyin</a></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/G7PoJFF.png" alt="Sogou" title="">
                </div>
                <div class="image-caption">Sogou</div>
            </figure>
<p>下載完成后可以直接雙擊下載的deb包裝或執行指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo dpkg -i sogoupinyin*.deb</div><div class="line">$ sudo apt -f install</div></pre></td></tr></table></figure></p>
<ul>
<li><strong>第一行指令會提示sogou的一些鏈接錯誤，需用第二條指令解決。</strong></li>
</ul>
<p>安裝完成之後重啟系統。</p>
<p>再次開啟系統后就能夠在輸入法設置菜單看到Sogou的選項了。</p>
<ul>
<li><strong>Tips</strong>：有些版本會出現搜狗與Fcitx的衝突問題，但是本人沒有遇到這個問題，但是仍然提供一個評價最佳的解決策略：(移除其中一種輸入法架構)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo apt remove fcitx*</div><div class="line">$ sudo apt autoremove</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Linux</code> <code>Ubuntu 16.04</code> <code>sogou输入法</code> </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;目前Ubuntu常用的中文输入法有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;搜狗拼音： 搜狗出品的面向Linux的输入法。&lt;/li&gt;
&lt;li&gt;Fcitx
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="Ubuntu 16.04" scheme="http://yoursite.com/tags/Ubuntu-16-04/"/>
    
      <category term="sogou输入法" scheme="http://yoursite.com/tags/sogou%E8%BE%93%E5%85%A5%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习（Machine Learning）简单学</title>
    <link href="http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/"/>
    <id>http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/</id>
    <published>2017-07-24T05:48:31.000Z</published>
    <updated>2017-07-24T10:05:41.645Z</updated>
    
    <content type="html"><![CDATA[<p>本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了<a href="https://morvanzhou.github.io/tutorials/machine-learning/" target="_blank" rel="external">莫烦Python</a>的教学视频，发现其中的内容丰富有趣并且具有很好的阶层学习框架。于是总结了一些精髓并加入了自己从事机器学习研究所工作的一些见解，总结了一些精华的部分以供大家快速入门和学习。</p>
<h1 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h1><p>机器学习（Machine Learning）是由一帮计算机科学家们希望让计算机像人类一样思考而延伸出来的一门计算机理论。机器学习最早来自心理和生物科学，科学家们认为人和计算机其实没有什么差别，都是一大批相互连接的信息传递和存储元素所组成的系统。机器学习是一门典型的跨领域科学，其中包含了概率学、统计学等等方面。随着计算机性能的提升和计算机运算速度的升级，机器学习的应用才真正开始融入我们日常的生活当中。而不久的将来，机器学习必将成为人类探索机器世界的关键钥匙。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>图像识别， AI对话式智慧型家居, 聊天机器人， 股市风险预测…</p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>机器学习的实现方式多种多样，在程式语言中我们称之为算法。<br>Machine Learning的学习方式主要包括：</p>
<ul>
<li><strong>监督式学习（Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and Labels</li>
<li><strong>Principle</strong>: 通过让计算机学习这些label来标记相应的value，从中找出它认为重要的部分作为判断依据。（<strong>既定规律</strong>）</li>
<li><strong>Example</strong>: Logistic Regression、Back Propogation Neural Network</li>
</ul>
</li>
<li><strong>非监督式学习（Un-Supervised Learning）</strong><ul>
<li><strong>Input: Values</strong></li>
<li><strong>Principle</strong>: 只提供value的情况下，计算机事先无法得知value所代表的含义以及需要学习的正确结果，这时候就需要让计算机自己学会分类不同的value，从而总结出不同value背后所隐藏的重要规律作为判断依据。（<strong>生成规律</strong>）</li>
<li><strong>Example</strong>: Apriori、K-Means</li>
</ul>
</li>
<li><strong>半监督式学习（Semi-Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and A few Labels</li>
<li><strong>Principle</strong>: 这种学习方式主要让计算机考虑如何利用少量的label总结出最适合value的判断规则，从而引申到更大范围的value中。</li>
<li><strong>Example</strong>: Laplacisn SVM、Graph Inference</li>
</ul>
</li>
<li><strong>强化学习（Reinforcement Learning）</strong><ul>
<li><strong>Input</strong>: Environment and Set of Operations</li>
<li><strong>Principle</strong>: 通过将计算机设定在一个复杂的环境中，让机器去随机尝试各种可能的操作，并通过环境的回馈（正确加分，不正确扣分）的方式让机器的行为向加分的方面靠近，最终适应环境。</li>
<li><strong>Example</strong>: Alpha GO、Robot Control</li>
</ul>
</li>
</ul>
<p>Machine Leaning的算法主要分为这几类：</p>
<ul>
<li><strong>回归算法（Regression）</strong></li>
<li><strong>基于实例的算法（Instance-Based Algorithm）</strong></li>
<li><strong>正则化方式（Regular Expression）</strong></li>
<li><strong>决策树（Decision Tree）</strong></li>
<li><strong>贝叶斯（Bayesian）</strong></li>
<li><strong>基于核的算法（Kernel-Based Algorithm）</strong></li>
<li><strong>聚类算法（Clustering）</strong></li>
<li><strong>关联法则（Association Rule）</strong></li>
<li><strong>遗传算法（Genetic Algorithm）</strong><ul>
<li>源自进化理论，淘汰弱者，适者生存。通过不断更新和淘汰的机制去选择最优的设计模型。</li>
</ul>
</li>
<li><strong>人工神经网络（Neural Network）</strong></li>
<li><strong>深度学习（Deep Learning）</strong></li>
<li><strong>降低维度算法（Reduce Dimension）</strong></li>
<li><strong>集成算法（Integrated Algorithm）</strong></li>
</ul>
<h1 id="什么是神经网络（Neural-Network）"><a href="#什么是神经网络（Neural-Network）" class="headerlink" title="什么是神经网络（Neural Network）"></a>什么是神经网络（Neural Network）</h1><p>基于生物学的神经结构，将神经细胞的电信号传播机制应用到计算机结构中来，通过对信号传导和演变来组成网络架构。人工神经网络中的每一个“神经元”就是一个Neuron，用来以一定的算法改变输入的信号，从而改变传输的信息，达到对环境做出反应的目的。另一方面，通过神经网络产生的反应收到环境的反馈（做的好或不好），这些反馈和目标行为的误差会通过神经网络的反向传递从原先的路径传送回去，沿途中这些反馈信号会反过来刺激Neuron调整相应的参数从而使得下一次正向传递的结果能够更加贴近目标。如此往复便是整个神经网络训练的过程。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/umtL8L5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>人类通过学习，能够掌握和判别事物的特征从而对事物的本质做出判断，而机器同样是利用这种机制建立起相应的“识别”模型，这些模型对不同的事物具有不同的反应强度，利用强度的不同来区别事物的本质。</p>
<h2 id="神经网络的基本结构"><a href="#神经网络的基本结构" class="headerlink" title="神经网络的基本结构"></a>神经网络的基本结构</h2><p>一个简单的神经网络由3个部分组成：</p>
<ul>
<li><strong>Input Layer</strong><ul>
<li>输入层，用来将资料喂给神经网络</li>
</ul>
</li>
<li><strong>Hidden Layer</strong><ul>
<li>隐藏层，用来尝试改变和调整神经网络的模型和数据的转化</li>
</ul>
</li>
<li><strong>Output Layer</strong><ul>
<li>输出层，用来将神经网络处理后的信号输出成最终的结果</li>
</ul>
</li>
</ul>
<h2 id="神经元（Neuron）的激活函数（Activation-Function）"><a href="#神经元（Neuron）的激活函数（Activation-Function）" class="headerlink" title="神经元（Neuron）的激活函数（Activation Function）"></a>神经元（Neuron）的激活函数（Activation Function）</h2><p>在神经网络学习的过程中，需要对输入的信号做出某种调整，才能真正得到最终的结果。<br>传统的激活函数包括：<br><strong>Sigmoid</strong>、<strong>TanHyperbolic(tanh)</strong>、<strong>ReLu</strong>、 <strong>softplus</strong>以及<strong>softmax</strong>函数</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LT2BXvM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>例如当我们输入一只猫，输入层神经网络会把信号传递给隐藏层的神经元。每一个接收到信息的神经元会通过自己现有的经验对信号做出判断，利用激活函数（activation function）来判断此时的神经元是否需要被激活。激活后的神经元就会对输入信号进行处理并传递给下一层的神经网络层，如此往复当信号传递到输出层时则会经由最终的刺激函数（一般为softmax）产生相应的结果确定输出的信号是属于哪一个标签（label）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vYgqqHJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果此时计算机得到了错误的结果，我们就会通过反向的传递将误差传导回去，改变<strong>所有</strong>的神经元参数，继而那些原本活跃的神经元就会被弱化，在下一次的神经传导过程中就会逐渐被激活函数淘汰。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UHIK2YN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>经过更新的神经网络能够在下一次迭代过程（epoch）中就会改变思路，转而尝试其他的判断方法。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/so90M0c.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>直到得到正确的结果，误差就会小到可以忽略，如此神经网络得以生成。</p>
<h2 id="卷及神经网络（CNN）"><a href="#卷及神经网络（CNN）" class="headerlink" title="卷及神经网络（CNN）"></a>卷及神经网络（CNN）</h2><p>卷积神经网络（Convolution Neural Network）在图片识别方面能够给出不错的结果。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y65bdvJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TZ1jOeO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用<strong>图片</strong>作为例子，任何输入的信号都会被转化成计算机能够识别的数字信号集合，例如矩阵（matrix）。<strong>文字</strong>也是一样的，我们把文字抽象成一个固定维度的向量，在这个维度空间中，每个字都是独立区别开来的，文字的多样性就有这些数字的排列组合来定义。这些信号集会通过输入层读取信息并进入神经网络中。<br>卷积神经网络就是其中的一种网络模式，我们可以把它分成<strong>卷积</strong>和<strong>神经网络</strong>两个部分来理解。</p>
<ul>
<li><strong>卷积</strong>：可以理解为对一个区域信号强弱的总体分析。通过卷积运算可以在一定的区域内总结有用信号的强弱分布，从而对一定区域内信号的变化情况能够有一个较好的认知。卷积能够增强信号的连续性，用区域单位代替点电位。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uOav6gV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><strong>神经网络</strong>：卷积神经网络利用批量过滤的方式，在大范围的信号中不断收集信息，每一次得到的区域信息都是区域中的一小块，之后从这些信息中总结出一些所谓的边缘信号（edges，例如：竖线，横线，斜线，圆圈等基本边缘，其可能分别代表人脸眼睛的左上角，中间，右上角等等部位的区域信息）。同样，用相同的方式从边缘信息组合的图像中总结出更大范围的边缘信息（例如：利用竖线，横线，圆圈等结构组合出整个眼睛）。最后将得到的结果传入全连接层的分类神经网络中就能得到相应的label了。</li>
</ul>
<p><strong>Example：</strong> </p>
<p><img src="https://i.imgur.com/fScPOCU.png" alt=""></p>
<p>图片的维度信息有长、宽和高，长和宽用来表示图片的信号集，高度则是表示颜色的信号分布。被白颜色只有1个高度单位，而彩色的图片则有R、G、B三种基本颜色的信息单位。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VmMQcSI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用批量过滤从图片中收集一定区域中的像素块，而输出的值就是一个高度更高，长和宽都更小的图片。这些图片存储的就是边缘（edges）信息。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/twaqQCR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>反复进行同样的过滤步骤，就可以对图片的信息有更好的理解。之后再对结果进行分类就行了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ikChVno.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在卷积的过程中，神经元可能无意中会丢失一些信息。池化（pooling）就是为了解决这样的问题而被设计出来的。既然我们的信息是在卷积过程中压缩的时候丢失的，那么我们就舍弃这个步骤，直接保留原本的长宽，最后在由池化层统一进行压缩长宽的动作。</p>
<h3 id="CNN常用结构"><a href="#CNN常用结构" class="headerlink" title="CNN常用结构"></a>CNN常用结构</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zugYmYR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>比较流行的<strong>CNN结构</strong>先是输入信号，经过卷积层进行卷积运算，然后经过池化压缩长宽的维度。常用的是Max Pooling的结构：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/T3B3QjS.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在区域中区最大值作为代表这个区域的信号。之后再次对结果进行相同的卷积和池化，进一步压缩信号。之后通过两个全连接层将信号传导给分类器进行分类预测。</p>
<h2 id="递归神经网络（RNN）"><a href="#递归神经网络（RNN）" class="headerlink" title="递归神经网络（RNN）"></a>递归神经网络（RNN）</h2><p>递归神经网络（Recurrent Neural Network）在自然语言处理和序列化信息分析方面能够给出不错的结果。如果说CNN是图像识别的代表性神经网络，那么RNN就是文字处理领域的“CNN”。</p>
<ul>
<li><strong>语言文字</strong>就是一个典型的<strong>序列化信号集</strong>，我们说出的每一句话之间，甚至每一个词之间都有先后关系的依赖，如果抛开字的先后顺序，我们的语言将会失去原本的含义。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/afEYtWN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>假设现在有许多不同的数据信号，如果神经网络只是基于当前的输入信号进行结果的预测，那么就相当于无视了所谓的连续规则，其中必然会丢失重要的时序信息。就好比做菜，酱料A要比酱料B先放，否则就会导致串味的现象。因此一般的NN结构无法让机器了解数据之间的关联。</p>
<p><strong>那么要如何做到让计算机也具有处理连续信号的能力呢？</strong></p>
<ul>
<li>从人的角度出发，不难想到的方式就是记住先前处理过的信号，并将这些信号一同作为输入传递到当前的神经网络中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/AUqu2Ss.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们将先前处理的结果存入记忆中，在分析当前信号时会产生新的记忆。由于记忆之间不会相互关联，因此我们可以直接将先前的记忆调用过来一起进行处理：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/D86UcOA.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如此一来往复多次，神经网络就能携带长期的序列信号进行处理了。<strong>总结之前的流程：</strong></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/MW1BRcu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN运作过程中，每次的结果都会被存储为一个State状态信号，并通过不断迭代传递到下一个乃至更远的神经网络中去。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/iQKtiQP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN下一个时刻到来时，State状态同样会被存储成T+1时刻的State，但这是的 <strong>Y（t）</strong> 不再只是由 <strong>S（t+1）</strong> 来决定的，而是通过 <strong>S（t）</strong> 和 <strong>S（t+1）</strong> 共同处理 <strong>X(t+1)</strong> 得到的结果。因此这个State结构也可以用递回的方式来表示。</li>
</ul>
<h3 id="RNN常用结构"><a href="#RNN常用结构" class="headerlink" title="RNN常用结构"></a>RNN常用结构</h3><p>RNN的形式多种多样，一般需要根据处理的情况不同选择相应适合环境的模型进行建模。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/aZqWHqb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通常可以看到以下几种：</p>
<ul>
<li>如果是用于<strong>分类</strong>的话，例如在判断一句话的情感取向，判断是positive或者negative的情况下，倾向于使用根据最终结点的结果来输出判断的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Noc6AFL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>描述</strong>的话，例如通过一些集成度高的特征信号（图片等）来产生一个描述性的句子或者序列的情况下，倾向于使用根据单一输入来逐步读取时序信息的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2zP4G0h.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>翻译</strong>的话，例如通过一段连续的输入信号来预测下一段连续输出信号的情况下，倾向于使用多对多输出的序列化RNN（Sequence-to-Sequence）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LJSO3JG.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="神经网络非监督式学习实现Autoencoder"><a href="#神经网络非监督式学习实现Autoencoder" class="headerlink" title="神经网络非监督式学习实现Autoencoder"></a>神经网络非监督式学习实现Autoencoder</h1><p>在神经网络训练过程中，往往会需要输入大量的信息，而这些信息对于计算机的学习来说具有十分巨大的负担。想想人类的学习过程，如果一次性塞给我们大量的信息，不但达不到很好的学习效果，还会浪费大量的时间。</p>
<p>因此我们需要一个特殊的神经网络来将原本的信息进行压缩，提取其中最具有代表性的信息，这个网络就是所谓的<strong>编码器（encoder）</strong>。之后再通过放大压缩后的信息，重现原始资料的全部信息，也就是 <strong>解码（decoder）</strong> 的过程。而我们所需要做的就是取得编码器压缩之后的简要信息，送入神经网络进行学习，从而达到我们的目的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/SfOfLbo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>压缩和解压的过程共同构成自编码（Autoencoder）的行为，通过训练编码器和解码器的神经网络结构，依据每次压缩前和解压后数据的对比情况来判断压缩的好坏程度，并利用反向传递来修正误差，从而最大程度上的压缩和还原原始信号。由于从头到尾我们所需要的输入信息为原始信号的信息，整个过程不需要对应的标签信息（label），因此autoencoder属于非监督学习的方式。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BidenDF.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通常会使用到的部分是自编码的结果，也就是压缩过后的概括性讯息。我们建构的其他神经网络只需要对这些精髓的信息进行学习就行了。这样的方式不仅减少了神经网络的负担，还能达到很好的学习效果。</li>
</ul>
<p>自编码的思路和传统的主成分分析算法的精髓类似，都是试图从数据中抓住决定性的关键内容，来概括和分类数据的特征。相比于传统的降维算法中的PCA主成分分析方法，Autoencoder甚至能够取得更好的效果，因此也常被用来对原始数据进行<strong>降维</strong>。</p>
<h1 id="生成对抗网络（GAN）"><a href="#生成对抗网络（GAN）" class="headerlink" title="生成对抗网络（GAN）"></a>生成对抗网络（GAN）</h1><p>生成对抗网络（Generative Adversarial Net）不同于传统的FNN、CNN和RNN是将输入的数据和输出的结果通过某种关系联系起来的神经网络模型，GAN则是一种<strong>凭空生成结果</strong>的模型。</p>
<ul>
<li>当然所谓的 <strong>凭空</strong> 并不是真正意义上的<strong>无</strong>，而是通过一些随机的尝试（随机数组合）创造出一些东西。比如一张图片（像素集合）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/lOfWUK4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们可以把这个随机尝试生成图片的网络比喻成一名新手画家，他们根据自己的灵感用现有的技术生成一些画作。一开始可能有了灵感但是由于作画技术的限制，往往无法生成理想中的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/tU6ZZEW.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>于是这名画家就找到了自己的好朋友新手鉴赏家，可是因为新手鉴赏家本身不具备良好的分辨能力，因此往往给出错误的回答。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a3YNuV0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这个时候就会有外部的干涉参与其中，通过一些标记好的资料来训练这名新手鉴赏家，让他一步步能够辨别画作的好坏。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ou0PBfm.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>最重要的是在训练新手鉴赏家的过程中，随着鉴赏技术不断成熟，鉴赏家开始对新手画家的一些作品做出正确的判断和反馈。这时新手画家就会从这个新手鉴赏家手中得到<strong>真正的有用的标签（label）</strong>，进而利用这些标签改变自己的网络，让自己能够画得更好。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PW7ll1Q.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>总结之前的流程，就是新手鉴赏家这个神经网络利用从外部监督得到的反馈提升自己，然后再利用自己去训练另外一个神经网络，随着新手画家神经网络的不断提升，鉴赏家网络得知自己的能力已经无法鉴赏该画作时，就再次求助外部反馈。就在这一次一次地<strong>对抗</strong>中，两个神经网络就会越来越强大。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/huvFBco.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在GAN网络中，新手画家就是我们的<strong>生成器（Generator）</strong>，新手鉴赏家就是所谓的<strong>Discriminator（辨别器）</strong>，画家的每一幅画都是通过不同的数字排列组合成的像素矩阵，也就是我们说的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BtcBwwU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="GAN的应用"><a href="#GAN的应用" class="headerlink" title="GAN的应用"></a>GAN的应用</h2><p>GAN因为能够通过随机组合产生新的数据，因而常被用在数据的合成和生成新数据的方面。</p>
<ul>
<li>其中一个重要的例子就是数据序列的加减法：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7NxbFvF.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中的二次元人物是通过GAN神经网络的学习，然后利用描述性的选项组合，来生成不同特征的人物图像的一个神经网络网络应用。</p>
<h1 id="理解神经网络的“-黑盒子-”"><a href="#理解神经网络的“-黑盒子-”" class="headerlink" title="理解神经网络的“ 黑盒子 ”"></a>理解神经网络的“ 黑盒子 ”</h1><p>神经网络的成功之处在于它能够从输入和输出的数据中总结出一个抽象的算法函式，基于这个函式的关系我们就能够对未知的数据进行预测。</p>
<p>例如：<br>$$$<br>y = {ax + b \over 2}<br>$$$</p>
<p>这个就相当于一个已经训练好的神经网络模型，对于输入信号<code>X</code>通过网络的处理之后得到输出结果<code>Y</code>。</p>
<p>而神经网络建立的模型就像是把算法公式中所有参数进行一个<strong>封装</strong>，然后开放一个相应的<strong>接口(Interface)</strong>用于呼叫和取值。因此神经网络也被亲切地称之为 <strong>“ 黑匣子 ”</strong> 。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/U5riVAp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>神经网络一般分为三个部分，输入和输出都是人类能够理解的信息，而中间的部分就是所谓的<strong>盲区</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uZpZxdz.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果我们将神经网络的中间层注意拆解后会发现输出的事物往往会是我们看不懂的东西，这就是为什么神经网络 <strong>“黑”</strong> 的原因了。对于人而言，我们在记忆复杂的环境和事物时往往会用一些自己熟知的<strong>记号来标记事物</strong>，使得我们能够更加清楚地记得事物的特征。计算机也是一样的：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gdW7DwM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们知道神经网络处理的信息大都是数字集，通过神经层的分离可以看到这些数字集发生了改变，这些改变在人类看来无法理解，但事实上却是计算机利用自己的方式将这些事物通过它们捕捉到的特征信息转换成<strong>它们眼中的记号</strong>。也就是说计算机正在试图用自己能够理解的方式标记这些特征。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FF8SNDZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在神经网络中，我们称人们能够识别的<strong>特征</strong>记作<strong>Features</strong>，而机器转换后的<strong>特征标记</strong>记作<strong>Feature Representation</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ZrHPbGp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>利用手写数字的特征来理解的话，神经网络的Feature Representation就是空间中不同区域的分布状况。不同的位置聚集了不同的数字集合，落在不同的区域内就说明该输入属于哪一个输出。也就是说计算机把我们熟知的<strong>数字（也就是Features）</strong> 用 <strong>空间坐标区域（也就是Feature Representation）</strong> 来表示。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1GT46F0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>理解神经网络的内部结构和Feature Representation的含义可以很好地利用 <strong>迁移学习（Transform Learning）</strong> 的方式来组合我们的神经网络，从而达到更好的效果。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hE5VgF2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>例如我们已经训练好了从图片中解析物体的神经网络，它能够从图像的序列信息中提取关键的特征事物，此时只需要将输出层替换掉，再加入新的神经网络结构进行连接，就可以生成全新的模型。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qslxK9t.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>新的神经网络重新训练之后就能够具有全新的功能，利用原先的网络优势来拓展生成新的<strong>特征标记</strong>，一定程度上减少了神经网络训练的复杂度。基于先前的图像提取，能够从图中得到事物的<strong>特征信息（Feature Representation）</strong>，再利用新的网络将这些信息进一步转换成表示事物价格的<strong>特征信息</strong>，如此一来神经网络的功能就得以演化了。</li>
</ul>
<p>LICENCE： 图片摘录自网络引擎，未经授权请勿用于盈利性活动<br>更多详细内容 ： <a href="https://morvanzhou.github.io/" target="_blank" rel="external">Link</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了&lt;a href=&quot;https://morvanzhou.github.io/tutorials/machine-learning/&quot; targe
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="Reinforcement Learning" scheme="http://yoursite.com/tags/Reinforcement-Learning/"/>
    
  </entry>
  
</feed>
