<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>指尖の岁月</title>
  <subtitle>世间点滴，莫忘于心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-07-25T07:16:13.678Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Eternal</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>聊天机器人训练语料整理</title>
    <link href="http://yoursite.com/2017/07/25/Corpus/"/>
    <id>http://yoursite.com/2017/07/25/Corpus/</id>
    <published>2017-07-25T07:15:05.000Z</published>
    <updated>2017-07-25T07:16:13.678Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Dialog-Datasets-for-Training-Chatbot"><a href="#Dialog-Datasets-for-Training-Chatbot" class="headerlink" title="Dialog Datasets for Training Chatbot"></a>Dialog Datasets for Training Chatbot</h1><p>在进行Chatbot的研究过程中，除了要有一个漂亮的模型之外，还需要有大量可供训练的语料来强化我们的聊天机器人。越干净的语料就能训练出越接近人类自然语言回复的Chatbot。</p>
<ul>
<li>目前网上公开的语料大多是一些带有噪音的、数量有限的语料。在这里总结了一些可行的语料以及一些利用爬取工具得到的语料，其中包括：</li>
</ul>
<h1 id="基本公开语料"><a href="#基本公开语料" class="headerlink" title="基本公开语料"></a>基本公开语料</h1><ul>
<li><p><a href="https://github.com/rustch3n/dgk_lost_conv" target="_blank" rel="external">dgk_shooter_min.conv</a><br>中文电影对白语料，噪音大，由于对话未区分说话人，因此对白问答关系难以对应。</p>
</li>
<li><p><a href="https://github.com/gunthercox/chatterbot-corpus/tree/master/chatterbot_corpus/data/" target="_blank" rel="external">ChatBot多语种聊天语料</a><br>ChatterBot聊天引擎所提供的基本语聊，涵盖语种范围广，但是数量不多，但质量较高，适合模型测试。</p>
</li>
<li><p><a href="https://github.com/karthikncode/nlp-datasets#question-answering" target="_blank" rel="external">DataSets for Natural Language Processing</a><br>这个是人为收集总结的自然语言处理研究论文以及对应的数据资料集，主要覆盖方面包括了： <strong>Question Answering, Dialogue Systems</strong> 以及 <strong>Goal-Oriented Dialogue System</strong> 等。文本都由英文构成，可用于机器翻译和对话模型使用。</p>
</li>
<li><p><a href="https://github.com/rustch3n/dgk_lost_conv/tree/master/results" target="_blank" rel="external">小黄鸡对话机器人训练语料</a><br>这就是网络上流行的小黄鸡对话机器人的训练语料，包括了 <strong>xiaohuangji50w_fenciA.conv.zip （已分词）</strong> 和 <strong>xiaohuangji50w_nofenci.conv.zip （未分词）</strong> 两个部分，分词以 <strong>“/”</strong> 区隔开来，并没有语义上的划分。语料中含有较多表情颜文字，总体对话字数较少，杂讯较多。</p>
</li>
<li><p><a href="https://github.com/Samurais/egret-wenda-corpus" target="_blank" rel="external">白鹭时代中文问答语料</a><br>由白鹭时代官方论坛问答版块的问题及回复组成，回复选取了标注 <strong>“最佳答案”</strong> 的记录为目标。人工审核资料，给每一个问题一个可以接受的答案。数量不多，多为问答模式。</p>
</li>
<li><p><a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" target="_blank" rel="external">Cornell_Movie-Dialogs_Corpus</a><br>康奈尔大学影视对话资料集，语料包含对话人名称信息，语料为英文，以多轮对话为主。</p>
</li>
</ul>
<h1 id="个人爬取语聊（初步整理）"><a href="#个人爬取语聊（初步整理）" class="headerlink" title="个人爬取语聊（初步整理）"></a>个人爬取语聊（初步整理）</h1><ul>
<li><p><a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/news%20corpus" target="_blank" rel="external">中文新闻语料</a><br>利用爬虫从各大新闻网站上爬取的新闻头条和简讯。</p>
</li>
<li><p><a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/PTT_charactors" target="_blank" rel="external">PTT八卦版推文</a><br>利用爬虫从社交软体PTT上对于八卦分类板块的内容进行爬取，原始资料为 <a href="">PTT八卦板推文.txt</a> 其中包括一些符号和空格杂讯，过滤杂讯（利用统计方式按比例替换成固定符号，降低资料复杂度）之后，通过 <strong>单字</strong> 或 <a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/PTT_words" target="_blank" rel="external">词组</a>（jieba段词） 等不同方式建立问答语料和字典。</p>
</li>
</ul>
<h1 id="License"><a href="#License" class="headerlink" title="License:"></a>License:</h1><p>公开语料的版权归原作者所有，未经允许不得一个人名义投入盈利性活动。</p>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords:"></a>Keywords:</h1><p>Tags: <code>Corpus</code> <code>Chatbot</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Dialog-Datasets-for-Training-Chatbot&quot;&gt;&lt;a href=&quot;#Dialog-Datasets-for-Training-Chatbot&quot; class=&quot;headerlink&quot; title=&quot;Dialog Datasets for 
    
    </summary>
    
    
      <category term="Chatbot" scheme="http://yoursite.com/tags/Chatbot/"/>
    
      <category term="Corpus" scheme="http://yoursite.com/tags/Corpus/"/>
    
      <category term="Dialogue" scheme="http://yoursite.com/tags/Dialogue/"/>
    
  </entry>
  
  <entry>
    <title>Python简单学</title>
    <link href="http://yoursite.com/2017/07/25/Python/"/>
    <id>http://yoursite.com/2017/07/25/Python/</id>
    <published>2017-07-25T06:10:56.000Z</published>
    <updated>2017-07-25T06:12:12.576Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Foundation-Summary"><a href="#Foundation-Summary" class="headerlink" title="Foundation Summary"></a>Foundation Summary</h1><ul>
<li><strong>Print</strong></li>
<li><strong>Calculation Function</strong></li>
<li><strong>Variable</strong></li>
<li><strong>While loop</strong></li>
<li><strong>For loop</strong></li>
<li><strong>If/Elif/Else Condition</strong></li>
<li><strong>Function Definition[Def] with/without parameters</strong></li>
<li><strong>Global or Local Variable</strong></li>
<li><strong>Read or Write files</strong><ul>
<li><code>readlines()</code> and <code>readline()</code></li>
</ul>
</li>
<li><strong>Class</strong><ul>
<li><code>__init__</code> constructor</li>
</ul>
</li>
<li><strong>input</strong></li>
<li><strong>Tuple &amp; List</strong><ul>
<li>Both are iterative</li>
</ul>
</li>
<li><strong>List</strong><ul>
<li><code>append</code> <code>insert</code> <code>remove</code></li>
</ul>
</li>
<li><strong>Multi-dimention List</strong></li>
<li><strong>Dictionary</strong><ul>
<li><code>del(also can used for list)</code></li>
</ul>
</li>
<li><strong>Import</strong></li>
<li><strong>Continue &amp; Break</strong></li>
<li><strong>Error processing[Try/Except]</strong></li>
<li><p><strong>Zip</strong></p>
<ul>
<li>Output is an object<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">a = [1, 2, 3]</div><div class="line">b = [4, 5]</div><div class="line"># Convert to list</div><div class="line">list(zip(a, b))</div><div class="line"># Also we can use for loop to iterate each elements in object</div><div class="line">for i, j in zip(a,b)</div><div class="line"># Output of list(zip(a, b)) is: [(1, 4), (2, 5)]</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Lambda</strong><br>Example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def fun1(x, y):</div><div class="line">    return(x + y)</div><div class="line">fun2 = lambda x, y : x + y</div><div class="line"># fun1 is the same as fun2</div></pre></td></tr></table></figure>
</li>
<li><p><strong>Map</strong></p>
<ul>
<li>Output is an object<br>Example:<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def fun1(x, y):</div><div class="line">    return(x + y)</div><div class="line">list(map(fun1, [1, 2, 3], [4, 5]))</div><div class="line"># Output is: [5, 7]</div><div class="line"># Note: The output of fun1([1], [2]) is: [1, 2]</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Copy &amp; Deepcopy</strong></p>
<ul>
<li>python object share address(point)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># ********Copy********:</div><div class="line">a = [1, 2, 3]</div><div class="line">b = a</div><div class="line">b[0] = 11</div><div class="line">a = b = [11, 2, 3]</div><div class="line"># id(a) == id(b) is True</div><div class="line"></div><div class="line">import copy</div><div class="line">c = copy.copy(a)</div><div class="line"># id(a) == id(b) is False</div><div class="line"># Note:</div><div class="line">a = [1, 2, [3, 4]]</div><div class="line">d = copy.copy(a)</div><div class="line"># id(a) == id(d) is False</div><div class="line"># id(a[2]) == id(d[2]) is True</div><div class="line"># Because d[2] == a[2] are both object</div><div class="line"># Note2:</div><div class="line">a = 2</div><div class="line">b = a</div><div class="line">a = 3</div><div class="line"># b = 2 auto copy</div><div class="line"># ********Deepcopy ********:</div><div class="line">e = copy.deepcopy(a)</div><div class="line"># id(a[2]) == id(e[2]) is False</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="Multi-Thread"><a href="#Multi-Thread" class="headerlink" title="Multi-Thread"></a>Multi-Thread</h1><h2 id="Lead-to-Improve-Efficiency"><a href="#Lead-to-Improve-Efficiency" class="headerlink" title="Lead to Improve Efficiency"></a>Lead to Improve Efficiency</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">import threading</div><div class="line">import time</div><div class="line"># check the number of threads</div><div class="line">print(threading.active_count())</div><div class="line"># check all the details of threads </div><div class="line">print(threading.enumerate())</div><div class="line"># check which threads are working</div><div class="line">print(threading.current_thread())</div><div class="line"># ********Extend********:</div><div class="line">def thread_job():</div><div class="line">    print(&quot;MSG : This is a new Thread, number = %s\n&quot; % threading.current_thread())</div><div class="line">    for i in range(10):</div><div class="line">        time.sleep(0.1)</div><div class="line">    print(&quot;MSG : T1 Finished.\n&quot;)</div><div class="line">new_thread = threading.Thread(target = thread_job, Name = &apos;T1&apos;)</div><div class="line">def thread_job2():</div><div class="line">    print(&quot;MSG : T2 Start.\n&quot;)</div><div class="line">    print(&quot;MSG : T2 Finished.\n&quot;)</div><div class="line">new2_thread = threading.Thread(target = thread_job2, Name = &apos;T2&apos;)</div><div class="line">new_thread.start()</div><div class="line">new2_thread.start()</div><div class="line"># ********Join********:</div><div class="line"># print(&quot;MSG : Done.\n&quot;)</div><div class="line"># when we run the code &quot;Done&quot; will show before &quot;T2 Finished&quot; </div><div class="line">new2_thread.join()</div><div class="line">print(&quot;MSG : Done.\n&quot;)</div><div class="line"># T1 is slower than T2, so that &quot;Done&quot; will show before &quot;T1 Finished&quot;</div></pre></td></tr></table></figure>
<h2 id="Example-of-queue-using-in-thread"><a href="#Example-of-queue-using-in-thread" class="headerlink" title="Example of queue using in thread:"></a>Example of queue using in thread:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"># ********Queue********:</div><div class="line">import threading</div><div class="line">import time</div><div class="line">from queue import Queue</div><div class="line"></div><div class="line">def job(l, q):</div><div class="line">    for i in range(len(l)):</div><div class="line">        l[i] = l[i] ** 2</div><div class="line">        time.sleep(1)</div><div class="line">    # thread can not return value</div><div class="line">    # return l</div><div class="line">    q.put(l)</div><div class="line"></div><div class="line">def multithreading():</div><div class="line">    q = Queue()</div><div class="line">    threads = []</div><div class="line">    data = [[1,2,3], [4,5,6], [7,8,9]]</div><div class="line">    for i in range(3):</div><div class="line">        t = threading.Thread(target = job, args = (data[i], q))</div><div class="line">        t.start()</div><div class="line">        print(&quot;MSG : Number of thread is %s&quot; % threading.active_count())</div><div class="line">        threads.append(t)</div><div class="line">    [t.join() for t in threads]</div><div class="line">    results = []</div><div class="line">    for _ in range(3):</div><div class="line">        results.append(q.get())</div><div class="line">    print(results)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multithreading()</div></pre></td></tr></table></figure>
<h2 id="Global-Interpreter-lock-GIL"><a href="#Global-Interpreter-lock-GIL" class="headerlink" title="Global Interpreter lock(GIL):"></a>Global Interpreter lock(GIL):</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"># ********GIL********:</div><div class="line"># GIL shows that only one calculation unit can be run at a time</div><div class="line"># Therefore, for example, the efficiency of 4-threading is not equal to normal&apos;s * 4</div><div class="line">import threading</div><div class="line">from queue import Queue</div><div class="line">import copy</div><div class="line">import time</div><div class="line"></div><div class="line">def job(l, q):</div><div class="line">    result = sum(l)</div><div class="line">    q.put(result)</div><div class="line"></div><div class="line">def multi(l):</div><div class="line">    q = Queue()</div><div class="line">    threads = []</div><div class="line">    for i in range(4):</div><div class="line">        t = threading.Thread(target = job, args = (copy.copy(l), q), name = &apos;T%i&apos; % i)</div><div class="line">        t.start()</div><div class="line">        threads.append(t)</div><div class="line">    [t.join() for t in threads]</div><div class="line">    total = 0</div><div class="line">    for _ in range(4):</div><div class="line">        total += q.get()</div><div class="line">    print(total)</div><div class="line">    </div><div class="line">def normal(l):</div><div class="line">    total = sum(l)</div><div class="line">    print(total)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    l = list(range(1000000))</div><div class="line">    current_time = time.time()</div><div class="line">    normal(l*4)</div><div class="line">    print(&apos;MSG : normal time: &apos;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multi(l)</div><div class="line">    print(&apos;MSG : multithreading time: &apos;, time.time() - current_time)</div></pre></td></tr></table></figure>
<h2 id="Lock-example-Squential-operation-multi-thread"><a href="#Lock-example-Squential-operation-multi-thread" class="headerlink" title="Lock example(Squential operation multi-thread)"></a>Lock example(Squential operation multi-thread)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"># ********Lock********:</div><div class="line">imort threading</div><div class="line"></div><div class="line">def job1():</div><div class="line">    global A, lock</div><div class="line">    lock.acquire()</div><div class="line">    for i in range(10):</div><div class="line">        A += 1</div><div class="line">        print(&apos;MSG : job1 &apos;, A)</div><div class="line">    lock.release()</div><div class="line">    </div><div class="line">def job2():</div><div class="line">    global A, lock</div><div class="line">    lock.acquire()</div><div class="line">    for i in range(10):</div><div class="line">        A += 10</div><div class="line">        print(&apos;MSG : job2 &apos;, A)</div><div class="line">    lock.release()</div><div class="line">        </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    lock = threading.Lock()</div><div class="line">    A = 0</div><div class="line">    t1 = threading.Thread(target = job1)</div><div class="line">    t2 = threading.Thread(target = job2)</div><div class="line">    t1.start()</div><div class="line">    t2.start()</div><div class="line">    t1.join()</div><div class="line">    t2.join()</div></pre></td></tr></table></figure>
<h1 id="Multiprocessing"><a href="#Multiprocessing" class="headerlink" title="Multiprocessing"></a>Multiprocessing</h1><h2 id="Create-a-process"><a href="#Create-a-process" class="headerlink" title="Create a process"></a>Create a process</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># ********Extend********:</div><div class="line">import multiprocessing as mp</div><div class="line">import threading as td</div><div class="line"></div><div class="line">def job(a, b):</div><div class="line">    print(a + b)</div><div class="line"></div><div class="line"># processing must run in __main__</div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    new_process = mp.Process(target = job, args = (1, 2))</div><div class="line">    new_process.start()</div><div class="line">    new_process.join()</div></pre></td></tr></table></figure>
<h2 id="Example-of-queue-using-in-processing"><a href="#Example-of-queue-using-in-processing" class="headerlink" title="Example of queue using in processing:"></a>Example of queue using in processing:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># ********Queue********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">def job(q):</div><div class="line">    result = 0</div><div class="line">    for i in range(1000):</div><div class="line">        result += i + i ** 2 + i ** 3</div><div class="line">    # return (result)</div><div class="line">    q.put(result)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    q = mp.Queue()</div><div class="line">    # Don&apos;t forget the &apos;,&apos; after args while the number of parameter is one</div><div class="line">    p1 = mp.Process(target = job, args = (q, ))</div><div class="line">    p2 = mp.Process(target = job, args = (q, ))</div><div class="line">    p1.start()</div><div class="line">    p2.start()</div><div class="line">    p1.join()</div><div class="line">    p2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(result1 + result2)</div></pre></td></tr></table></figure>
<h2 id="Efficiency-Comparison-normal-multithreading-multiprocessing"><a href="#Efficiency-Comparison-normal-multithreading-multiprocessing" class="headerlink" title="Efficiency Comparison(normal, multithreading, multiprocessing)"></a>Efficiency Comparison(normal, multithreading, multiprocessing)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"># ********Efficiency Comparison********:</div><div class="line">import multiprocessing as mp</div><div class="line">import threading as td</div><div class="line">from queue import Queue</div><div class="line">import time</div><div class="line"></div><div class="line">def job(q):</div><div class="line">    result = 0</div><div class="line">    for i in range(100000):</div><div class="line">        result += i + i ** 2 + i ** 3</div><div class="line">    # return (result)</div><div class="line">    q.put(result)</div><div class="line">    </div><div class="line">def normal():</div><div class="line">    result = 0</div><div class="line">    for _ in range(2):</div><div class="line">        for i in range(100000):</div><div class="line">            result += i + i ** 2 + i ** 3</div><div class="line">    print(&apos;MSG : normal &apos;, result)</div><div class="line">    </div><div class="line">def multiprocess():</div><div class="line">    q = mp.Queue()</div><div class="line">    p1 = mp.Process(target = job, args = (q, ))</div><div class="line">    p2 = mp.Process(target = job, args = (q, ))</div><div class="line">    p1.start()</div><div class="line">    p1.join()</div><div class="line">    p2.start()</div><div class="line">    p2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(&quot;MSG : Processing &quot;, result1 + result2)</div><div class="line">    </div><div class="line">def multithread():</div><div class="line">    q = Queue()</div><div class="line">    t1 = td.Thread(target = job, args = (q, ))</div><div class="line">    t2 = td.Thread(target = job, args = (q, ))</div><div class="line">    t1.start()</div><div class="line">    t2.start()</div><div class="line">    t1.join()</div><div class="line">    t2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(&quot;MSG : Threading &quot;, result1 + result2)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    current_time = time.time()</div><div class="line">    normal()</div><div class="line">    print(&quot;MSG : normal time: &quot;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multithread()</div><div class="line">    print(&quot;MSG : multithread time: &quot;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multiprocess()</div><div class="line">    print(&quot;MSG : multiprocess time: &quot;, time.time() - current_time )</div></pre></td></tr></table></figure>
<h2 id="Processing-Pool"><a href="#Processing-Pool" class="headerlink" title="Processing Pool"></a>Processing Pool</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"># ********Pool********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">def job(x):</div><div class="line">    return x * x</div><div class="line"></div><div class="line">def multiprocess():</div><div class="line">    pool = mp.Pool(processes = 3)</div><div class="line">    # type = &apos;list&apos;</div><div class="line">    result = pool.map(job, range(10))</div><div class="line">    print(result)</div><div class="line">    # type = &apos;int&apos; </div><div class="line">    result = pool.apply_async(job, (2, ))</div><div class="line">    print(result.get())</div><div class="line">    # Note: pool.apply_async can only input one number for iterating</div><div class="line">    # type = &apos;object&apos;</div><div class="line">    multi_result = [pool.apply_async(job,(i, )) for i in range(10)]</div><div class="line">    print([result.get() for result in multi_result])</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multiprocess()</div></pre></td></tr></table></figure>
<h2 id="Shared-memory"><a href="#Shared-memory" class="headerlink" title="Shared memory"></a>Shared memory</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># ********Shared memory********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">value = mp.Value(&apos;d&apos;, 1)</div><div class="line"># can be only one dimension</div><div class="line">array = mp.Array(&apos;i&apos;, [1,2,3])</div><div class="line"># Value and Array can be share among multiple cores</div></pre></td></tr></table></figure>
<h2 id="Lock-example-avoid-different-cores-processing-out-of-order-with-shared-variable"><a href="#Lock-example-avoid-different-cores-processing-out-of-order-with-shared-variable" class="headerlink" title="Lock example(avoid different cores processing out of order with shared variable)"></a>Lock example(avoid different cores processing out of order with shared variable)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># ********Lock********:</div><div class="line">import multiprocessing as mp</div><div class="line">import time</div><div class="line"></div><div class="line">def job(v, num, l):</div><div class="line">    l.acquire()</div><div class="line">    for _ in range(10):</div><div class="line">        time.sleep(0.1)</div><div class="line">        v.value += num</div><div class="line">        print(v.value)</div><div class="line">    l.release()</div><div class="line"></div><div class="line">def multiprocess():</div><div class="line">    l = mp.Lock()</div><div class="line">    v = mp.Value(&apos;i&apos;, 0)</div><div class="line">    p1 = mp.Process(target = job, args = (v, 1, l))</div><div class="line">    p2 = mp.Process(target = job, args = (v, 3, l))</div><div class="line">    p1.start()</div><div class="line">    p2.start()</div><div class="line">    p1.join()</div><div class="line">    p2.join()</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multiprocess()</div></pre></td></tr></table></figure>
<h1 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h1><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><h3 id="Numpy-Foundation"><a href="#Numpy-Foundation" class="headerlink" title="Numpy Foundation"></a>Numpy Foundation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Foundation********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">array = np.array([[1,2,3],[2,3,4]])</div><div class="line">print(array)</div><div class="line">print(&quot;MSG : number of dims= &quot;, array.ndim)</div><div class="line"># If only have one dimension, shape will be (num, ) which represent it can be iterated</div><div class="line">print(&quot;MSG : shape= &quot;, array.shape)</div><div class="line">print(&quot;MSG : size= &quot;, array.size)</div></pre></td></tr></table></figure>
<h3 id="Numpy-Array"><a href="#Numpy-Array" class="headerlink" title="Numpy Array"></a>Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.array([[2,3,4], [5,6,7]], dtype = np.int)</div><div class="line">print(a.dtype)</div><div class="line"></div><div class="line">b = np.zeros((3, 4), dtype = np.int32)</div><div class="line">print(b)</div><div class="line"></div><div class="line">c = np.ones((3, 4), dtype = np.int32)</div><div class="line">print(c)</div><div class="line"></div><div class="line"># The output is a list of numbers that are approximate to zero </div><div class="line">d = np.empty((3, 4), dtype = np.int32)</div><div class="line">print(d)</div><div class="line"></div><div class="line">e = np.arange(10, 20, 2)</div><div class="line">f = np.arange(12).reshape((3,4))</div><div class="line">print(e)</div><div class="line">print(f)</div><div class="line"></div><div class="line">g = np.linspace(1, 10, 20)</div><div class="line">print(g)</div></pre></td></tr></table></figure>
<h3 id="Some-Useful-Numpy-Calculation-Formula"><a href="#Some-Useful-Numpy-Calculation-Formula" class="headerlink" title="Some Useful Numpy Calculation Formula"></a>Some Useful Numpy Calculation Formula</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Calculation********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.array([10, 20, 30, 40])</div><div class="line">b = np.arange(4)</div><div class="line">c = a - b</div><div class="line"># Output list composed of int numbers</div><div class="line">print(c)</div><div class="line"># Output list composed of boolean elements</div><div class="line">print(b &lt; 3)</div><div class="line">np.dot(a, b)</div><div class="line">rd = np.arange(2, 6)</div><div class="line"># Output has 2 dimensions(0 -&gt; col; 1 -&gt; row)</div><div class="line">np.sum(rd, axis = 1)</div><div class="line">np.min(rd, axis = 0)</div><div class="line">np.max(rd)</div><div class="line">np.argmin(rd)</div><div class="line">np.mean(rd)</div><div class="line">np.average(rd)</div><div class="line">np.median(rd)</div><div class="line"># Output is [2, 5, 9, 14]</div><div class="line">np.cumsum(rd)</div><div class="line"># Output is [1, 1, 1]</div><div class="line">np.diff(rd)</div><div class="line"># Output composed of multi-dimensional array representing  the row and col number of all nonzero elements in rd array respectively</div><div class="line">np.nonzero(rd)</div><div class="line"># sort among each dimensions independent</div><div class="line">np.sort(rd)</div><div class="line">np.sort(rd.reshape((2, 2)))</div><div class="line"># transpose also we can use rd.T to transpose directly</div><div class="line">np.transpose(rd)</div><div class="line"># matrix multiplication</div><div class="line">(rd.T).dot(rd)</div><div class="line">np.clip(rd, 2, 4)</div><div class="line"># Note: we can use axis to choose 0 -&gt; col or 1 -&gt; row as the target for calculation</div></pre></td></tr></table></figure>
<h3 id="Search-From-Numpy-Array"><a href="#Search-From-Numpy-Array" class="headerlink" title="Search From Numpy Array"></a>Search From Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Index Search********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.arange(3, 15).reshape((3, 4))</div><div class="line">A[2] # Output is [11, 12, 13, 14]</div><div class="line">A[2][1] </div><div class="line"># the same as</div><div class="line">A[1, 2]</div><div class="line">A[:, 1]</div><div class="line">A[1, 1:2]</div><div class="line">for row in A:</div><div class="line">    print(row)</div><div class="line"># Trick</div><div class="line">for colume in A.T:</div><div class="line">    print(colume)</div><div class="line"># flat function parse elements from A like a generator</div><div class="line"># Note: A.flat is different from A.flatten()</div><div class="line"># pre-one is an object and the next output a list</div><div class="line">for item in A.flat:</div><div class="line">    print(item)</div></pre></td></tr></table></figure>
<h3 id="Merge-Numpy-Array"><a href="#Merge-Numpy-Array" class="headerlink" title="Merge Numpy Array"></a>Merge Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># ********Merge Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.array([1, 1, 1])</div><div class="line">B = np.array([2, 2, 2])</div><div class="line"># vertical stack with output [[1, 1, 1], [2, 2, 2]]</div><div class="line">C = np.vstack((A, B))</div><div class="line">print(A.shape, C.shape)</div><div class="line"># Horizontal stack with with output [1, 1, 1, 2, 2, 2]</div><div class="line">D = np.hstack((A, B))</div><div class="line"># Note: transpose function can not convert shape(3,) into shape(,3)</div><div class="line">A_ = A[:, np.newaxis]) # newaxis is an extend dimension</div><div class="line"># If we want to get output by merge col-values like [[1, 2], [1, 2], [1, 2]] we can use:</div><div class="line">E = np.hstack((A[:, np.newaxis], B[:, np.newaxis]))</div><div class="line"># the same as:</div><div class="line">F = np.concatenate((A_, A_), axis = 1)</div><div class="line"># Note: np.concatenate((A, B), axis = 1) will shuffle an error because concatenate will reduce dimension when mergement operation happened, and A or B only have one dimension</div></pre></td></tr></table></figure>
<h3 id="Split-Numpy-Array"><a href="#Split-Numpy-Array" class="headerlink" title="Split Numpy Array"></a>Split Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Split Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.arange(12).reshape((3, 4))</div><div class="line"># every pieces should have the same length</div><div class="line">np.split(A, 2, axis = 1)</div><div class="line"># If you want to split into pieces that in different size</div><div class="line"># Binary split from left to right</div><div class="line">np.array_split(A, 3, axis = 1)</div><div class="line"># Vertical split</div><div class="line">np.vsplit(A, 3)</div><div class="line"># Horizontal split</div><div class="line">np.hsplit(A, 2)</div></pre></td></tr></table></figure>
<h3 id="Numpy-Array-Copy"><a href="#Numpy-Array-Copy" class="headerlink" title="Numpy Array Copy"></a>Numpy Array Copy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Array Copy********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.arange(4, dtype = np.float32)</div><div class="line">b = a</div><div class="line">c = a</div><div class="line">d = b</div><div class="line">a[0] = 0.3</div><div class="line"># now a = b = c = d = [0.30000001, 1., 2., 3.]</div><div class="line">b is a # result is True</div><div class="line"># Note: copy object connected with point</div><div class="line">b = a.copy() # deep copy</div><div class="line"># or</div><div class="line">import copy</div><div class="line">b = copy.copy(a)</div><div class="line">a is b # result is False</div></pre></td></tr></table></figure>
<h2 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h2><h3 id="Pandas-Foundation"><a href="#Pandas-Foundation" class="headerlink" title="Pandas Foundation"></a>Pandas Foundation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Data Representation********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">s = pd.Series([1, 3, 6, np.nan, 44, 1])</div><div class="line">dates = pd.date_range(&apos;20170101&apos;, periods = 6)</div><div class="line">df = pd.DataFrame(np.random.randn(6, 4), index = dates, columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df1 = pd.DataFrame(np.arange(12).reshape((3, 4)))</div><div class="line">df2 = pd.DataFrame(&#123;&apos;A&apos;: 1., &apos;B&apos;: pd.Timestamp(&apos;20130102&apos;), &apos;C&apos;: pd.Series(1, index = list(range(4)), dtype = &apos;float32&apos;), &apos;D&apos;: np.array([3] * 4, dtype = &apos;int32&apos;), &apos;E&apos;: pd.Categorical([&apos;test&apos;, &apos;train&apos;, &apos;test&apos;, &apos;train&apos;]), &apos;F&apos;: &apos;foo&apos;&#125;)</div><div class="line">print(df2.dtypes)</div><div class="line">print(df2.index)</div><div class="line">print(df2.columns)</div><div class="line">print(df2.values)</div><div class="line"># Only fit to number elements</div><div class="line">print(df2.describe()) # result index includes count, mean, std, min, 25%, 50%, 75%, max...</div><div class="line">print(df2.T)</div><div class="line"># Sort for columns</div><div class="line">print(df2.sort_index(axis = 1, ascending = False))</div><div class="line"># Sort for column values</div><div class="line">print(df2.sort_values(by = &apos;E&apos;))</div></pre></td></tr></table></figure>
<h3 id="Pandas-Data-Sampling"><a href="#Pandas-Data-Sampling" class="headerlink" title="Pandas Data Sampling"></a>Pandas Data Sampling</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Data Sampling********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">print(df[&apos;A&apos;]) </div><div class="line"># the same as :</div><div class="line">print(df.A)</div><div class="line">print(df[0: 3], &apos;\n&apos;, df[&apos;20130101&apos;: &apos;20130103&apos;])</div><div class="line"># select by label:</div><div class="line">print(df.loc[&apos;20130102&apos;])</div><div class="line">print(df.loc[&apos;20130102&apos;, [&apos;A&apos;, &apos;B&apos;]])</div><div class="line"># select by position:</div><div class="line">print(df.iloc[3, 1])</div><div class="line">print(df.iloc[[1, 3, 5], 1: 3])</div><div class="line"># mixed selection:</div><div class="line">print(df.ix[:3, [&apos;A&apos;, &apos;C&apos;]])</div><div class="line"># Boolean indexing selection:</div><div class="line">print(df[df.A &gt; 8])</div><div class="line"># multi-conditions(Can not use &apos;and&apos;):</div><div class="line">print(df[df[2] &gt; 3][df[1] &lt; 2])</div></pre></td></tr></table></figure>
<h3 id="Pandas-Value-Config"><a href="#Pandas-Value-Config" class="headerlink" title="Pandas Value Config"></a>Pandas Value Config</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># ********Pandas change value********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">df.iloc[2, 2] = 1111</div><div class="line">df.loc[&apos;20130101&apos;, &apos;B&apos;] = 2222</div><div class="line">df[df[&apos;A&apos;] &gt; 0] = 0</div><div class="line"># add a new column</div><div class="line">df[&apos;F&apos;] = np.nan</div><div class="line">df[&apos;E&apos;] = pd.Series(np.arange(6, dtype = np.int32)+1, index = pd.date_range(&apos;20130101&apos;, periods = 6))</div></pre></td></tr></table></figure>
<h3 id="Pandas-Handling-Nan"><a href="#Pandas-Handling-Nan" class="headerlink" title="Pandas Handling Nan"></a>Pandas Handling Nan</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Pandas NaN********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">df.iloc[0, 1] = np.nan</div><div class="line">df.iloc[1, 2] = np.nan</div><div class="line"># &apos;any&apos; means we drop the row as long as nan exist, &apos;all&apos; means we drop the row if all the elements are nan</div><div class="line">print(df.dropna(axis = 0, how = &apos;any&apos;)) # how = &#123;&apos;any&apos;, &apos;all&apos;&#125;</div><div class="line">print(df.drop(&apos;A&apos;, axis = 1))</div><div class="line"># replace nan</div><div class="line">print(df.fillna(value = 0))</div><div class="line">print(df.isnull()) # result is a dictionary with &apos;True&apos; and &apos;False&apos;</div><div class="line">print(np.any(df.isnull()) == True)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Read-and-Write"><a href="#Pandas-Read-and-Write" class="headerlink" title="Pandas Read and Write"></a>Pandas Read and Write</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Read and Write********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line"># Some useful function like: read_csv, read_excel, read_sql, read_json ...</div><div class="line"></div><div class="line">df = pd.read_csv(&apos;Sample.csv&apos;, &apos;r&apos;)</div><div class="line"># Sample.csv</div><div class="line"># A,B,C,D</div><div class="line"># 0,1,2,3</div><div class="line"># 4,5,6,7</div><div class="line"># 8,9,10,11</div><div class="line"></div><div class="line"># Save as pickle file</div><div class="line">df.to_pickle(&apos;Sample.pickle&apos;)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Concatenating"><a href="#Pandas-Concatenating" class="headerlink" title="Pandas Concatenating"></a>Pandas Concatenating</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Concatenating********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">df1 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df2 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df3 = pd.DataFrame(np.ones((3, 4))*2, columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line"># ignore_index will reset the index from top to bottom</div><div class="line">result1 = pd.concat([df1, df2, df3], axis = 0, ignore_index = True)</div><div class="line"></div><div class="line"># concat-join, [&apos;inner&apos;, &apos;outer&apos;]</div><div class="line">df4 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;], index = [1, 2, 3])</div><div class="line">df5 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], index = [2, 3, 4])</div><div class="line"># use NaN as the default value</div><div class="line">result2 = pd.concat([df4, df5], ignore_index = True, join = &apos;inner&apos;) # &apos;inner&apos; only remain the same parts</div><div class="line"></div><div class="line"># concat-join_axes</div><div class="line">result3 = pd.concat([df4, df5], axis = 1, join_axes = [df4.index]) # result&apos;s index is only the index of df4</div><div class="line"></div><div class="line"># append</div><div class="line">df6 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df7 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df8 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], index = [2, 3, 4])</div><div class="line">result4 = df6.append(df7, ignore_index = True)</div><div class="line">result5 = df6.append([df7, df8])</div><div class="line">s1 = pd.Series([1, 2, 3, 4], index = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">result6 = df6.append(s1, ignore_index = True)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Merge-concat-without-the-same-parts"><a href="#Pandas-Merge-concat-without-the-same-parts" class="headerlink" title="Pandas Merge(concat without the same parts)"></a>Pandas Merge(concat without the same parts)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Merge********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line"># merge by index named &apos;key&apos;(may be used in database)</div><div class="line">df1 = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;key&apos;) # we have to make sure these two frames contain the same index named &apos;key&apos;</div><div class="line"></div><div class="line"># consider two keys</div><div class="line">df1 = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K0&apos;, &apos;K1&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)</div><div class="line"># default join = &apos;inner&apos;</div><div class="line">result = pd.merge(df1, df2, on = [&apos;key1&apos;, &apos;key2&apos;])</div><div class="line">result2 = pd.merge(df1, df2, on = [&apos;key1&apos;, &apos;key2&apos;], how = &apos;outer&apos;) # how = &#123;&apos;left&apos;, &apos;right&apos;, &apos;outer&apos;, &apos;inner&apos;&#125;</div><div class="line"></div><div class="line"># consider indicator(detail of merge)</div><div class="line">df1 = pd.DataFrame(&#123;&apos;col1&apos;: [0, 1], &apos;col_left&apos;: [&apos;a&apos;, &apos;b&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;col1&apos;: [1, 2, 2], &apos;col_right&apos;: [2, 2, 2]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;col1&apos;, how = &apos;outer&apos;, indicator = True)</div><div class="line">result1 = pd.merge(df1, df2, on = &apos;col1&apos;, how = &apos;outer&apos;, indicator = &apos;indicator_column&apos;) # rename &apos;indicator&apos;</div><div class="line"></div><div class="line"># merged by index</div><div class="line">df1 = pd.DataFrame(&#123;&apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;]&#125;, index = [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;])</div><div class="line">df2 = pd.DataFrame(&#123;&apos;C&apos;: [&apos;C0&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;, index = [&apos;K0&apos;, &apos;K2&apos;, &apos;K3&apos;])</div><div class="line">result = pd.merge(df1, df2, left_index = True, right_index = True, how = &apos;outer&apos;)</div><div class="line">result1 = pd.merge(df1, df2, left_index = True, right_index = True, how = &apos;outer&apos;)</div><div class="line"></div><div class="line"># handle overlapping</div><div class="line">df1 = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;age&apos;: [1, 2, 3]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K3&apos;], &apos;age&apos;: [4, 5, 6]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;k&apos;, suffixes = [&apos;_boy&apos;, &apos;_girl&apos;], how = &apos;inner&apos;)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Plot-View"><a href="#Pandas-Plot-View" class="headerlink" title="Pandas Plot(View)"></a>Pandas Plot(View)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Plot********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line">import matplotlib.pyplot as plt</div><div class="line"></div><div class="line"># Series</div><div class="line">data = pd.Series(np.random.randn(1000), index = np.arange(1000))</div><div class="line">data = data.cumsum()</div><div class="line"># plt.plot(x = horizontal_value1, y = vertical_value)</div><div class="line">data.plot()</div><div class="line">plt.show()</div><div class="line"></div><div class="line"># DataFrame</div><div class="line">data = pd.DataFrame(np.random.randn(1000).reshape((250, 4)), index = np.arange(250), columns = list((&quot;ABCD&quot;)))</div><div class="line">data = data.cumsum()</div><div class="line">data.plot()</div><div class="line">plt.show()</div><div class="line"></div><div class="line"># scatter -&gt; plt.scatter(x = .., y = ..)</div><div class="line"># plot methods = &#123;&apos;bar&apos;, &apos;hist&apos;, &apos;box&apos;, &apos;kde&apos;, &apos;area&apos;, &apos;scatter&apos;, &apos;hexbin&apos;, &apos;pie&apos;&#125;</div><div class="line">a = data.plot.scatter(x = &apos;A&apos;, y = &apos;B&apos;, color = &apos;DarkBlue&apos;, label = &apos;Class 1&apos;) # only can hold 2 elements</div><div class="line">data.plot.scatter(x = &apos;A&apos;, y = &apos;C&apos;, color = &apos;DarkGreen&apos;, label = &apos;Class 2&apos;, ax = a)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><h2 id="Matplotlib-Foundation"><a href="#Matplotlib-Foundation" class="headerlink" title="Matplotlib Foundation"></a>Matplotlib Foundation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Foundation********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-1, 1, 50)</div><div class="line">y = x * 2 + 1</div><div class="line">plt.plot(x, y)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Figure"><a href="#Matplotlib-Figure" class="headerlink" title="Matplotlib Figure"></a>Matplotlib Figure</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Figure********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.plot(x, y1)</div><div class="line">plt.figure(num = 3, figsize = (8, 5))</div><div class="line">plt.plot(x, y1)</div><div class="line">plt.plot(x, y2, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Setting"><a href="#Matplotlib-Setting" class="headerlink" title="Matplotlib Setting"></a>Matplotlib Setting</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Setting********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.plot(x, y2)</div><div class="line">plt.plot(x, y1, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;)</div><div class="line">plt.xlim((-1, 2))</div><div class="line">plt.ylim((-2, 3))</div><div class="line">plt.xlabel(&apos;I am X&apos;)</div><div class="line">plt.ylabel(&apos;I am Y&apos;)</div><div class="line">new_ticks = np.linspace(-1, 2, 5) # steps</div><div class="line">plt.xticks(new_ticks)</div><div class="line">plt.yticks([-2, -1.8, 0, 1.22, 3], [r&apos;$really\ bad$&apos;, r&apos;$bad$&apos;, r&apos;$normal$&apos;, r&apos;$good$&apos;, r&apos;$really\ good$&apos;]) # alpha need write as &apos;\alpha&apos;</div><div class="line"></div><div class="line"># gca = &apos;get current axis&apos;</div><div class="line">ax = plt.gca()</div><div class="line">ax.spines[&apos;right&apos;].set_color(&apos;none&apos;) # right side of boundarys</div><div class="line">ax.spines[&apos;top&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.xaxis.set_ticks_position(&apos;bottom&apos;)</div><div class="line">ax.yaxis.set_ticks_position(&apos;left&apos;)</div><div class="line">ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;, 0)) # &apos;data&apos; can set to &apos;outward&apos; , &apos;axes&apos;... </div><div class="line">ax.spines[&apos;left&apos;].set_position((&apos;data&apos;, 0))</div><div class="line"></div><div class="line"># Legend</div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.xlim((-1, 2))</div><div class="line">plt.ylim((-2, 3))</div><div class="line">plt.xlabel(&apos;I am X&apos;)</div><div class="line">plt.ylabel(&apos;I am Y&apos;)</div><div class="line">new_ticks = np.linspace(-1, 2, 5) # steps</div><div class="line">plt.xticks(new_ticks)</div><div class="line">plt.yticks([-2, -1.8, 0, 1.22, 3], [r&apos;$really\ bad$&apos;, r&apos;$bad$&apos;, r&apos;$normal$&apos;, r&apos;$good$&apos;, r&apos;$really\ good$&apos;]) # alpha need write as &apos;\alpha&apos;</div><div class="line">l1, = plt.plot(x, y2, label = &apos;up&apos;) # Don&apos;t forget &apos;,&apos;</div><div class="line">l2, = plt.plot(x, y1, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;, label = &apos;down&apos;)</div><div class="line">plt.legend(handles = [l1, l2], labels = [&apos;line 1&apos;, &apos;line 2&apos;], loc = &apos;best&apos;) # loc = &#123;&apos;best&apos;, &apos;upper&apos;, &apos;lower right&apos;, &apos;center&apos;...&#125;</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Annotation"><a href="#Matplotlib-Annotation" class="headerlink" title="Matplotlib Annotation"></a>Matplotlib Annotation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Annotation********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y = 2 * x + 1</div><div class="line">plt.figure(num = 1, figsize = (8, 5))</div><div class="line">plt.plot(x, y)</div><div class="line">ax = plt.gca()</div><div class="line">ax.spines[&apos;right&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.spines[&apos;top&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.xaxis.set_ticks_position(&apos;bottom&apos;)</div><div class="line">ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;, 0))</div><div class="line">ax.yaxis.set_ticks_position(&apos;left&apos;)</div><div class="line">ax.spines[&apos;left&apos;].set_position((&apos;data&apos;, 0))</div><div class="line"></div><div class="line">X0 = 1</div><div class="line">Y0 = 2 * X0 + 1</div><div class="line"># Point</div><div class="line">plt.scatter(X0, Y0, s = 50, color = &apos;b&apos;)</div><div class="line"># Line</div><div class="line">plt.plot([X0, X0], [Y0, 0], &apos;k--&apos;, lw = 2.5)</div><div class="line"># Choice one</div><div class="line">plt.annotate(r&apos;$2x+1=%s$&apos; % Y0, xy = (X0, Y0), xycoords = &apos;data&apos;, xytext = (+30, -30), textcoords = &apos;offset points&apos;, fontsize = 16, arrowprops = dict(arrowstyle = &apos;-&gt;&apos;, connectionstyle = &apos;arc3, rad = .2&apos;))</div><div class="line"># Choice two</div><div class="line">plt.text(-3.7, 3, r&apos;$This\ is\ some\ text.\ \mu\ \sigma_i\ \alpha_t$&apos;, fontdict = &#123;&apos;size&apos;: 16, &apos;color&apos;: &apos;r&apos;&#125;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords:"></a>Keywords:</h1><p>Tags: <code>Python</code> <code>Numpy</code> <code>Pandas</code> <code>Matplotlib</code> </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Foundation-Summary&quot;&gt;&lt;a href=&quot;#Foundation-Summary&quot; class=&quot;headerlink&quot; title=&quot;Foundation Summary&quot;&gt;&lt;/a&gt;Foundation Summary&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Numpy" scheme="http://yoursite.com/tags/Numpy/"/>
    
      <category term="Pandas" scheme="http://yoursite.com/tags/Pandas/"/>
    
      <category term="Matplotlib" scheme="http://yoursite.com/tags/Matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>利用LSTM模型进行手写识别</title>
    <link href="http://yoursite.com/2017/07/25/RNN/"/>
    <id>http://yoursite.com/2017/07/25/RNN/</id>
    <published>2017-07-25T04:03:41.000Z</published>
    <updated>2017-07-25T04:08:11.421Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Recurrent-Neural-Netword-RNN-Using-Tensorflow"><a href="#Recurrent-Neural-Netword-RNN-Using-Tensorflow" class="headerlink" title="Recurrent Neural Netword(RNN) Using Tensorflow"></a>Recurrent Neural Netword(RNN) Using Tensorflow</h1><h1 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>MNIST database of handwritten digits. <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">Click here</a><br>Input data: Image shape(28*28)<br>Output label: 0~9 </p>
<h2 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h2><ul>
<li>Data_Size<ul>
<li><code>Input_dimension</code>: Dimension of each image</li>
<li><code>Output_dimension</code>: Dimension of predicted label</li>
<li><code>Classes</code>: The number of different outputs</li>
</ul>
</li>
<li>Model_Parameter<ul>
<li><code>Training_iter</code>: The number of iterations for training</li>
<li><code>Batch_size</code>: The length of inputeach epoch</li>
</ul>
</li>
</ul>
<h2 id="Requirement"><a href="#Requirement" class="headerlink" title="Requirement"></a>Requirement</h2><ul>
<li><code>Python 2.7</code></li>
<li><code>Tensorflow 0.12.1</code></li>
</ul>
<h1 id="Model-RNN-LSTM"><a href="#Model-RNN-LSTM" class="headerlink" title="Model(RNN + LSTM)"></a>Model(RNN + LSTM)</h1><p>We use a Recurrent Neural Network with <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">LSTM</a> Cell to implement this model.</p>
<ul>
<li>LSTM (Long Short Term Memory):</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="http://upload-images.jianshu.io/upload_images/42741-b9a16a53d58ca2b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="LSTM_MODEL" title="">
                </div>
                <div class="image-caption">LSTM_MODEL</div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://json0071.gitbooks.io/deeplearning/content/LSTM.png" alt="LSTM" title="">
                </div>
                <div class="image-caption">LSTM</div>
            </figure>
<p>LSTM Composed of three gates which called INPUT_GATE, FORGET_GATE and OUTPUT_GATE.</p>
<p>More information about how to implement LSTM Model is <a href="https://www.tensorflow.org/tutorials/recurrent" target="_blank" rel="external">here</a>.</p>
<ul>
<li><strong>Initialize Step</strong></li>
</ul>
<p>First we should initialize the placeholder and weights of our neural network.<br><code>placeholder</code>: just like the <strong>x</strong> of the function:<br>$$<br>f(x) = x^2<br>$$<br><code>weights</code>: the weight for converting input data to output label.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</div><div class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</div><div class="line"></div><div class="line">weights = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden, n_classes]))</div><div class="line">&#125;</div><div class="line">biases = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><strong>Training Step</strong></li>
</ul>
<p><strong>First</strong> we define a RNN_Model function.<br>Using linear relationship to combine the output parameters.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def RNN_Model(x, weights, biases):</div><div class="line">    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias = 1.0)</div><div class="line">    output, states = tf.nn.rnn(lstm_cell, x, dtype = tf.float32)</div><div class="line">    return tf.matmul(output[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]</div></pre></td></tr></table></figure>
<p><strong>Second</strong> we have to define the loss function and optmizer of our model.<br><code>loss fuction</code>: softmax_cross_entropy<br><code>optimizer</code>: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">prediction = RNN_Model(x, weights, biases)</div><div class="line">result = tf.nn.softmax(prediction)</div><div class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))</div><div class="line">optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)</div></pre></td></tr></table></figure>
<p><strong>Third</strong> in order to evaluate the efficiency of this model, we define the function to calculate accuracy.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> we can start training after all the initialization.</p>
<ul>
<li>We can use session to run our tensorflow function.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    sess.run(init)</div><div class="line">    while &quot;./epoch&quot; &lt; training_iters</div><div class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">        batch_x = batch_x.reshape((batch_size, n_steps, n_input))</div><div class="line">        sess.run(optimizer, feed_dict = &#123;x: batch_x, y: batch_y&#125;</div><div class="line">        if &quot;./batch_size&quot;:</div><div class="line">            acc = sess.run(accuracy, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div><div class="line">            los = sess.run(loss, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div></pre></td></tr></table></figure>
<p><strong>Tips</strong>: “./“ represent the parameters defined by user own.</p>
<ul>
<li><strong>Testing Step</strong></li>
</ul>
<p>After training we get a weights in the tensorflow session which can be used to predict our test data.</p>
<p><strong>First</strong> generate the testing dataset from mnist generator.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">test_data = mnist.test.images[:&quot;./test_length&quot;].reshape(-1, n_steps, n_input)</div><div class="line">res = sess.run(result, feed_dict = &#123;x: test_data&#125;)</div><div class="line">predict_label = sess.run(tf.argmax(res, 1))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> because tensorflow mnist test dataset have its own ground-truth. So we can estimate if our “predict_label” is correct. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">test_label = mnist.test.labels[:&quot;./test_lenght&quot;]</div><div class="line">sess.run(accuracy, feed_dict = &#123;x: predict_label, y: test_label&#125;)</div></pre></td></tr></table></figure>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><ol>
<li><p>Install tensorflow.</p>
<ul>
<li>If we will run our model on GPU we have to install cuda and cuDNN.<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install tensorflow(-gpu)==0.12.1</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Import tensorflow package.</p>
</li>
<li>Import tensorflow mnist dataset and read the dataset as a generator.</li>
<li>Run our model<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python &quot;./model_name&quot;.py</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples/" target="_blank" rel="external">Googel Tensorflow Example</a></li>
</ul>
<h1 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h1><p>In this experiment we use a simple RNN(LSTM) model to predict the handwritten digits which also catch a good consequence in CNN.<br>RNN model is good for using in NLP processing. But how to explore the most useful <strong>determines</strong> whether our model can get an excellent result or not.</p>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Machine Learning</code> <code>RNN</code> <code>LSTM</code> <code>Tensorflow</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot;&gt;&lt;a href=&quot;#Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;Re
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
      <category term="Tensorflow" scheme="http://yoursite.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04遠端桌面（remote desktop）設置</title>
    <link href="http://yoursite.com/2017/07/25/Remote/"/>
    <id>http://yoursite.com/2017/07/25/Remote/</id>
    <published>2017-07-25T04:00:24.000Z</published>
    <updated>2017-07-25T04:08:02.329Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Ubuntu上的遠端鏈接比起windows系統自帶的Remote Desktop需要配置的條件更多。網上也有許多不同的版本，本人嘗試之後發現了一些常見的問題，特在此總結可行的一般流程與常見問題的解決方式。</p>
<h1 id="System-Config"><a href="#System-Config" class="headerlink" title="System Config"></a>System Config</h1><p><code>Ubuntu16.04</code> <code>Windows 10</code></p>
<h1 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h1><p>1、如果需要從Ubuntu連接到Windows系統，則可以安裝Desktop</p>
<ul>
<li>sudo apt-get install ubuntu-desktop</li>
</ul>
<p>2、若只是從Windows鏈接到Ubuntu則跳過第一步，直接安裝遠端桌面軟體xrdp</p>
<ul>
<li><p>sudo apt-get install xrdp</p>
<ul>
<li>此時若打開xrdp的配置文件，可以看到默認的xrdp協定，遠 端桌面則是根據這個來請求遠端服務的。</li>
</ul>
</li>
<li>sudo vim /etc/xrdp/xrdp.ini</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1tOoyic.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>其中port = -1表示默認port(5910)作為登錄的接口，之後的連接可通過這個port連入相同的session（因為遠端連接的port一般可以兼容port5900到5910）如果需要更改連接的port可以在xrdp.ini文檔中修改port為port = ask59XX來請求連接。</li>
</ul>
<p>修改完畢後記得重啟xrdp：</p>
<ul>
<li>sudo service xrdp restart</li>
</ul>
<p>3、此時可以查看service port看是否處於LISTEN的狀態。</p>
<ul>
<li>netstat -utl</li>
</ul>
<p><strong>Important : 必須確保三個port處於監聽狀態</strong></p>
<ul>
<li>port 3389</li>
<li>port 3350</li>
<li>port 59XX</li>
</ul>
<p><img src="https://i.imgur.com/0BgAP4w.png" alt=""></p>
<p>4、確保Ubuntu系統安裝了vnc服務，大部分系統會自行安裝，可以通過重複安裝確認。</p>
<ul>
<li>sudo apt-get install vnc4server<br>或</li>
<li>sudo apt-get install tightvncserver</li>
</ul>
<p>5、由於xrdp會開放3389的port作為遠端圖形化界面的窗口，因此還需要有相應的圖形化桌面套件。<br><strong>Ubuntu常用的桌面套件有三種，選擇一種安裝即可</strong></p>
<ul>
<li>安裝與設定Xfce<ul>
<li>sudo apt install xfce4</li>
<li>echo “xfce4-session” &gt; ~/.xsession </li>
</ul>
</li>
<li>安裝與設定Lxde<ul>
<li>sudo apt install lxde</li>
<li>echo “lxsession -s LXDE -e LXDE” &gt; ~/.xession </li>
</ul>
</li>
<li>安裝與設定Mate<ul>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/ppa</li>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/trusty-mate</li>
<li>sudo apt update</li>
<li>sudo apt install –no-install-recommends ubuntu-mate-core ubuntu-mate-desktop</li>
<li>echo “mate-session” &gt; ~/.xsession</li>
</ul>
</li>
</ul>
<p>6、之後就可以使用遠端桌面連接Windows和Ubuntu了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PBsp6Sc.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>结果如下（Mate）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a1PmzMs.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Common-Problem"><a href="#Common-Problem" class="headerlink" title="Common Problem"></a>Common Problem</h2><ul>
<li>遠端連接出現error-problem connecting：<ul>
<li>通常是因為vnc服務沒有架好，查看port的監聽狀態（詳見步驟3），如果只有3389和3350沒有5910的情況，則需要手動開啟相應的port進行連接。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>vncserver : 1~9 (引號兩邊都需要空格)</li>
<li>在xrdp設定檔中將prot從-1改為ask剛才開啟的port（vncserver設1則開啟5901以此類推）</li>
</ul>
</li>
<li>遠端桌面連接進入出現灰色網格，無圖像，滑鼠變成X：<ul>
<li>出現這種狀況通常是沒有安裝遠端桌面套件，導致圖形化界面無法呈現。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>安裝三種遠端桌面套件的一種（詳見步驟5）</li>
</ul>
</li>
</ul>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Ubuntu</code> <code>Remote Desktop</code> <code>xrdp</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;Ubuntu上的遠端鏈接比起windows系統自帶的Remo
    
    </summary>
    
    
      <category term="Ubuntu" scheme="http://yoursite.com/tags/Ubuntu/"/>
    
      <category term="Remote Desktop" scheme="http://yoursite.com/tags/Remote-Desktop/"/>
    
      <category term="xrdp" scheme="http://yoursite.com/tags/xrdp/"/>
    
  </entry>
  
  <entry>
    <title>Python字符編碼問題</title>
    <link href="http://yoursite.com/2017/07/25/Unicode/"/>
    <id>http://yoursite.com/2017/07/25/Unicode/</id>
    <published>2017-07-25T03:52:58.000Z</published>
    <updated>2017-07-25T04:08:25.789Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是编码"><a href="#什么是编码" class="headerlink" title="什么是编码"></a>什么是编码</h1><p>字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編程語言中，我們經常會處理文本編碼之間的轉化問題，因為文本可能存在不同的編碼格式，例如 ASCII、GBK、UTF-8等等。最近在做NN的過程中面臨Corpus的unicode編碼問題，因此需要弄清楚python不同版本對編碼問題的處理策略。</p>
<h2 id="字符的抽象概念"><a href="#字符的抽象概念" class="headerlink" title="字符的抽象概念"></a>字符的抽象概念</h2><p>看了一些網絡上的介紹，發現我們所謂的字符表示文本中單一的一個符號。然而一個字符不是一個字節，例如 “中” 這個字在文本中是一個基礎字符，但是在計算機中卻不是一個字節。一個字符有許多表示方法，不同的表示方法會使用不同的字節數，這就是所謂的編碼。<strong>字符就是文本中的最小單元</strong>。</p>
<h2 id="編碼的方式"><a href="#編碼的方式" class="headerlink" title="編碼的方式"></a>編碼的方式</h2><p>Unicode是一種編碼規範，用來統一表示世界上的各種語言。其作為Python語言中的一種中間轉換碼，如果要對不同編碼格式的文本進行轉換，就必須對字符串解碼（decode）成Unicode，再從Unicode編碼（encode）成另一種編碼格式：</p>
<p><code>decode</code> : 作用是將編碼的字符串轉換成Unicode。<br><code>encode</code> : 作用是將Unicode傳換成其他編碼格式。</p>
<h1 id="Python2-vs-Python3"><a href="#Python2-vs-Python3" class="headerlink" title="Python2 vs Python3"></a>Python2 vs Python3</h1><p>Python3的編碼形式默認為Unicode</p>
<ul>
<li>那麼Python3的文本可以通過encode傳換成bytes嗎？bytes和str一樣嗎？</li>
</ul>
<p>首先bytes不是字符串，那么b ‘a’ 和 ‘a’ 的区别是什么呢？在Python3运行输入出bytes的时候，它采取的原则是这样的：没读一个字节就和ascii码比对一下，如果符合ascii码的字符（特殊字符，字母和数字等除外），那这个字节就按照ascii码来表示，否则就按照十六进制‘\x’的形式来表示。</p>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ctGhV9P.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>因此bytes对象不能由超过0到127的ascii码范围的unicode字<br>符串表示。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8ou3vVE.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>bytes的表示方式为b + (字符串)，如果不用bytes表示，则直接用 ‘\x’ + 两位十六进制数表示一个字节。</p>
<ul>
<li>那么在Python2表示unicode的时候我们使用u + (字符串)的形式表示unicode编码，而Python3中则无需这么做。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2ji3C8E.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y2rtdQM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>注意在Python3中u‘字符串’和‘\u四位十六进制数’是等价的，而且都为str对象。而‘\u四位十六进制数’和‘\u四位十六进制数’却不相同。</li>
</ul>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RZD8Ptn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Python2</code> <code>Python3</code> <code>Unicode</code> <code>编码</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是编码&quot;&gt;&lt;a href=&quot;#什么是编码&quot; class=&quot;headerlink&quot; title=&quot;什么是编码&quot;&gt;&lt;/a&gt;什么是编码&lt;/h1&gt;&lt;p&gt;字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編
    
    </summary>
    
    
      <category term="Unicode" scheme="http://yoursite.com/tags/Unicode/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04如何安裝搜狗（Sogou）輸入法</title>
    <link href="http://yoursite.com/2017/07/25/Ubuntu-sogo/"/>
    <id>http://yoursite.com/2017/07/25/Ubuntu-sogo/</id>
    <published>2017-07-25T03:48:07.000Z</published>
    <updated>2017-07-25T04:08:20.329Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>目前Ubuntu常用的中文输入法有：</p>
<ul>
<li>搜狗拼音： 搜狗出品的面向Linux的输入法。</li>
<li>Fcitx： 这个是Ubuntu系统自带的Linux开源的输入法框架，提供了包括Google PinYin、ShuangPin、SunPinYin、Hong Kong和TaiWan繁体等一系列输入法。</li>
</ul>
<p>下面主要讲下如何在Ubuntu 16.04上安装搜狗输入法。</p>
<h2 id="安裝過程"><a href="#安裝過程" class="headerlink" title="安裝過程"></a>安裝過程</h2><p>下載安裝檔之前首先需要確認本機的Ubuntu系統是什麼樣的編碼位元。利用“uname -a”指令查詢系統資訊。</p>
<p>下載安裝包，sogou提供了32位和64位版本:<a href="http://pinyin.sogou.com/linux/?r=pinyin" target="_blank" rel="external">http://pinyin.sogou.com/linux/?r=pinyin</a></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/G7PoJFF.png" alt="Sogou" title="">
                </div>
                <div class="image-caption">Sogou</div>
            </figure>
<p>下載完成后可以直接雙擊下載的deb包裝或執行指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo dpkg -i sogoupinyin*.deb</div><div class="line">$ sudo apt -f install</div></pre></td></tr></table></figure></p>
<ul>
<li><strong>第一行指令會提示sogou的一些鏈接錯誤，需用第二條指令解決。</strong></li>
</ul>
<p>安裝完成之後重啟系統。</p>
<p>再次開啟系統后就能夠在輸入法設置菜單看到Sogou的選項了。</p>
<ul>
<li><strong>Tips</strong>：有些版本會出現搜狗與Fcitx的衝突問題，但是本人沒有遇到這個問題，但是仍然提供一個評價最佳的解決策略：(移除其中一種輸入法架構)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo apt remove fcitx*</div><div class="line">$ sudo apt autoremove</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>Tags: <code>Linux</code> <code>Ubuntu 16.04</code> <code>sogou输入法</code> </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;目前Ubuntu常用的中文输入法有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;搜狗拼音： 搜狗出品的面向Linux的输入法。&lt;/li&gt;
&lt;li&gt;Fcitx
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="Ubuntu 16.04" scheme="http://yoursite.com/tags/Ubuntu-16-04/"/>
    
      <category term="sogou输入法" scheme="http://yoursite.com/tags/sogou%E8%BE%93%E5%85%A5%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习（Machine Learning）简单学</title>
    <link href="http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/"/>
    <id>http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/</id>
    <published>2017-07-24T05:48:31.000Z</published>
    <updated>2017-07-26T05:10:08.461Z</updated>
    
    <content type="html"><![CDATA[<p>本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了<a href="https://morvanzhou.github.io/tutorials/machine-learning/" target="_blank" rel="external">莫烦Python</a>的教学视频，发现其中的内容丰富有趣并且具有很好的阶层学习框架。于是总结了一些精髓并加入了自己从事机器学习研究所工作的一些见解，总结了一些精华的部分以供大家快速入门和学习。</p>
<h1 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h1><p>机器学习（Machine Learning）是由一帮计算机科学家们希望让计算机像人类一样思考而延伸出来的一门计算机理论。机器学习最早来自心理和生物科学，科学家们认为人和计算机其实没有什么差别，都是一大批相互连接的信息传递和存储元素所组成的系统。机器学习是一门典型的跨领域科学，其中包含了概率学、统计学等等方面。随着计算机性能的提升和计算机运算速度的升级，机器学习的应用才真正开始融入我们日常的生活当中。而不久的将来，机器学习必将成为人类探索机器世界的关键钥匙。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>图像识别， AI对话式智慧型家居, 聊天机器人， 股市风险预测…</p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>机器学习的实现方式多种多样，在程式语言中我们称之为算法。<br>Machine Learning的学习方式主要包括：</p>
<ul>
<li><strong>监督式学习（Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and Labels</li>
<li><strong>Principle</strong>: 通过让计算机学习这些label来标记相应的value，从中找出它认为重要的部分作为判断依据。（<strong>既定规律</strong>）</li>
<li><strong>Example</strong>: Logistic Regression、Back Propogation Neural Network</li>
</ul>
</li>
<li><strong>非监督式学习（Un-Supervised Learning）</strong><ul>
<li><strong>Input: Values</strong></li>
<li><strong>Principle</strong>: 只提供value的情况下，计算机事先无法得知value所代表的含义以及需要学习的正确结果，这时候就需要让计算机自己学会分类不同的value，从而总结出不同value背后所隐藏的重要规律作为判断依据。（<strong>生成规律</strong>）</li>
<li><strong>Example</strong>: Apriori、K-Means</li>
</ul>
</li>
<li><strong>半监督式学习（Semi-Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and A few Labels</li>
<li><strong>Principle</strong>: 这种学习方式主要让计算机考虑如何利用少量的label总结出最适合value的判断规则，从而引申到更大范围的value中。</li>
<li><strong>Example</strong>: Laplacisn SVM、Graph Inference</li>
</ul>
</li>
<li><strong>强化学习（Reinforcement Learning）</strong><ul>
<li><strong>Input</strong>: Environment and Set of Operations</li>
<li><strong>Principle</strong>: 通过将计算机设定在一个复杂的环境中，让机器去随机尝试各种可能的操作，并通过环境的回馈（正确加分，不正确扣分）的方式让机器的行为向加分的方面靠近，最终适应环境。</li>
<li><strong>Example</strong>: Alpha GO、Robot Control</li>
</ul>
</li>
</ul>
<p>Machine Leaning的算法主要分为这几类：</p>
<ul>
<li><strong>回归算法（Regression）</strong></li>
<li><strong>基于实例的算法（Instance-Based Algorithm）</strong></li>
<li><strong>正则化方式（Regular Expression）</strong></li>
<li><strong>决策树（Decision Tree）</strong></li>
<li><strong>贝叶斯（Bayesian）</strong></li>
<li><strong>基于核的算法（Kernel-Based Algorithm）</strong></li>
<li><strong>聚类算法（Clustering）</strong></li>
<li><strong>关联法则（Association Rule）</strong></li>
<li><strong>遗传算法（Genetic Algorithm）</strong><ul>
<li>源自进化理论，淘汰弱者，适者生存。通过不断更新和淘汰的机制去选择最优的设计模型。</li>
</ul>
</li>
<li><strong>人工神经网络（Neural Network）</strong></li>
<li><strong>深度学习（Deep Learning）</strong></li>
<li><strong>降低维度算法（Reduce Dimension）</strong></li>
<li><strong>集成算法（Integrated Algorithm）</strong></li>
</ul>
<h1 id="什么是神经网络（Neural-Network）"><a href="#什么是神经网络（Neural-Network）" class="headerlink" title="什么是神经网络（Neural Network）"></a>什么是神经网络（Neural Network）</h1><p>基于生物学的神经结构，将神经细胞的电信号传播机制应用到计算机结构中来，通过对信号传导和演变来组成网络架构。人工神经网络中的每一个“神经元”就是一个Neuron，用来以一定的算法改变输入的信号，从而改变传输的信息，达到对环境做出反应的目的。另一方面，通过神经网络产生的反应收到环境的反馈（做的好或不好），这些反馈和目标行为的误差会通过神经网络的反向传递从原先的路径传送回去，沿途中这些反馈信号会反过来刺激Neuron调整相应的参数从而使得下一次正向传递的结果能够更加贴近目标。如此往复便是整个神经网络训练的过程。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/umtL8L5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>人类通过学习，能够掌握和判别事物的特征从而对事物的本质做出判断，而机器同样是利用这种机制建立起相应的“识别”模型，这些模型对不同的事物具有不同的反应强度，利用强度的不同来区别事物的本质。</p>
<h2 id="神经网络的基本结构"><a href="#神经网络的基本结构" class="headerlink" title="神经网络的基本结构"></a>神经网络的基本结构</h2><p>一个简单的神经网络由3个部分组成：</p>
<ul>
<li><strong>Input Layer</strong><ul>
<li>输入层，用来将资料喂给神经网络</li>
</ul>
</li>
<li><strong>Hidden Layer</strong><ul>
<li>隐藏层，用来尝试改变和调整神经网络的模型和数据的转化</li>
</ul>
</li>
<li><strong>Output Layer</strong><ul>
<li>输出层，用来将神经网络处理后的信号输出成最终的结果</li>
</ul>
</li>
</ul>
<h2 id="神经元（Neuron）的激活函数（Activation-Function）"><a href="#神经元（Neuron）的激活函数（Activation-Function）" class="headerlink" title="神经元（Neuron）的激活函数（Activation Function）"></a>神经元（Neuron）的激活函数（Activation Function）</h2><p>在神经网络学习的过程中，需要对输入的信号做出某种调整，才能真正得到最终的结果。<br>传统的激活函数包括：<br><strong>Sigmoid</strong>、<strong>TanHyperbolic(tanh)</strong>、<strong>ReLu</strong>、 <strong>softplus</strong>以及<strong>softmax</strong>函数</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LT2BXvM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>例如当我们输入一只猫，输入层神经网络会把信号传递给隐藏层的神经元。每一个接收到信息的神经元会通过自己现有的经验对信号做出判断，利用激活函数（activation function）来判断此时的神经元是否需要被激活。激活后的神经元就会对输入信号进行处理并传递给下一层的神经网络层，如此往复当信号传递到输出层时则会经由最终的刺激函数（一般为softmax）产生相应的结果确定输出的信号是属于哪一个标签（label）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vYgqqHJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果此时计算机得到了错误的结果，我们就会通过反向的传递将误差传导回去，改变<strong>所有</strong>的神经元参数，继而那些原本活跃的神经元就会被弱化，在下一次的神经传导过程中就会逐渐被激活函数淘汰。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UHIK2YN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>经过更新的神经网络能够在下一次迭代过程（epoch）中就会改变思路，转而尝试其他的判断方法。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/so90M0c.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>直到得到正确的结果，误差就会小到可以忽略，如此神经网络得以生成。</p>
<h2 id="卷及神经网络（CNN）"><a href="#卷及神经网络（CNN）" class="headerlink" title="卷及神经网络（CNN）"></a>卷及神经网络（CNN）</h2><p>卷积神经网络（Convolution Neural Network）在图片识别方面能够给出不错的结果。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y65bdvJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TZ1jOeO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用<strong>图片</strong>作为例子，任何输入的信号都会被转化成计算机能够识别的数字信号集合，例如矩阵（matrix）。<strong>文字</strong>也是一样的，我们把文字抽象成一个固定维度的向量，在这个维度空间中，每个字都是独立区别开来的，文字的多样性就有这些数字的排列组合来定义。这些信号集会通过输入层读取信息并进入神经网络中。<br>卷积神经网络就是其中的一种网络模式，我们可以把它分成<strong>卷积</strong>和<strong>神经网络</strong>两个部分来理解。</p>
<ul>
<li><strong>卷积</strong>：可以理解为对一个区域信号强弱的总体分析。通过卷积运算可以在一定的区域内总结有用信号的强弱分布，从而对一定区域内信号的变化情况能够有一个较好的认知。卷积能够增强信号的连续性，用区域单位代替点电位。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uOav6gV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><strong>神经网络</strong>：卷积神经网络利用批量过滤的方式，在大范围的信号中不断收集信息，每一次得到的区域信息都是区域中的一小块，之后从这些信息中总结出一些所谓的边缘信号（edges，例如：竖线，横线，斜线，圆圈等基本边缘，其可能分别代表人脸眼睛的左上角，中间，右上角等等部位的区域信息）。同样，用相同的方式从边缘信息组合的图像中总结出更大范围的边缘信息（例如：利用竖线，横线，圆圈等结构组合出整个眼睛）。最后将得到的结果传入全连接层的分类神经网络中就能得到相应的label了。</li>
</ul>
<p><strong>Example：</strong> </p>
<p><img src="https://i.imgur.com/fScPOCU.png" alt=""></p>
<p>图片的维度信息有长、宽和高，长和宽用来表示图片的信号集，高度则是表示颜色的信号分布。被白颜色只有1个高度单位，而彩色的图片则有R、G、B三种基本颜色的信息单位。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VmMQcSI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用批量过滤从图片中收集一定区域中的像素块，而输出的值就是一个高度更高，长和宽都更小的图片。这些图片存储的就是边缘（edges）信息。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/twaqQCR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>反复进行同样的过滤步骤，就可以对图片的信息有更好的理解。之后再对结果进行分类就行了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ikChVno.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在卷积的过程中，神经元可能无意中会丢失一些信息。池化（pooling）就是为了解决这样的问题而被设计出来的。既然我们的信息是在卷积过程中压缩的时候丢失的，那么我们就舍弃这个步骤，直接保留原本的长宽，最后在由池化层统一进行压缩长宽的动作。</p>
<h3 id="CNN常用结构"><a href="#CNN常用结构" class="headerlink" title="CNN常用结构"></a>CNN常用结构</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zugYmYR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>比较流行的<strong>CNN结构</strong>先是输入信号，经过卷积层进行卷积运算，然后经过池化压缩长宽的维度。常用的是Max Pooling的结构：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/T3B3QjS.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在区域中区最大值作为代表这个区域的信号。之后再次对结果进行相同的卷积和池化，进一步压缩信号。之后通过两个全连接层将信号传导给分类器进行分类预测。</p>
<h2 id="递归神经网络（RNN）"><a href="#递归神经网络（RNN）" class="headerlink" title="递归神经网络（RNN）"></a>递归神经网络（RNN）</h2><p>递归神经网络（Recurrent Neural Network）在自然语言处理和序列化信息分析方面能够给出不错的结果。如果说CNN是图像识别的代表性神经网络，那么RNN就是文字处理领域的“CNN”。</p>
<ul>
<li><strong>语言文字</strong>就是一个典型的<strong>序列化信号集</strong>，我们说出的每一句话之间，甚至每一个词之间都有先后关系的依赖，如果抛开字的先后顺序，我们的语言将会失去原本的含义。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/afEYtWN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>假设现在有许多不同的数据信号，如果神经网络只是基于当前的输入信号进行结果的预测，那么就相当于无视了所谓的连续规则，其中必然会丢失重要的时序信息。就好比做菜，酱料A要比酱料B先放，否则就会导致串味的现象。因此一般的NN结构无法让机器了解数据之间的关联。</p>
<p><strong>那么要如何做到让计算机也具有处理连续信号的能力呢？</strong></p>
<ul>
<li>从人的角度出发，不难想到的方式就是记住先前处理过的信号，并将这些信号一同作为输入传递到当前的神经网络中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/AUqu2Ss.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们将先前处理的结果存入记忆中，在分析当前信号时会产生新的记忆。由于记忆之间不会相互关联，因此我们可以直接将先前的记忆调用过来一起进行处理：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/D86UcOA.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如此一来往复多次，神经网络就能携带长期的序列信号进行处理了。<strong>总结之前的流程：</strong></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/MW1BRcu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN运作过程中，每次的结果都会被存储为一个State状态信号，并通过不断迭代传递到下一个乃至更远的神经网络中去。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/iQKtiQP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN下一个时刻到来时，State状态同样会被存储成T+1时刻的State，但这是的 <strong>Y（t）</strong> 不再只是由 <strong>S（t+1）</strong> 来决定的，而是通过 <strong>S（t）</strong> 和 <strong>S（t+1）</strong> 共同处理 <strong>X(t+1)</strong> 得到的结果。因此这个State结构也可以用递回的方式来表示。</li>
</ul>
<h3 id="RNN常用结构"><a href="#RNN常用结构" class="headerlink" title="RNN常用结构"></a>RNN常用结构</h3><p>RNN的形式多种多样，一般需要根据处理的情况不同选择相应适合环境的模型进行建模。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/aZqWHqb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通常可以看到以下几种：</p>
<ul>
<li>如果是用于<strong>分类</strong>的话，例如在判断一句话的情感取向，判断是positive或者negative的情况下，倾向于使用根据最终结点的结果来输出判断的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Noc6AFL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>描述</strong>的话，例如通过一些集成度高的特征信号（图片等）来产生一个描述性的句子或者序列的情况下，倾向于使用根据单一输入来逐步读取时序信息的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2zP4G0h.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>翻译</strong>的话，例如通过一段连续的输入信号来预测下一段连续输出信号的情况下，倾向于使用多对多输出的序列化RNN（Sequence-to-Sequence）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LJSO3JG.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="神经网络非监督式学习实现Autoencoder"><a href="#神经网络非监督式学习实现Autoencoder" class="headerlink" title="神经网络非监督式学习实现Autoencoder"></a>神经网络非监督式学习实现Autoencoder</h1><p>在神经网络训练过程中，往往会需要输入大量的信息，而这些信息对于计算机的学习来说具有十分巨大的负担。想想人类的学习过程，如果一次性塞给我们大量的信息，不但达不到很好的学习效果，还会浪费大量的时间。</p>
<p>因此我们需要一个特殊的神经网络来将原本的信息进行压缩，提取其中最具有代表性的信息，这个网络就是所谓的<strong>编码器（encoder）</strong>。之后再通过放大压缩后的信息，重现原始资料的全部信息，也就是 <strong>解码（decoder）</strong> 的过程。而我们所需要做的就是取得编码器压缩之后的简要信息，送入神经网络进行学习，从而达到我们的目的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/SfOfLbo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>压缩和解压的过程共同构成自编码（Autoencoder）的行为，通过训练编码器和解码器的神经网络结构，依据每次压缩前和解压后数据的对比情况来判断压缩的好坏程度，并利用反向传递来修正误差，从而最大程度上的压缩和还原原始信号。由于从头到尾我们所需要的输入信息为原始信号的信息，整个过程不需要对应的标签信息（label），因此autoencoder属于非监督学习的方式。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BidenDF.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通常会使用到的部分是自编码的结果，也就是压缩过后的概括性讯息。我们建构的其他神经网络只需要对这些精髓的信息进行学习就行了。这样的方式不仅减少了神经网络的负担，还能达到很好的学习效果。</li>
</ul>
<p>自编码的思路和传统的主成分分析算法的精髓类似，都是试图从数据中抓住决定性的关键内容，来概括和分类数据的特征。相比于传统的降维算法中的PCA主成分分析方法，Autoencoder甚至能够取得更好的效果，因此也常被用来对原始数据进行<strong>降维</strong>。</p>
<h1 id="生成对抗网络（GAN）"><a href="#生成对抗网络（GAN）" class="headerlink" title="生成对抗网络（GAN）"></a>生成对抗网络（GAN）</h1><p>生成对抗网络（Generative Adversarial Net）不同于传统的FNN、CNN和RNN是将输入的数据和输出的结果通过某种关系联系起来的神经网络模型，GAN则是一种<strong>凭空生成结果</strong>的模型。</p>
<ul>
<li>当然所谓的 <strong>凭空</strong> 并不是真正意义上的<strong>无</strong>，而是通过一些随机的尝试（随机数组合）创造出一些东西。比如一张图片（像素集合）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/lOfWUK4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们可以把这个随机尝试生成图片的网络比喻成一名新手画家，他们根据自己的灵感用现有的技术生成一些画作。一开始可能有了灵感但是由于作画技术的限制，往往无法生成理想中的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/tU6ZZEW.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>于是这名画家就找到了自己的好朋友新手鉴赏家，可是因为新手鉴赏家本身不具备良好的分辨能力，因此往往给出错误的回答。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a3YNuV0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这个时候就会有外部的干涉参与其中，通过一些标记好的资料来训练这名新手鉴赏家，让他一步步能够辨别画作的好坏。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ou0PBfm.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>最重要的是在训练新手鉴赏家的过程中，随着鉴赏技术不断成熟，鉴赏家开始对新手画家的一些作品做出正确的判断和反馈。这时新手画家就会从这个新手鉴赏家手中得到<strong>真正的有用的标签（label）</strong>，进而利用这些标签改变自己的网络，让自己能够画得更好。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PW7ll1Q.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>总结之前的流程，就是新手鉴赏家这个神经网络利用从外部监督得到的反馈提升自己，然后再利用自己去训练另外一个神经网络，随着新手画家神经网络的不断提升，鉴赏家网络得知自己的能力已经无法鉴赏该画作时，就再次求助外部反馈。就在这一次一次地<strong>对抗</strong>中，两个神经网络就会越来越强大。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/huvFBco.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在GAN网络中，新手画家就是我们的<strong>生成器（Generator）</strong>，新手鉴赏家就是所谓的<strong>Discriminator（辨别器）</strong>，画家的每一幅画都是通过不同的数字排列组合成的像素矩阵，也就是我们说的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BtcBwwU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="GAN的应用"><a href="#GAN的应用" class="headerlink" title="GAN的应用"></a>GAN的应用</h2><p>GAN因为能够通过随机组合产生新的数据，因而常被用在数据的合成和生成新数据的方面。</p>
<ul>
<li>其中一个重要的例子就是数据序列的加减法：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7NxbFvF.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中的二次元人物是通过GAN神经网络的学习，然后利用描述性的选项组合，来生成不同特征的人物图像的一个神经网络网络应用。</p>
<h1 id="理解神经网络的“-黑盒子-”"><a href="#理解神经网络的“-黑盒子-”" class="headerlink" title="理解神经网络的“ 黑盒子 ”"></a>理解神经网络的“ 黑盒子 ”</h1><p>神经网络的成功之处在于它能够从输入和输出的数据中总结出一个抽象的算法函式，基于这个函式的关系我们就能够对未知的数据进行预测。</p>
<p>例如：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y = {ax + b \over 2}" style="border:none;"></p>
<p>这个就相当于一个已经训练好的神经网络模型，对于输入信号<code>X</code>通过网络的处理之后得到输出结果<code>Y</code>。</p>
<p>而神经网络建立的模型就像是把算法公式中所有参数进行一个<strong>封装</strong>，然后开放一个相应的<strong>接口(Interface)</strong>用于呼叫和取值。因此神经网络也被亲切地称之为 <strong>“ 黑匣子 ”</strong> 。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/U5riVAp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>神经网络一般分为三个部分，输入和输出都是人类能够理解的信息，而中间的部分就是所谓的<strong>盲区</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uZpZxdz.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果我们将神经网络的中间层注意拆解后会发现输出的事物往往会是我们看不懂的东西，这就是为什么神经网络 <strong>“黑”</strong> 的原因了。对于人而言，我们在记忆复杂的环境和事物时往往会用一些自己熟知的<strong>记号来标记事物</strong>，使得我们能够更加清楚地记得事物的特征。计算机也是一样的：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gdW7DwM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们知道神经网络处理的信息大都是数字集，通过神经层的分离可以看到这些数字集发生了改变，这些改变在人类看来无法理解，但事实上却是计算机利用自己的方式将这些事物通过它们捕捉到的特征信息转换成<strong>它们眼中的记号</strong>。也就是说计算机正在试图用自己能够理解的方式标记这些特征。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FF8SNDZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在神经网络中，我们称人们能够识别的<strong>特征</strong>记作<strong>Features</strong>，而机器转换后的<strong>特征标记</strong>记作<strong>Feature Representation</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ZrHPbGp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>利用手写数字的特征来理解的话，神经网络的Feature Representation就是空间中不同区域的分布状况。不同的位置聚集了不同的数字集合，落在不同的区域内就说明该输入属于哪一个输出。也就是说计算机把我们熟知的<strong>数字（也就是Features）</strong> 用 <strong>空间坐标区域（也就是Feature Representation）</strong> 来表示。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1GT46F0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>理解神经网络的内部结构和Feature Representation的含义可以很好地利用 <strong>迁移学习（Transform Learning）</strong> 的方式来组合我们的神经网络，从而达到更好的效果。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hE5VgF2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>例如我们已经训练好了从图片中解析物体的神经网络，它能够从图像的序列信息中提取关键的特征事物，此时只需要将输出层替换掉，再加入新的神经网络结构进行连接，就可以生成全新的模型。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qslxK9t.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>新的神经网络重新训练之后就能够具有全新的功能，利用原先的网络优势来拓展生成新的<strong>特征标记</strong>，一定程度上减少了神经网络训练的复杂度。基于先前的图像提取，能够从图中得到事物的<strong>特征信息（Feature Representation）</strong>，再利用新的网络将这些信息进一步转换成表示事物价格的<strong>特征信息</strong>，如此一来神经网络的功能就得以演化了。</li>
</ul>
<h1 id="如何优化神经网络（Optimization）"><a href="#如何优化神经网络（Optimization）" class="headerlink" title="如何优化神经网络（Optimization）"></a>如何优化神经网络（Optimization）</h1><p>优化（Optimization）一直是人类领先于其他生物而在环境中不断成长的重要因素，机器也不例外，通过优化的方式自我更新才能不被复杂的环境所淘汰。</p>
<h2 id="神经网络梯度下降算法（Gradient-Descent）"><a href="#神经网络梯度下降算法（Gradient-Descent）" class="headerlink" title="神经网络梯度下降算法（Gradient Descent）"></a>神经网络梯度下降算法（Gradient Descent）</h2><p>神经网络能够自我学习自我更新不仅仅归功于它能够学习并记忆输入和输出的规律，最重要的是它能够根据学习的规律进行自我调整以让自身适应这个变化的环境。那么机器学习模块又是如何进行优化的呢？答案就是所谓的<strong>梯度下降</strong>了。</p>
<ul>
<li>先前说过神经网络的自我调整是基于结果的反馈，也就是所谓的误差来修正自己：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost = {(predicted - real)^2}" style="border:none;"></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/jwReIP2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Cost函式表达的结果近似可以看成一条平滑的二次曲线，而在更高纬度的层面上就是一个<strong>弯曲的面</strong>，越是接近曲面的底部，误差的Cost就会越小。而梯度下降（Gradient Descent）就是在这个曲面中通过微分的方式找到一个能够向最低点移动的方向，并以此作为动力开始优化自己。当达到最低点时，求导的结果和二次曲线相切，这个时候梯度就消失了，也就是所谓的最佳化状态。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RGjpuX3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>然而按照理论而言，这样的方式也太容易得到想要的结果了，那么神经网络的优化（Optimization）也太神了吧，其实这一切是<strong>很难实现</strong>的。</p>
</li>
<li><p>不同于之前所看到的梯度下降曲面，我们生活中的信号往往需要有许多的维度来表示，尤其是复杂的信号（例如图片或者文字）。这些信号在低纬度的时候几乎无法将他们区别分类，因此我们只能将他们丢到更高的维度上面进行非线性分割。这时候就会存在一个问题了，随着维度的提高，我们所熟知的曲面渐渐变得不再平滑了：</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3UNJkcZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这样的曲面反映出一个关键问题就是<strong>优化的不确定性</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/4PmjIUv.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在多维的复杂曲面中，我们能够找到不止一个梯度消失的点，而这些至低点并不都是我们所谓的<strong>最优解</strong>。当我们初始化的位置不同，我们的结果就会随着梯度下降（Gradient Descent）的优化模式寻找距离自己最近的一些至低点。如此一来<strong>不同的初始值</strong>就会很大程度上影响我们优化的结果。针对这个问题，目前比较好的解决方式就是给信号加上一个 <strong>动量（Momentum）</strong> 以至于在运动至最低点的时候，动量会趋势信号的Cost继续改变（此时梯度又恢复了）。如果我们设定的动量足以让信号摆脱当前的梯度曲面（说明曲面不够深，也就是所谓的局部最优解），信号就会继续去寻找一个更加<strong>难以摆脱的梯度曲面（更深）</strong>，如此一来就能够尽量靠近<strong>全局最优解</strong>。</li>
</ul>
<h1 id="如何评估神经网络的优越性"><a href="#如何评估神经网络的优越性" class="headerlink" title="如何评估神经网络的优越性"></a>如何评估神经网络的优越性</h1><p>机器学习的过程中，神经网络往往会存在一些问题，例如学习效率低，学习误差（loss）变化幅度摇摆不定，或是因为杂讯和信号太多没有办法找到有效的规律和结论。而这些问题可能来自<strong>数据</strong>、<strong>参数</strong>以及<strong>模型结构本身</strong>等各方面的因素。</p>
<h2 id="数据集评估"><a href="#数据集评估" class="headerlink" title="数据集评估"></a>数据集评估</h2><p>在评估数据和模型的吻合度上，我们需要对数据进行一个初步的认知，也就是确定数据集和结果之间的特征关系，也就是所谓的<strong>Features</strong>。这些Features能够很大程度地影响神经网络的学习效率。</p>
<ul>
<li>传统的机器学习算法通常会通过采用 <strong>Cross-Validation</strong> 的方式来对数据进行评估。也就是现将数据集依照6:2:2（不固定）的比例进行拆分，分别表示为<strong>训练集（Training Data）</strong>、<strong>验证集（Validating Data）</strong> 和 <strong>测试集（Testing Data）</strong> 三个部分。</li>
</ul>
<p>评估模型最终结果的好坏往往是测试集决定的，这里面会有训练的时候不曾出现过的输入信号，这也是对神经网络效能的一个<strong>考验</strong>。而要在学习的过程中让学习训练集的模型意识到不单单是要学好那些见过的部分，<strong>没见过的部分</strong>也需要充分地准备，这时候就会用到验证数据集的检验了。在训练完毕之后，我们重新划分3个资料集的比例和分布，就可以重新定义出新的训练资料了。在不断变换数据集的同时，我们可以对模型的<strong>参数进行更加科学的优化和分析</strong>。</p>
<ul>
<li>评价机器学习的方式（Evaluation Function）包括了<strong>误差（Error或Loss）</strong> 以及 <strong>精确度（Accuracy）</strong>，误差就是预测结果和实际结果的差值，而精确度就是在预测过程中的正确率了。</li>
</ul>
<p>有的时候在训练的时候往往结果让人满意，可是到了测试的时候结果却不尽人意，这又是为什么呢？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BbwFVzg.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>原来在训练过程中，神经网络太过优秀了，以至于它将自身优化成为了完全符合这个输入数据的一个模型。而一旦我们测试的输入和训练样本差别很大，就会让模型无从下手，这种现象就是所谓的过拟合（Overfitting）。</p>
<ul>
<li>比较常用来解决Overfitting的方式为<strong>Dropout</strong>，也就是在训练的过程中随机舍弃掉一些数据，从而让自己的模型留有一些变通的空间，来适应突发的情况。</li>
</ul>
<h1 id="为什么要对特征进行标准化（Normalization）"><a href="#为什么要对特征进行标准化（Normalization）" class="headerlink" title="为什么要对特征进行标准化（Normalization）"></a>为什么要对特征进行标准化（Normalization）</h1><p>现实中的数据可能来自不同的地方，不同来源的数据有各自的取值范围。而在学习的过程中，这些取值范围往往<strong>差距悬殊</strong>，这样就会对训练产生障碍。想象一下，如果我们两个权重矩阵M1和M2,我们给M1一个三位数量级的输入参数，给M2一个一位数量级的输入参数，会发生什么事情呢？答案很明显，当我们改变M1的参数时，对于总体的影响是十分巨大的，而相比之下想要达到这样的差距，就必须对M2进行很大幅度的调整。</p>
<h2 id="如何标准化"><a href="#如何标准化" class="headerlink" title="如何标准化"></a>如何标准化</h2><p>延续之前的例子，如果这时候的误差值是：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Error = {predicted - real}" style="border:none;"></p>
<p>那么对这个误差我们应该确保对所有的权重矩阵（Weight Matrix）具有类似的跨度。</p>
<p>通常用于标准化（Normalization）的方法有两种：</p>
<ul>
<li><p>一种是<strong>最小-最大标准化（Minmax Normalization）</strong>。它会将所有的数据按照一个缩放比例转换到0和1的区间中。对单独的特征而言，这个权重是唯一的（全局适用）。</p>
</li>
<li><p>另一种方法是<strong>标准正规化（Standard Normalization）</strong>。它会将所有数据转换成平均值为0，标准差（Std）为1的数据。</p>
</li>
</ul>
<p>这样的标准化问题不但能够平衡数据间的波动和差异，还能提高学习的效率，让机器学习能够正常地平衡每一个特征变数的优化和调节。</p>
<p>LICENCE： 图片摘录自网络引擎，未经授权请勿用于盈利性活动<br>更多详细内容 ： <a href="https://morvanzhou.github.io/" target="_blank" rel="external">Link</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了&lt;a href=&quot;https://morvanzhou.github.io/tutorials/machine-learning/&quot; targe
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="Reinforcement Learning" scheme="http://yoursite.com/tags/Reinforcement-Learning/"/>
    
  </entry>
  
</feed>
