<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>指尖の岁月</title>
  <subtitle>世间点滴，莫忘于心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-08-04T06:54:32.035Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Eternal</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>医疗管理系统</title>
    <link href="http://yoursite.com/2017/08/04/database/"/>
    <id>http://yoursite.com/2017/08/04/database/</id>
    <published>2017-08-04T06:51:50.000Z</published>
    <updated>2017-08-04T06:54:32.035Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本系统主要是基于 <code>Struts2 MVC架构</code> + <code>mysql资料库</code> 共同开发的医疗信息管理系统模型。利用JSP打造简易的网页与接口，让用户能够通过系统纪录和查询医疗的细节流程。</p>
<p><a href="https://github.com/EternalFeather/Medical_Management_System_with_Database" target="_blank" rel="external">下載鏈接</a></p>
<h1 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h1><ul>
<li><code>操作系统</code>：Windows10</li>
<li><code>资料库</code>：Mysql</li>
<li><code>IDE</code>：Eclipse</li>
<li><code>开发语言</code>：Jsp + Sql + Java</li>
</ul>
<h1 id="SQL-Table"><a href="#SQL-Table" class="headerlink" title="SQL Table"></a>SQL Table</h1><p>资料库端分为五个Table，分别为 <code>Department</code>、<code>Employee</code>、<code>Hospital</code>、<code>Patient</code> 和 <code>Report</code>。</p>
<h2 id="Attribute-Introduction"><a href="#Attribute-Introduction" class="headerlink" title="Attribute Introduction"></a>Attribute Introduction</h2><p><strong>Hospital Table:</strong> 記錄醫院的具體信息</p>
<ul>
<li>Hospital_ID:每間醫院的編號（唯一）</li>
<li>Hospital_Name:醫院的名稱</li>
<li>Hospital_Address:醫院的地理位置</li>
<li>Hospital_Scale:醫院的規模大小</li>
</ul>
<p><strong>Department Table:</strong> 記錄醫院里各個不同部門的具體信息</p>
<ul>
<li>Department_ID:醫院裏面不同部門的編號（唯一）</li>
<li>Department_Subject:部門的名稱</li>
<li>Department_People:部門的人數</li>
<li>Field:部門所掌管的職能</li>
</ul>
<p><strong>Employee Table:</strong> 記錄醫院工作人員的具體信息</p>
<ul>
<li>Doctor_ID:每個員工的編號（唯一）</li>
<li>Doctor_Name:員工的姓名</li>
<li>Doctor_Age:員工的年齡</li>
<li>Doctor_Specialty:員工的專長</li>
</ul>
<p><strong>Patient Table:</strong> 記錄病人的具體信息</p>
<ul>
<li>Patient_ID:每個病人的編號（唯一）</li>
<li>Patient_Name:病人的姓名</li>
<li>Patient_Age:病人的年齡</li>
<li>Patient_Disease:病人的癥狀</li>
</ul>
<p><strong>Report Table:</strong> 記錄病人病歷記錄的具體信息</p>
<ul>
<li>Report_ID:每個病歷記錄的編號（唯一）</li>
<li>Report_Disease:病歷記錄的病人癥狀</li>
<li>Report_PatientName:病歷記錄的病人姓名</li>
<li>Report_Medicine:病歷記錄的病人用藥情況</li>
</ul>
<h1 id="ER-Diagram"><a href="#ER-Diagram" class="headerlink" title="ER Diagram"></a>ER Diagram</h1><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qdBYNZI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="Relation-Schema"><a href="#Relation-Schema" class="headerlink" title="Relation Schema"></a>Relation Schema</h1><table>
<thead>
<tr>
<th style="text-align:center">Hospital Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Hospital_ID</td>
<td style="text-align:center">Hospital_Name</td>
<td style="text-align:center">Hospital_Address</td>
<td style="text-align:center">Hospital_Scale</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Department Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Department_ID</td>
<td style="text-align:center">Department_Subject</td>
<td style="text-align:center">Department_People</td>
<td style="text-align:center">Field</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Employee Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Doctor_ID</td>
<td style="text-align:center">Doctor_Name</td>
<td style="text-align:center">Doctor_Name</td>
<td style="text-align:center">Doctor_Specialty</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Patient Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Patient_ID</td>
<td style="text-align:center">Patient_Name</td>
<td style="text-align:center">Patient_Age</td>
<td style="text-align:center">Patient_Disease</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Report Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Report_ID</td>
<td style="text-align:center">Report_Disease</td>
<td style="text-align:center">Report_PatientName</td>
<td style="text-align:center">Report_Medicine</td>
</tr>
</tbody>
</table>
<h1 id="Relationship-Introduction"><a href="#Relationship-Introduction" class="headerlink" title="Relationship Introduction"></a>Relationship Introduction</h1><ul>
<li>每個醫院都會有許多不同的部門，每個部門都是隸屬於某一家醫院。</li>
<li>每個醫院部門都會招聘不同數量的員工，未退休的員工會屬於某一個部門。</li>
<li>所有負責醫療工作的員工都會給病人開具病歷證明，所有的病歷證明都是由醫療工作員工開具的。</li>
<li>所有的病人都有自己的病歷記錄，所有的病歷記錄記錄著該病人的醫療情況。</li>
<li>負責醫療工作的員工會給病人看病，同時醫院的員工也有可能是病人。</li>
</ul>
<h1 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h1><p>配置好sql和server之后，就可以通过localhost或者IP来访问系统网址了，这里用的是Tomcat Server來訪問資料庫系統首頁。。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/OAdFgoI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/czWAFBo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>左邊的功能列表可以選擇需要操作的Entity進行不同的資料庫操作。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ukIeIjX.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>以醫院管理為例，進入醫院管理操作介面，系統會自動列出所有的數據庫資料。點擊左上角的<strong>添加</strong>按鈕可以添加新的醫院信息到database；同時可以通過<strong>Search</strong>的選項來索引資料庫裏面的資料；點擊操作欄位的<strong>修改和刪除</strong>可以分別對相應的資料進行修改和刪除；最後點擊右上角的<strong>手動修改和查詢</strong>可以分別通過手動輸入SQL指令來進行修改動作（insert，delete，update）和查詢動作（select）。</p>
<ul>
<li>添加介面：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PDo43C2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>可以<strong>添加</strong>醫院的相關信息到數據庫。</p>
<ul>
<li>選擇操作：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/mYQk0G0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>系統會給出相應的<strong>檢索</strong>結果：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UGf1VbP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>修改和刪除：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/9jEEf1k.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>點擊修改操作系統會自動捕捉當前的資料信息，方便進行<strong>修改</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/EZVj52s.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>點擊刪除操作系統會提示<strong>是否刪除</strong>，點擊確定則會從資料庫移除相應信息。</p>
<ul>
<li>手動修改和刪除：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eknZV1t.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/fqo6fRa.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>點擊<strong>手動修改和刪除</strong>操作，系統會跳出相應的輸入框，可以通過手動輸入SQL指令來進行Select檢索或者Insert，Update，Delete等操作。</p>
<ul>
<li>Nested Query和Aggregate Query（以醫生管理為例）：<br>點擊Nested Query會跳轉至如下畫面。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/9P6SJ1w.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>分別點擊不同的按鈕可以<strong>跳轉</strong>至相應功能對應的介面。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Cp7doj5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通過選項可以自動通過Button的方式呼叫資料庫，通過sql指令也可以進行資料庫的操作。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/df2ElPC.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通過選項操作同樣可以用button的方式呼叫資料庫操作，sql指令同樣也能夠進行相應的操作。（注：在sql對於Aggregate操作過程中需要對應下方的欄位進行as重命名）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本系统主要是基于 &lt;code&gt;Struts2 MVC架构&lt;/
    
    </summary>
    
    
      <category term="Database" scheme="http://yoursite.com/tags/Database/"/>
    
      <category term="System" scheme="http://yoursite.com/tags/System/"/>
    
      <category term="Struts MVC" scheme="http://yoursite.com/tags/Struts-MVC/"/>
    
  </entry>
  
  <entry>
    <title>Word2Vec on Wikipedia</title>
    <link href="http://yoursite.com/2017/08/04/word2vec/"/>
    <id>http://yoursite.com/2017/08/04/word2vec/</id>
    <published>2017-08-04T06:51:25.000Z</published>
    <updated>2017-08-04T07:53:29.800Z</updated>
    
    <content type="html"><![CDATA[<p>我们知道语言在人际交往当中充当了重要的角色，理解语言的编码就能够了解对方所要表达的意思。而机器不同于人，无法从繁杂的文字当中快速提取有用的信息，因此需要借助一个能够代表文字语言的编码单位，也就是我们说的<strong>向量（Vector）</strong>。因此训练Word2Vec的模型，用来计算词语之间的相似度似乎成为了解决文字编码问题的不可或缺的重要途径之一。</p>
<h1 id="配置需求"><a href="#配置需求" class="headerlink" title="配置需求"></a>配置需求</h1><ul>
<li><code>Python3</code></li>
<li><code>Gensim</code> &gt;= 2.3.0 (<strong>沒試過更低的版本</strong>)</li>
<li><code>Opencc</code></li>
<li><code>jieba</code></li>
</ul>
<h1 id="模型训练语料"><a href="#模型训练语料" class="headerlink" title="模型训练语料"></a>模型训练语料</h1><ul>
<li>维基百科官方提供了大约11G的很好的英文語料： <a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2" target="_blank" rel="external">開源數據鏈接</a>。</li>
<li>同時也提供了大約1.5G的中文語料： <a href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2" target="_blank" rel="external">開源數據鏈接</a>。</li>
</ul>
<p>其主要的文档格式以 <code>.xml</code> 为主。</p>
<h1 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h1><ul>
<li>下載相應的Python執行檔：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/EternalFeather/Word2Vec-on-Wikipedia-Corpus.git</div></pre></td></tr></table></figure>
<h2 id="資料前處理"><a href="#資料前處理" class="headerlink" title="資料前處理"></a>資料前處理</h2><p>前處理第一階段需要將wiki的 <code>.xml</code> 格式的數據轉換成 <code>text</code> 格式的數據:</p>
<ul>
<li><p>通過 <code>word2vec_process.py</code> 實現，基本參數包括：</p>
<ul>
<li><code>-data</code>： 輸入的維基百科數據集。</li>
<li><code>-output</code>： 輸出的文件位置和名稱。</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python word2vec_process.py -data enwiki-latest-pages-articles.xml.bz2 -output wiki.en.text</div></pre></td></tr></table></figure>
<p><strong>Tips:</strong> </p>
<ul>
<li>如果是中文維基百科的語料訓練時，會存在一些繁體和簡體混雜的中文字，如果想要統一字體格式，就可以使用Opencc將字體進行轉換：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">opencc -i wiki.zh.text -o wiki.zh.text.jianti -c zht2zhs.ini</div></pre></td></tr></table></figure>
<ul>
<li>中文的維基百科數據接下來就是需要進行斷詞處理了，這裏使用的<strong>中文斷詞工具</strong>是 <code>jieba</code>。</li>
</ul>
<p>這裏利用了gensim裏面處理維基百科的class <code>WikiCorpus</code>，通過 <code>get_texts</code> function將每篇文章換行輸出成text文本，並且已經完成了去標點的工作。運行之後就能夠得到英文維基百科的數據文檔 <code>wiki.en.text</code>(參數可自行設定名稱)。</p>
<h2 id="模型訓練"><a href="#模型訓練" class="headerlink" title="模型訓練"></a>模型訓練</h2><p>有了文章的text數據集之後，無論是word2vec binary版本還是gensim的word2vec，都可以用來訓練我們的模型，不過後者的運算速度比較快。</p>
<ul>
<li><p>模型的建立通過 <code>word2vec_model.py</code> 實現，基本參數包括：</p>
<ul>
<li><code>-text</code>： 輸入的維基百科文字檔名稱。</li>
<li><code>-vector</code>： 輸出的向量文檔存儲位置和名稱（默認爲 <strong>wiki.en.text.vector</strong>）。</li>
<li><code>-core</code>： 多進程運行使用的cpu數量（默認爲全部）。</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python word2vec_model.py -text wiki.en.text -vector wiki.en.text.vector -core 8</div></pre></td></tr></table></figure>
<h2 id="模型測試"><a href="#模型測試" class="headerlink" title="模型測試"></a>模型測試</h2><p>訓練結束之後就能得到一個gensim原始c版本的word2vec的vector格式的模型，這時候我們就可以利用這些模型進行一些文字的評估測試了：</p>
<ul>
<li><p>導入模型進行操作通過 <code>word2vec_eval.py</code> 實現，基本參數包括：</p>
<ul>
<li><code>-vector</code>： 載入的模型位置和名稱。</li>
<li><code>-mode</code>： 想要執行模型的功能名稱（包括 <em>similar<strong>【預測相關的words】、</strong>similarity*</em>【判斷兩個words的相似度】等）</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python word2vec_eval.py -vector wiki.en.text.vector -mode similarity</div></pre></td></tr></table></figure>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="http://www.52nlp.cn/%E4%B8%AD%E8%8B%B1%E6%96%87%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E8%AF%AD%E6%96%99%E4%B8%8A%E7%9A%84word2vec%E5%AE%9E%E9%AA%8C" target="_blank" rel="external">我愛自然語言處理</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们知道语言在人际交往当中充当了重要的角色，理解语言的编码就能够了解对方所要表达的意思。而机器不同于人，无法从繁杂的文字当中快速提取有用的信息，因此需要借助一个能够代表文字语言的编码单位，也就是我们说的&lt;strong&gt;向量（Vector）&lt;/strong&gt;。因此训练Word
    
    </summary>
    
    
      <category term="Word2Vec" scheme="http://yoursite.com/tags/Word2Vec/"/>
    
      <category term="Embedding" scheme="http://yoursite.com/tags/Embedding/"/>
    
  </entry>
  
  <entry>
    <title>中文情緒字典（Chinese Sentiment Lexicon）</title>
    <link href="http://yoursite.com/2017/08/04/sentiment/"/>
    <id>http://yoursite.com/2017/08/04/sentiment/</id>
    <published>2017-08-04T06:51:16.000Z</published>
    <updated>2017-08-04T07:04:18.501Z</updated>
    
    <content type="html"><![CDATA[<h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p>利用 <code>PMI</code> 和 <code>SOC-PMI</code> 等語言統計分析算法，從現有文章中標記一些seed words，通過半監督式學習找出段落中隱含的其他情緒詞匯，從而建立起完整的情緒字典。</p>
<p>情緒字典的覆蓋範圍包括 <code>名詞</code> 、 <code>動詞</code> 和 <code>形容詞</code> 等部分，每個詞都會有一個正向分數（positive）和一個負向分數（negative）。兩個分數的高低可以判斷這個詞的情緒分布狀況。</p>
<h1 id="必要配置"><a href="#必要配置" class="headerlink" title="必要配置"></a>必要配置</h1><ul>
<li><code>Python2</code></li>
<li><code>JDK</code></li>
<li><code>jieba</code></li>
</ul>
<h1 id="使用流程"><a href="#使用流程" class="headerlink" title="使用流程"></a>使用流程</h1><ul>
<li>下載情緒字典程式：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/EternalFeather/-Chinese-Sentiment-Lexicon-.git</div></pre></td></tr></table></figure>
<ul>
<li>將預設的Seed Word（也就是自行標記的幾個情緒面向詞匯）放入 <code>SentimentLexicon/data/input/Seedwords.txt</code>  中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3KEOqCF.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>將需要提取情緒詞匯的訓練文章放入 <code>SentimentLexicon/data/input/Corpus.txt</code> 中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/nGJWyIO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>運行 <code>SL.jar</code> 文件即可開始訓練過程：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -jar &apos;SL.jar&apos;</div></pre></td></tr></table></figure>
<h1 id="測試結果"><a href="#測試結果" class="headerlink" title="測試結果"></a>測試結果</h1><ul>
<li>得到的結果會儲存在 <code>SentimentLexicon/data/Propagation/FinalMatrix.csv</code> 文件中。 </li>
</ul>
<p><img src="https://i.imgur.com/Ugyr8cq.png" alt=""></p>
<p>可以看出在比較詞的正負向上能夠取得比較可觀的結果。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;功能&quot;&gt;&lt;a href=&quot;#功能&quot; class=&quot;headerlink&quot; title=&quot;功能&quot;&gt;&lt;/a&gt;功能&lt;/h1&gt;&lt;p&gt;利用 &lt;code&gt;PMI&lt;/code&gt; 和 &lt;code&gt;SOC-PMI&lt;/code&gt; 等語言統計分析算法，從現有文章中標記一些seed wo
    
    </summary>
    
    
      <category term="Sentiment Lexicon" scheme="http://yoursite.com/tags/Sentiment-Lexicon/"/>
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="PMI" scheme="http://yoursite.com/tags/PMI/"/>
    
  </entry>
  
  <entry>
    <title>Gal-game-on-Renpy</title>
    <link href="http://yoursite.com/2017/08/02/gal/"/>
    <id>http://yoursite.com/2017/08/02/gal/</id>
    <published>2017-08-02T07:09:53.000Z</published>
    <updated>2017-08-04T06:55:14.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安裝說明"><a href="#安裝說明" class="headerlink" title="安裝說明"></a>安裝說明</h1><p>Renpy Platform可以用來設計自己專屬的視覺小說遊戲。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/nkF3saW.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p><a href="https://pan.baidu.com/s/1kVeIIoR" target="_blank" rel="external">Demo遊戲鏈接</a><br>提取密碼: <code>m0va</code></p>
<h1 id="素材來源"><a href="#素材來源" class="headerlink" title="素材來源"></a>素材來源</h1><p>遊戲使用的圖片、視頻以及音頻的剪輯原素材來源於 <code>FAVORITE</code> 和 <code>YUZUSOFT</code> 遊戲公司，未經授權不得用以商業目的性傳播和使用。大部分圖片經過PS修圖處理，<strong>如需轉載請注明出處</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7RkEoRe.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="使用說明"><a href="#使用說明" class="headerlink" title="使用說明"></a>使用說明</h1><ul>
<li>將Github上 <code>images.rar</code> 中的三個文件放入下載好的遊戲文件中的 <code>game/images/</code> 目錄中。</li>
<li>運行 <code>.exe</code> 文件即可開始遊戲。</li>
</ul>
<h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><ul>
<li>主界面（會根據劇情不同有所變化）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/kkJKDds.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>CG鑑賞頁面</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/sXbSQeM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/wEylyRQ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zz1W2PG.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>設定頁面</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ZdgAa0M.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>載入頁面</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8MQf1cJ.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>遊戲分支選單</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PzFMnpP.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>遊戲主題內容部分</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ydrcpP9.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>遊戲即時選單</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8Hq7y0e.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>選單 <code>ENCYCLOPEDIA</code> 遊戲介紹和玩法功能簡介</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/oBPr4mH.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/bHGIB3K.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;安裝說明&quot;&gt;&lt;a href=&quot;#安裝說明&quot; class=&quot;headerlink&quot; title=&quot;安裝說明&quot;&gt;&lt;/a&gt;安裝說明&lt;/h1&gt;&lt;p&gt;Renpy Platform可以用來設計自己專屬的視覺小說遊戲。&lt;/p&gt;
&lt;figure class=&quot;image-bubb
    
    </summary>
    
    
      <category term="Renpy" scheme="http://yoursite.com/tags/Renpy/"/>
    
      <category term="Gal-game" scheme="http://yoursite.com/tags/Gal-game/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04配置深度學習開發環境（CUDA+CUDNN）</title>
    <link href="http://yoursite.com/2017/08/01/cuda/"/>
    <id>http://yoursite.com/2017/08/01/cuda/</id>
    <published>2017-08-01T08:18:31.000Z</published>
    <updated>2017-08-04T06:54:57.123Z</updated>
    
    <content type="html"><![CDATA[<h1 id="顯卡規格查詢"><a href="#顯卡規格查詢" class="headerlink" title="顯卡規格查詢"></a>顯卡規格查詢</h1><p>首先需要確定自己顯卡的規格：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">lspci -vnn | grep VGA -A 12</div></pre></td></tr></table></figure></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Hqk5wzt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>其中<code>nvidia_375</code>就是顯卡的規格指數，後面會用到。</p>
<h1 id="安裝CUDA"><a href="#安裝CUDA" class="headerlink" title="安裝CUDA"></a>安裝CUDA</h1><p>前往<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">CUDA下載</a>頁面選擇好系統參數進行下載。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uxl5TQY.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="配置CUDA環境"><a href="#配置CUDA環境" class="headerlink" title="配置CUDA環境"></a>配置CUDA環境</h2><p>Installation Instructions:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb</div><div class="line">sudo apt-get update</div><div class="line">sudo apt-get install cuda</div></pre></td></tr></table></figure></p>
<h1 id="安裝cuDNN"><a href="#安裝cuDNN" class="headerlink" title="安裝cuDNN"></a>安裝cuDNN</h1><p>前往<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="external">cuDNN下載</a>點擊同意並選擇規格後開始下載。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VsYqKL0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="配置cuDNN環境"><a href="#配置cuDNN環境" class="headerlink" title="配置cuDNN環境"></a>配置cuDNN環境</h2><p>Installation Instructions:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgz</div><div class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include</div><div class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64</div><div class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</div></pre></td></tr></table></figure></p>
<h3 id="設定環境變數"><a href="#設定環境變數" class="headerlink" title="設定環境變數"></a>設定環境變數</h3><p>接下來到<code>.bashrc</code>檔案：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vim ~/.bashrc</div></pre></td></tr></table></figure>
<p>將下面的指令復制到配置文件的末尾：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/nvidia-375</div><div class="line">export CUDA_HOME=/usr/local/cuda</div><div class="line">export PATH=$PATH:/usr/local/cuda/bin</div></pre></td></tr></table></figure>
<p><strong>注意</strong>：其中的/usr/lib/nvidia-375就是之前查詢的顯卡規格。</p>
<h2 id="查看配置結果"><a href="#查看配置結果" class="headerlink" title="查看配置結果"></a>查看配置結果</h2><p>配置完成後可以查看是否成功配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nvidia-smi -l</div></pre></td></tr></table></figure>
<p>即可即時查看GPU的運作情況</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/xnyMEH3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="安裝Tensorflow-gpu"><a href="#安裝Tensorflow-gpu" class="headerlink" title="安裝Tensorflow-gpu"></a>安裝Tensorflow-gpu</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo pip install tensorflow-gpu</div></pre></td></tr></table></figure>
<p>安裝之後會加入pip library中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip freeze</div></pre></td></tr></table></figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qHCfJgT.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如此以來就可以用GPU操作深度學習的框架了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;顯卡規格查詢&quot;&gt;&lt;a href=&quot;#顯卡規格查詢&quot; class=&quot;headerlink&quot; title=&quot;顯卡規格查詢&quot;&gt;&lt;/a&gt;顯卡規格查詢&lt;/h1&gt;&lt;p&gt;首先需要確定自己顯卡的規格：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;tab
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="Tensorflow" scheme="http://yoursite.com/tags/Tensorflow/"/>
    
      <category term="CUDA" scheme="http://yoursite.com/tags/CUDA/"/>
    
      <category term="cuDNN" scheme="http://yoursite.com/tags/cuDNN/"/>
    
  </entry>
  
  <entry>
    <title>聊天机器人训练语料整理</title>
    <link href="http://yoursite.com/2017/07/25/Corpus/"/>
    <id>http://yoursite.com/2017/07/25/Corpus/</id>
    <published>2017-07-25T07:15:05.000Z</published>
    <updated>2017-08-04T06:54:46.051Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Dialog-Datasets-for-Training-Chatbot"><a href="#Dialog-Datasets-for-Training-Chatbot" class="headerlink" title="Dialog Datasets for Training Chatbot"></a>Dialog Datasets for Training Chatbot</h1><p>在进行Chatbot的研究过程中，除了要有一个漂亮的模型之外，还需要有大量可供训练的语料来强化我们的聊天机器人。越干净的语料就能训练出越接近人类自然语言回复的Chatbot。</p>
<ul>
<li>目前网上公开的语料大多是一些带有噪音的、数量有限的语料。在这里总结了一些可行的语料以及一些利用爬取工具得到的语料，其中包括：</li>
</ul>
<h1 id="基本公开语料"><a href="#基本公开语料" class="headerlink" title="基本公开语料"></a>基本公开语料</h1><ul>
<li><p><a href="https://github.com/rustch3n/dgk_lost_conv" target="_blank" rel="external">dgk_shooter_min.conv</a><br>中文电影对白语料，噪音大，由于对话未区分说话人，因此对白问答关系难以对应。</p>
</li>
<li><p><a href="https://github.com/gunthercox/chatterbot-corpus/tree/master/chatterbot_corpus/data/" target="_blank" rel="external">ChatBot多语种聊天语料</a><br>ChatterBot聊天引擎所提供的基本语聊，涵盖语种范围广，但是数量不多，但质量较高，适合模型测试。</p>
</li>
<li><p><a href="https://github.com/karthikncode/nlp-datasets#question-answering" target="_blank" rel="external">DataSets for Natural Language Processing</a><br>这个是人为收集总结的自然语言处理研究论文以及对应的数据资料集，主要覆盖方面包括了： <strong>Question Answering, Dialogue Systems</strong> 以及 <strong>Goal-Oriented Dialogue System</strong> 等。文本都由英文构成，可用于机器翻译和对话模型使用。</p>
</li>
<li><p><a href="https://github.com/rustch3n/dgk_lost_conv/tree/master/results" target="_blank" rel="external">小黄鸡对话机器人训练语料</a><br>这就是网络上流行的小黄鸡对话机器人的训练语料，包括了 <strong>xiaohuangji50w_fenciA.conv.zip （已分词）</strong> 和 <strong>xiaohuangji50w_nofenci.conv.zip （未分词）</strong> 两个部分，分词以 <strong>“/”</strong> 区隔开来，并没有语义上的划分。语料中含有较多表情颜文字，总体对话字数较少，杂讯较多。</p>
</li>
<li><p><a href="https://github.com/Samurais/egret-wenda-corpus" target="_blank" rel="external">白鹭时代中文问答语料</a><br>由白鹭时代官方论坛问答版块的问题及回复组成，回复选取了标注 <strong>“最佳答案”</strong> 的记录为目标。人工审核资料，给每一个问题一个可以接受的答案。数量不多，多为问答模式。</p>
</li>
<li><p><a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" target="_blank" rel="external">Cornell_Movie-Dialogs_Corpus</a><br>康奈尔大学影视对话资料集，语料包含对话人名称信息，语料为英文，以多轮对话为主。</p>
</li>
</ul>
<h1 id="个人爬取语聊（初步整理）"><a href="#个人爬取语聊（初步整理）" class="headerlink" title="个人爬取语聊（初步整理）"></a>个人爬取语聊（初步整理）</h1><ul>
<li><p><a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/news%20corpus" target="_blank" rel="external">中文新闻语料</a><br>利用爬虫从各大新闻网站上爬取的新闻头条和简讯。</p>
</li>
<li><p><a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/PTT_charactors" target="_blank" rel="external">PTT八卦版推文</a><br>利用爬虫从社交软体PTT上对于八卦分类板块的内容进行爬取，原始资料为 <a href="">PTT八卦板推文.txt</a> 其中包括一些符号和空格杂讯，过滤杂讯（利用统计方式按比例替换成固定符号，降低资料复杂度）之后，通过 <strong>单字</strong> 或 <a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/PTT_words" target="_blank" rel="external">词组</a>（jieba段词） 等不同方式建立问答语料和字典。</p>
</li>
</ul>
<h1 id="License"><a href="#License" class="headerlink" title="License:"></a>License:</h1><p>公开语料的版权归原作者所有，未经允许不得一个人名义投入盈利性活动。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Dialog-Datasets-for-Training-Chatbot&quot;&gt;&lt;a href=&quot;#Dialog-Datasets-for-Training-Chatbot&quot; class=&quot;headerlink&quot; title=&quot;Dialog Datasets for 
    
    </summary>
    
    
      <category term="Chatbot" scheme="http://yoursite.com/tags/Chatbot/"/>
    
      <category term="Corpus" scheme="http://yoursite.com/tags/Corpus/"/>
    
      <category term="Dialogue" scheme="http://yoursite.com/tags/Dialogue/"/>
    
  </entry>
  
  <entry>
    <title>Python简单学</title>
    <link href="http://yoursite.com/2017/07/25/Python/"/>
    <id>http://yoursite.com/2017/07/25/Python/</id>
    <published>2017-07-25T06:10:56.000Z</published>
    <updated>2017-08-04T06:55:33.518Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Foundation-Summary"><a href="#Foundation-Summary" class="headerlink" title="Foundation Summary"></a>Foundation Summary</h1><ul>
<li><strong>Print</strong></li>
<li><strong>Calculation Function</strong></li>
<li><strong>Variable</strong></li>
<li><strong>While loop</strong></li>
<li><strong>For loop</strong></li>
<li><strong>If/Elif/Else Condition</strong></li>
<li><strong>Function Definition[Def] with/without parameters</strong></li>
<li><strong>Global or Local Variable</strong></li>
<li><strong>Read or Write files</strong><ul>
<li><code>readlines()</code> and <code>readline()</code></li>
</ul>
</li>
<li><strong>Class</strong><ul>
<li><code>__init__</code> constructor</li>
</ul>
</li>
<li><strong>input</strong></li>
<li><strong>Tuple &amp; List</strong><ul>
<li>Both are iterative</li>
</ul>
</li>
<li><strong>List</strong><ul>
<li><code>append</code> <code>insert</code> <code>remove</code></li>
</ul>
</li>
<li><strong>Multi-dimention List</strong></li>
<li><strong>Dictionary</strong><ul>
<li><code>del(also can used for list)</code></li>
</ul>
</li>
<li><strong>Import</strong></li>
<li><strong>Continue &amp; Break</strong></li>
<li><strong>Error processing[Try/Except]</strong></li>
<li><p><strong>Zip</strong></p>
<ul>
<li>Output is an object<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">a = [1, 2, 3]</div><div class="line">b = [4, 5]</div><div class="line"># Convert to list</div><div class="line">list(zip(a, b))</div><div class="line"># Also we can use for loop to iterate each elements in object</div><div class="line">for i, j in zip(a,b)</div><div class="line"># Output of list(zip(a, b)) is: [(1, 4), (2, 5)]</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Lambda</strong><br>Example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def fun1(x, y):</div><div class="line">    return(x + y)</div><div class="line">fun2 = lambda x, y : x + y</div><div class="line"># fun1 is the same as fun2</div></pre></td></tr></table></figure>
</li>
<li><p><strong>Map</strong></p>
<ul>
<li>Output is an object<br>Example:<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def fun1(x, y):</div><div class="line">    return(x + y)</div><div class="line">list(map(fun1, [1, 2, 3], [4, 5]))</div><div class="line"># Output is: [5, 7]</div><div class="line"># Note: The output of fun1([1], [2]) is: [1, 2]</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Copy &amp; Deepcopy</strong></p>
<ul>
<li>python object share address(point)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># ********Copy********:</div><div class="line">a = [1, 2, 3]</div><div class="line">b = a</div><div class="line">b[0] = 11</div><div class="line">a = b = [11, 2, 3]</div><div class="line"># id(a) == id(b) is True</div><div class="line"></div><div class="line">import copy</div><div class="line">c = copy.copy(a)</div><div class="line"># id(a) == id(b) is False</div><div class="line"># Note:</div><div class="line">a = [1, 2, [3, 4]]</div><div class="line">d = copy.copy(a)</div><div class="line"># id(a) == id(d) is False</div><div class="line"># id(a[2]) == id(d[2]) is True</div><div class="line"># Because d[2] == a[2] are both object</div><div class="line"># Note2:</div><div class="line">a = 2</div><div class="line">b = a</div><div class="line">a = 3</div><div class="line"># b = 2 auto copy</div><div class="line"># ********Deepcopy ********:</div><div class="line">e = copy.deepcopy(a)</div><div class="line"># id(a[2]) == id(e[2]) is False</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="Multi-Thread"><a href="#Multi-Thread" class="headerlink" title="Multi-Thread"></a>Multi-Thread</h1><h2 id="Lead-to-Improve-Efficiency"><a href="#Lead-to-Improve-Efficiency" class="headerlink" title="Lead to Improve Efficiency"></a>Lead to Improve Efficiency</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">import threading</div><div class="line">import time</div><div class="line"># check the number of threads</div><div class="line">print(threading.active_count())</div><div class="line"># check all the details of threads </div><div class="line">print(threading.enumerate())</div><div class="line"># check which threads are working</div><div class="line">print(threading.current_thread())</div><div class="line"># ********Extend********:</div><div class="line">def thread_job():</div><div class="line">    print(&quot;MSG : This is a new Thread, number = %s\n&quot; % threading.current_thread())</div><div class="line">    for i in range(10):</div><div class="line">        time.sleep(0.1)</div><div class="line">    print(&quot;MSG : T1 Finished.\n&quot;)</div><div class="line">new_thread = threading.Thread(target = thread_job, Name = &apos;T1&apos;)</div><div class="line">def thread_job2():</div><div class="line">    print(&quot;MSG : T2 Start.\n&quot;)</div><div class="line">    print(&quot;MSG : T2 Finished.\n&quot;)</div><div class="line">new2_thread = threading.Thread(target = thread_job2, Name = &apos;T2&apos;)</div><div class="line">new_thread.start()</div><div class="line">new2_thread.start()</div><div class="line"># ********Join********:</div><div class="line"># print(&quot;MSG : Done.\n&quot;)</div><div class="line"># when we run the code &quot;Done&quot; will show before &quot;T2 Finished&quot; </div><div class="line">new2_thread.join()</div><div class="line">print(&quot;MSG : Done.\n&quot;)</div><div class="line"># T1 is slower than T2, so that &quot;Done&quot; will show before &quot;T1 Finished&quot;</div></pre></td></tr></table></figure>
<h2 id="Example-of-queue-using-in-thread"><a href="#Example-of-queue-using-in-thread" class="headerlink" title="Example of queue using in thread:"></a>Example of queue using in thread:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"># ********Queue********:</div><div class="line">import threading</div><div class="line">import time</div><div class="line">from queue import Queue</div><div class="line"></div><div class="line">def job(l, q):</div><div class="line">    for i in range(len(l)):</div><div class="line">        l[i] = l[i] ** 2</div><div class="line">        time.sleep(1)</div><div class="line">    # thread can not return value</div><div class="line">    # return l</div><div class="line">    q.put(l)</div><div class="line"></div><div class="line">def multithreading():</div><div class="line">    q = Queue()</div><div class="line">    threads = []</div><div class="line">    data = [[1,2,3], [4,5,6], [7,8,9]]</div><div class="line">    for i in range(3):</div><div class="line">        t = threading.Thread(target = job, args = (data[i], q))</div><div class="line">        t.start()</div><div class="line">        print(&quot;MSG : Number of thread is %s&quot; % threading.active_count())</div><div class="line">        threads.append(t)</div><div class="line">    [t.join() for t in threads]</div><div class="line">    results = []</div><div class="line">    for _ in range(3):</div><div class="line">        results.append(q.get())</div><div class="line">    print(results)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multithreading()</div></pre></td></tr></table></figure>
<h2 id="Global-Interpreter-lock-GIL"><a href="#Global-Interpreter-lock-GIL" class="headerlink" title="Global Interpreter lock(GIL):"></a>Global Interpreter lock(GIL):</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"># ********GIL********:</div><div class="line"># GIL shows that only one calculation unit can be run at a time</div><div class="line"># Therefore, for example, the efficiency of 4-threading is not equal to normal&apos;s * 4</div><div class="line">import threading</div><div class="line">from queue import Queue</div><div class="line">import copy</div><div class="line">import time</div><div class="line"></div><div class="line">def job(l, q):</div><div class="line">    result = sum(l)</div><div class="line">    q.put(result)</div><div class="line"></div><div class="line">def multi(l):</div><div class="line">    q = Queue()</div><div class="line">    threads = []</div><div class="line">    for i in range(4):</div><div class="line">        t = threading.Thread(target = job, args = (copy.copy(l), q), name = &apos;T%i&apos; % i)</div><div class="line">        t.start()</div><div class="line">        threads.append(t)</div><div class="line">    [t.join() for t in threads]</div><div class="line">    total = 0</div><div class="line">    for _ in range(4):</div><div class="line">        total += q.get()</div><div class="line">    print(total)</div><div class="line">    </div><div class="line">def normal(l):</div><div class="line">    total = sum(l)</div><div class="line">    print(total)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    l = list(range(1000000))</div><div class="line">    current_time = time.time()</div><div class="line">    normal(l*4)</div><div class="line">    print(&apos;MSG : normal time: &apos;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multi(l)</div><div class="line">    print(&apos;MSG : multithreading time: &apos;, time.time() - current_time)</div></pre></td></tr></table></figure>
<h2 id="Lock-example-Squential-operation-multi-thread"><a href="#Lock-example-Squential-operation-multi-thread" class="headerlink" title="Lock example(Squential operation multi-thread)"></a>Lock example(Squential operation multi-thread)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"># ********Lock********:</div><div class="line">imort threading</div><div class="line"></div><div class="line">def job1():</div><div class="line">    global A, lock</div><div class="line">    lock.acquire()</div><div class="line">    for i in range(10):</div><div class="line">        A += 1</div><div class="line">        print(&apos;MSG : job1 &apos;, A)</div><div class="line">    lock.release()</div><div class="line">    </div><div class="line">def job2():</div><div class="line">    global A, lock</div><div class="line">    lock.acquire()</div><div class="line">    for i in range(10):</div><div class="line">        A += 10</div><div class="line">        print(&apos;MSG : job2 &apos;, A)</div><div class="line">    lock.release()</div><div class="line">        </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    lock = threading.Lock()</div><div class="line">    A = 0</div><div class="line">    t1 = threading.Thread(target = job1)</div><div class="line">    t2 = threading.Thread(target = job2)</div><div class="line">    t1.start()</div><div class="line">    t2.start()</div><div class="line">    t1.join()</div><div class="line">    t2.join()</div></pre></td></tr></table></figure>
<h1 id="Multiprocessing"><a href="#Multiprocessing" class="headerlink" title="Multiprocessing"></a>Multiprocessing</h1><h2 id="Create-a-process"><a href="#Create-a-process" class="headerlink" title="Create a process"></a>Create a process</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># ********Extend********:</div><div class="line">import multiprocessing as mp</div><div class="line">import threading as td</div><div class="line"></div><div class="line">def job(a, b):</div><div class="line">    print(a + b)</div><div class="line"></div><div class="line"># processing must run in __main__</div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    new_process = mp.Process(target = job, args = (1, 2))</div><div class="line">    new_process.start()</div><div class="line">    new_process.join()</div></pre></td></tr></table></figure>
<h2 id="Example-of-queue-using-in-processing"><a href="#Example-of-queue-using-in-processing" class="headerlink" title="Example of queue using in processing:"></a>Example of queue using in processing:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># ********Queue********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">def job(q):</div><div class="line">    result = 0</div><div class="line">    for i in range(1000):</div><div class="line">        result += i + i ** 2 + i ** 3</div><div class="line">    # return (result)</div><div class="line">    q.put(result)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    q = mp.Queue()</div><div class="line">    # Don&apos;t forget the &apos;,&apos; after args while the number of parameter is one</div><div class="line">    p1 = mp.Process(target = job, args = (q, ))</div><div class="line">    p2 = mp.Process(target = job, args = (q, ))</div><div class="line">    p1.start()</div><div class="line">    p2.start()</div><div class="line">    p1.join()</div><div class="line">    p2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(result1 + result2)</div></pre></td></tr></table></figure>
<h2 id="Efficiency-Comparison-normal-multithreading-multiprocessing"><a href="#Efficiency-Comparison-normal-multithreading-multiprocessing" class="headerlink" title="Efficiency Comparison(normal, multithreading, multiprocessing)"></a>Efficiency Comparison(normal, multithreading, multiprocessing)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"># ********Efficiency Comparison********:</div><div class="line">import multiprocessing as mp</div><div class="line">import threading as td</div><div class="line">from queue import Queue</div><div class="line">import time</div><div class="line"></div><div class="line">def job(q):</div><div class="line">    result = 0</div><div class="line">    for i in range(100000):</div><div class="line">        result += i + i ** 2 + i ** 3</div><div class="line">    # return (result)</div><div class="line">    q.put(result)</div><div class="line">    </div><div class="line">def normal():</div><div class="line">    result = 0</div><div class="line">    for _ in range(2):</div><div class="line">        for i in range(100000):</div><div class="line">            result += i + i ** 2 + i ** 3</div><div class="line">    print(&apos;MSG : normal &apos;, result)</div><div class="line">    </div><div class="line">def multiprocess():</div><div class="line">    q = mp.Queue()</div><div class="line">    p1 = mp.Process(target = job, args = (q, ))</div><div class="line">    p2 = mp.Process(target = job, args = (q, ))</div><div class="line">    p1.start()</div><div class="line">    p1.join()</div><div class="line">    p2.start()</div><div class="line">    p2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(&quot;MSG : Processing &quot;, result1 + result2)</div><div class="line">    </div><div class="line">def multithread():</div><div class="line">    q = Queue()</div><div class="line">    t1 = td.Thread(target = job, args = (q, ))</div><div class="line">    t2 = td.Thread(target = job, args = (q, ))</div><div class="line">    t1.start()</div><div class="line">    t2.start()</div><div class="line">    t1.join()</div><div class="line">    t2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(&quot;MSG : Threading &quot;, result1 + result2)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    current_time = time.time()</div><div class="line">    normal()</div><div class="line">    print(&quot;MSG : normal time: &quot;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multithread()</div><div class="line">    print(&quot;MSG : multithread time: &quot;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multiprocess()</div><div class="line">    print(&quot;MSG : multiprocess time: &quot;, time.time() - current_time )</div></pre></td></tr></table></figure>
<h2 id="Processing-Pool"><a href="#Processing-Pool" class="headerlink" title="Processing Pool"></a>Processing Pool</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"># ********Pool********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">def job(x):</div><div class="line">    return x * x</div><div class="line"></div><div class="line">def multiprocess():</div><div class="line">    pool = mp.Pool(processes = 3)</div><div class="line">    # type = &apos;list&apos;</div><div class="line">    result = pool.map(job, range(10))</div><div class="line">    print(result)</div><div class="line">    # type = &apos;int&apos; </div><div class="line">    result = pool.apply_async(job, (2, ))</div><div class="line">    print(result.get())</div><div class="line">    # Note: pool.apply_async can only input one number for iterating</div><div class="line">    # type = &apos;object&apos;</div><div class="line">    multi_result = [pool.apply_async(job,(i, )) for i in range(10)]</div><div class="line">    print([result.get() for result in multi_result])</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multiprocess()</div></pre></td></tr></table></figure>
<h2 id="Shared-memory"><a href="#Shared-memory" class="headerlink" title="Shared memory"></a>Shared memory</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># ********Shared memory********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">value = mp.Value(&apos;d&apos;, 1)</div><div class="line"># can be only one dimension</div><div class="line">array = mp.Array(&apos;i&apos;, [1,2,3])</div><div class="line"># Value and Array can be share among multiple cores</div></pre></td></tr></table></figure>
<h2 id="Lock-example-avoid-different-cores-processing-out-of-order-with-shared-variable"><a href="#Lock-example-avoid-different-cores-processing-out-of-order-with-shared-variable" class="headerlink" title="Lock example(avoid different cores processing out of order with shared variable)"></a>Lock example(avoid different cores processing out of order with shared variable)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># ********Lock********:</div><div class="line">import multiprocessing as mp</div><div class="line">import time</div><div class="line"></div><div class="line">def job(v, num, l):</div><div class="line">    l.acquire()</div><div class="line">    for _ in range(10):</div><div class="line">        time.sleep(0.1)</div><div class="line">        v.value += num</div><div class="line">        print(v.value)</div><div class="line">    l.release()</div><div class="line"></div><div class="line">def multiprocess():</div><div class="line">    l = mp.Lock()</div><div class="line">    v = mp.Value(&apos;i&apos;, 0)</div><div class="line">    p1 = mp.Process(target = job, args = (v, 1, l))</div><div class="line">    p2 = mp.Process(target = job, args = (v, 3, l))</div><div class="line">    p1.start()</div><div class="line">    p2.start()</div><div class="line">    p1.join()</div><div class="line">    p2.join()</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multiprocess()</div></pre></td></tr></table></figure>
<h1 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h1><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><h3 id="Numpy-Foundation"><a href="#Numpy-Foundation" class="headerlink" title="Numpy Foundation"></a>Numpy Foundation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Foundation********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">array = np.array([[1,2,3],[2,3,4]])</div><div class="line">print(array)</div><div class="line">print(&quot;MSG : number of dims= &quot;, array.ndim)</div><div class="line"># If only have one dimension, shape will be (num, ) which represent it can be iterated</div><div class="line">print(&quot;MSG : shape= &quot;, array.shape)</div><div class="line">print(&quot;MSG : size= &quot;, array.size)</div></pre></td></tr></table></figure>
<h3 id="Numpy-Array"><a href="#Numpy-Array" class="headerlink" title="Numpy Array"></a>Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.array([[2,3,4], [5,6,7]], dtype = np.int)</div><div class="line">print(a.dtype)</div><div class="line"></div><div class="line">b = np.zeros((3, 4), dtype = np.int32)</div><div class="line">print(b)</div><div class="line"></div><div class="line">c = np.ones((3, 4), dtype = np.int32)</div><div class="line">print(c)</div><div class="line"></div><div class="line"># The output is a list of numbers that are approximate to zero </div><div class="line">d = np.empty((3, 4), dtype = np.int32)</div><div class="line">print(d)</div><div class="line"></div><div class="line">e = np.arange(10, 20, 2)</div><div class="line">f = np.arange(12).reshape((3,4))</div><div class="line">print(e)</div><div class="line">print(f)</div><div class="line"></div><div class="line">g = np.linspace(1, 10, 20)</div><div class="line">print(g)</div></pre></td></tr></table></figure>
<h3 id="Some-Useful-Numpy-Calculation-Formula"><a href="#Some-Useful-Numpy-Calculation-Formula" class="headerlink" title="Some Useful Numpy Calculation Formula"></a>Some Useful Numpy Calculation Formula</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Calculation********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.array([10, 20, 30, 40])</div><div class="line">b = np.arange(4)</div><div class="line">c = a - b</div><div class="line"># Output list composed of int numbers</div><div class="line">print(c)</div><div class="line"># Output list composed of boolean elements</div><div class="line">print(b &lt; 3)</div><div class="line">np.dot(a, b)</div><div class="line">rd = np.arange(2, 6)</div><div class="line"># Output has 2 dimensions(0 -&gt; col; 1 -&gt; row)</div><div class="line">np.sum(rd, axis = 1)</div><div class="line">np.min(rd, axis = 0)</div><div class="line">np.max(rd)</div><div class="line">np.argmin(rd)</div><div class="line">np.mean(rd)</div><div class="line">np.average(rd)</div><div class="line">np.median(rd)</div><div class="line"># Output is [2, 5, 9, 14]</div><div class="line">np.cumsum(rd)</div><div class="line"># Output is [1, 1, 1]</div><div class="line">np.diff(rd)</div><div class="line"># Output composed of multi-dimensional array representing  the row and col number of all nonzero elements in rd array respectively</div><div class="line">np.nonzero(rd)</div><div class="line"># sort among each dimensions independent</div><div class="line">np.sort(rd)</div><div class="line">np.sort(rd.reshape((2, 2)))</div><div class="line"># transpose also we can use rd.T to transpose directly</div><div class="line">np.transpose(rd)</div><div class="line"># matrix multiplication</div><div class="line">(rd.T).dot(rd)</div><div class="line">np.clip(rd, 2, 4)</div><div class="line"># Note: we can use axis to choose 0 -&gt; col or 1 -&gt; row as the target for calculation</div></pre></td></tr></table></figure>
<h3 id="Search-From-Numpy-Array"><a href="#Search-From-Numpy-Array" class="headerlink" title="Search From Numpy Array"></a>Search From Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Index Search********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.arange(3, 15).reshape((3, 4))</div><div class="line">A[2] # Output is [11, 12, 13, 14]</div><div class="line">A[2][1] </div><div class="line"># the same as</div><div class="line">A[1, 2]</div><div class="line">A[:, 1]</div><div class="line">A[1, 1:2]</div><div class="line">for row in A:</div><div class="line">    print(row)</div><div class="line"># Trick</div><div class="line">for colume in A.T:</div><div class="line">    print(colume)</div><div class="line"># flat function parse elements from A like a generator</div><div class="line"># Note: A.flat is different from A.flatten()</div><div class="line"># pre-one is an object and the next output a list</div><div class="line">for item in A.flat:</div><div class="line">    print(item)</div></pre></td></tr></table></figure>
<h3 id="Merge-Numpy-Array"><a href="#Merge-Numpy-Array" class="headerlink" title="Merge Numpy Array"></a>Merge Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># ********Merge Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.array([1, 1, 1])</div><div class="line">B = np.array([2, 2, 2])</div><div class="line"># vertical stack with output [[1, 1, 1], [2, 2, 2]]</div><div class="line">C = np.vstack((A, B))</div><div class="line">print(A.shape, C.shape)</div><div class="line"># Horizontal stack with with output [1, 1, 1, 2, 2, 2]</div><div class="line">D = np.hstack((A, B))</div><div class="line"># Note: transpose function can not convert shape(3,) into shape(,3)</div><div class="line">A_ = A[:, np.newaxis]) # newaxis is an extend dimension</div><div class="line"># If we want to get output by merge col-values like [[1, 2], [1, 2], [1, 2]] we can use:</div><div class="line">E = np.hstack((A[:, np.newaxis], B[:, np.newaxis]))</div><div class="line"># the same as:</div><div class="line">F = np.concatenate((A_, A_), axis = 1)</div><div class="line"># Note: np.concatenate((A, B), axis = 1) will shuffle an error because concatenate will reduce dimension when mergement operation happened, and A or B only have one dimension</div></pre></td></tr></table></figure>
<h3 id="Split-Numpy-Array"><a href="#Split-Numpy-Array" class="headerlink" title="Split Numpy Array"></a>Split Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Split Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.arange(12).reshape((3, 4))</div><div class="line"># every pieces should have the same length</div><div class="line">np.split(A, 2, axis = 1)</div><div class="line"># If you want to split into pieces that in different size</div><div class="line"># Binary split from left to right</div><div class="line">np.array_split(A, 3, axis = 1)</div><div class="line"># Vertical split</div><div class="line">np.vsplit(A, 3)</div><div class="line"># Horizontal split</div><div class="line">np.hsplit(A, 2)</div></pre></td></tr></table></figure>
<h3 id="Numpy-Array-Copy"><a href="#Numpy-Array-Copy" class="headerlink" title="Numpy Array Copy"></a>Numpy Array Copy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Array Copy********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.arange(4, dtype = np.float32)</div><div class="line">b = a</div><div class="line">c = a</div><div class="line">d = b</div><div class="line">a[0] = 0.3</div><div class="line"># now a = b = c = d = [0.30000001, 1., 2., 3.]</div><div class="line">b is a # result is True</div><div class="line"># Note: copy object connected with point</div><div class="line">b = a.copy() # deep copy</div><div class="line"># or</div><div class="line">import copy</div><div class="line">b = copy.copy(a)</div><div class="line">a is b # result is False</div></pre></td></tr></table></figure>
<h2 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h2><h3 id="Pandas-Foundation"><a href="#Pandas-Foundation" class="headerlink" title="Pandas Foundation"></a>Pandas Foundation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Data Representation********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">s = pd.Series([1, 3, 6, np.nan, 44, 1])</div><div class="line">dates = pd.date_range(&apos;20170101&apos;, periods = 6)</div><div class="line">df = pd.DataFrame(np.random.randn(6, 4), index = dates, columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df1 = pd.DataFrame(np.arange(12).reshape((3, 4)))</div><div class="line">df2 = pd.DataFrame(&#123;&apos;A&apos;: 1., &apos;B&apos;: pd.Timestamp(&apos;20130102&apos;), &apos;C&apos;: pd.Series(1, index = list(range(4)), dtype = &apos;float32&apos;), &apos;D&apos;: np.array([3] * 4, dtype = &apos;int32&apos;), &apos;E&apos;: pd.Categorical([&apos;test&apos;, &apos;train&apos;, &apos;test&apos;, &apos;train&apos;]), &apos;F&apos;: &apos;foo&apos;&#125;)</div><div class="line">print(df2.dtypes)</div><div class="line">print(df2.index)</div><div class="line">print(df2.columns)</div><div class="line">print(df2.values)</div><div class="line"># Only fit to number elements</div><div class="line">print(df2.describe()) # result index includes count, mean, std, min, 25%, 50%, 75%, max...</div><div class="line">print(df2.T)</div><div class="line"># Sort for columns</div><div class="line">print(df2.sort_index(axis = 1, ascending = False))</div><div class="line"># Sort for column values</div><div class="line">print(df2.sort_values(by = &apos;E&apos;))</div></pre></td></tr></table></figure>
<h3 id="Pandas-Data-Sampling"><a href="#Pandas-Data-Sampling" class="headerlink" title="Pandas Data Sampling"></a>Pandas Data Sampling</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Data Sampling********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">print(df[&apos;A&apos;]) </div><div class="line"># the same as :</div><div class="line">print(df.A)</div><div class="line">print(df[0: 3], &apos;\n&apos;, df[&apos;20130101&apos;: &apos;20130103&apos;])</div><div class="line"># select by label:</div><div class="line">print(df.loc[&apos;20130102&apos;])</div><div class="line">print(df.loc[&apos;20130102&apos;, [&apos;A&apos;, &apos;B&apos;]])</div><div class="line"># select by position:</div><div class="line">print(df.iloc[3, 1])</div><div class="line">print(df.iloc[[1, 3, 5], 1: 3])</div><div class="line"># mixed selection:</div><div class="line">print(df.ix[:3, [&apos;A&apos;, &apos;C&apos;]])</div><div class="line"># Boolean indexing selection:</div><div class="line">print(df[df.A &gt; 8])</div><div class="line"># multi-conditions(Can not use &apos;and&apos;):</div><div class="line">print(df[df[2] &gt; 3][df[1] &lt; 2])</div></pre></td></tr></table></figure>
<h3 id="Pandas-Value-Config"><a href="#Pandas-Value-Config" class="headerlink" title="Pandas Value Config"></a>Pandas Value Config</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># ********Pandas change value********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">df.iloc[2, 2] = 1111</div><div class="line">df.loc[&apos;20130101&apos;, &apos;B&apos;] = 2222</div><div class="line">df[df[&apos;A&apos;] &gt; 0] = 0</div><div class="line"># add a new column</div><div class="line">df[&apos;F&apos;] = np.nan</div><div class="line">df[&apos;E&apos;] = pd.Series(np.arange(6, dtype = np.int32)+1, index = pd.date_range(&apos;20130101&apos;, periods = 6))</div></pre></td></tr></table></figure>
<h3 id="Pandas-Handling-Nan"><a href="#Pandas-Handling-Nan" class="headerlink" title="Pandas Handling Nan"></a>Pandas Handling Nan</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Pandas NaN********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">df.iloc[0, 1] = np.nan</div><div class="line">df.iloc[1, 2] = np.nan</div><div class="line"># &apos;any&apos; means we drop the row as long as nan exist, &apos;all&apos; means we drop the row if all the elements are nan</div><div class="line">print(df.dropna(axis = 0, how = &apos;any&apos;)) # how = &#123;&apos;any&apos;, &apos;all&apos;&#125;</div><div class="line">print(df.drop(&apos;A&apos;, axis = 1))</div><div class="line"># replace nan</div><div class="line">print(df.fillna(value = 0))</div><div class="line">print(df.isnull()) # result is a dictionary with &apos;True&apos; and &apos;False&apos;</div><div class="line">print(np.any(df.isnull()) == True)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Read-and-Write"><a href="#Pandas-Read-and-Write" class="headerlink" title="Pandas Read and Write"></a>Pandas Read and Write</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Read and Write********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line"># Some useful function like: read_csv, read_excel, read_sql, read_json ...</div><div class="line"></div><div class="line">df = pd.read_csv(&apos;Sample.csv&apos;, &apos;r&apos;)</div><div class="line"># Sample.csv</div><div class="line"># A,B,C,D</div><div class="line"># 0,1,2,3</div><div class="line"># 4,5,6,7</div><div class="line"># 8,9,10,11</div><div class="line"></div><div class="line"># Save as pickle file</div><div class="line">df.to_pickle(&apos;Sample.pickle&apos;)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Concatenating"><a href="#Pandas-Concatenating" class="headerlink" title="Pandas Concatenating"></a>Pandas Concatenating</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Concatenating********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">df1 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df2 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df3 = pd.DataFrame(np.ones((3, 4))*2, columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line"># ignore_index will reset the index from top to bottom</div><div class="line">result1 = pd.concat([df1, df2, df3], axis = 0, ignore_index = True)</div><div class="line"></div><div class="line"># concat-join, [&apos;inner&apos;, &apos;outer&apos;]</div><div class="line">df4 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;], index = [1, 2, 3])</div><div class="line">df5 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], index = [2, 3, 4])</div><div class="line"># use NaN as the default value</div><div class="line">result2 = pd.concat([df4, df5], ignore_index = True, join = &apos;inner&apos;) # &apos;inner&apos; only remain the same parts</div><div class="line"></div><div class="line"># concat-join_axes</div><div class="line">result3 = pd.concat([df4, df5], axis = 1, join_axes = [df4.index]) # result&apos;s index is only the index of df4</div><div class="line"></div><div class="line"># append</div><div class="line">df6 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df7 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df8 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], index = [2, 3, 4])</div><div class="line">result4 = df6.append(df7, ignore_index = True)</div><div class="line">result5 = df6.append([df7, df8])</div><div class="line">s1 = pd.Series([1, 2, 3, 4], index = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">result6 = df6.append(s1, ignore_index = True)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Merge-concat-without-the-same-parts"><a href="#Pandas-Merge-concat-without-the-same-parts" class="headerlink" title="Pandas Merge(concat without the same parts)"></a>Pandas Merge(concat without the same parts)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Merge********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line"># merge by index named &apos;key&apos;(may be used in database)</div><div class="line">df1 = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;key&apos;) # we have to make sure these two frames contain the same index named &apos;key&apos;</div><div class="line"></div><div class="line"># consider two keys</div><div class="line">df1 = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K0&apos;, &apos;K1&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)</div><div class="line"># default join = &apos;inner&apos;</div><div class="line">result = pd.merge(df1, df2, on = [&apos;key1&apos;, &apos;key2&apos;])</div><div class="line">result2 = pd.merge(df1, df2, on = [&apos;key1&apos;, &apos;key2&apos;], how = &apos;outer&apos;) # how = &#123;&apos;left&apos;, &apos;right&apos;, &apos;outer&apos;, &apos;inner&apos;&#125;</div><div class="line"></div><div class="line"># consider indicator(detail of merge)</div><div class="line">df1 = pd.DataFrame(&#123;&apos;col1&apos;: [0, 1], &apos;col_left&apos;: [&apos;a&apos;, &apos;b&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;col1&apos;: [1, 2, 2], &apos;col_right&apos;: [2, 2, 2]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;col1&apos;, how = &apos;outer&apos;, indicator = True)</div><div class="line">result1 = pd.merge(df1, df2, on = &apos;col1&apos;, how = &apos;outer&apos;, indicator = &apos;indicator_column&apos;) # rename &apos;indicator&apos;</div><div class="line"></div><div class="line"># merged by index</div><div class="line">df1 = pd.DataFrame(&#123;&apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;]&#125;, index = [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;])</div><div class="line">df2 = pd.DataFrame(&#123;&apos;C&apos;: [&apos;C0&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;, index = [&apos;K0&apos;, &apos;K2&apos;, &apos;K3&apos;])</div><div class="line">result = pd.merge(df1, df2, left_index = True, right_index = True, how = &apos;outer&apos;)</div><div class="line">result1 = pd.merge(df1, df2, left_index = True, right_index = True, how = &apos;outer&apos;)</div><div class="line"></div><div class="line"># handle overlapping</div><div class="line">df1 = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;age&apos;: [1, 2, 3]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K3&apos;], &apos;age&apos;: [4, 5, 6]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;k&apos;, suffixes = [&apos;_boy&apos;, &apos;_girl&apos;], how = &apos;inner&apos;)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Plot-View"><a href="#Pandas-Plot-View" class="headerlink" title="Pandas Plot(View)"></a>Pandas Plot(View)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Plot********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line">import matplotlib.pyplot as plt</div><div class="line"></div><div class="line"># Series</div><div class="line">data = pd.Series(np.random.randn(1000), index = np.arange(1000))</div><div class="line">data = data.cumsum()</div><div class="line"># plt.plot(x = horizontal_value1, y = vertical_value)</div><div class="line">data.plot()</div><div class="line">plt.show()</div><div class="line"></div><div class="line"># DataFrame</div><div class="line">data = pd.DataFrame(np.random.randn(1000).reshape((250, 4)), index = np.arange(250), columns = list((&quot;ABCD&quot;)))</div><div class="line">data = data.cumsum()</div><div class="line">data.plot()</div><div class="line">plt.show()</div><div class="line"></div><div class="line"># scatter -&gt; plt.scatter(x = .., y = ..)</div><div class="line"># plot methods = &#123;&apos;bar&apos;, &apos;hist&apos;, &apos;box&apos;, &apos;kde&apos;, &apos;area&apos;, &apos;scatter&apos;, &apos;hexbin&apos;, &apos;pie&apos;&#125;</div><div class="line">a = data.plot.scatter(x = &apos;A&apos;, y = &apos;B&apos;, color = &apos;DarkBlue&apos;, label = &apos;Class 1&apos;) # only can hold 2 elements</div><div class="line">data.plot.scatter(x = &apos;A&apos;, y = &apos;C&apos;, color = &apos;DarkGreen&apos;, label = &apos;Class 2&apos;, ax = a)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><h2 id="Matplotlib-Foundation"><a href="#Matplotlib-Foundation" class="headerlink" title="Matplotlib Foundation"></a>Matplotlib Foundation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Foundation********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-1, 1, 50)</div><div class="line">y = x * 2 + 1</div><div class="line">plt.plot(x, y)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Figure"><a href="#Matplotlib-Figure" class="headerlink" title="Matplotlib Figure"></a>Matplotlib Figure</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Figure********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.plot(x, y1)</div><div class="line">plt.figure(num = 3, figsize = (8, 5))</div><div class="line">plt.plot(x, y1)</div><div class="line">plt.plot(x, y2, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Setting"><a href="#Matplotlib-Setting" class="headerlink" title="Matplotlib Setting"></a>Matplotlib Setting</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Setting********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.plot(x, y2)</div><div class="line">plt.plot(x, y1, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;)</div><div class="line">plt.xlim((-1, 2))</div><div class="line">plt.ylim((-2, 3))</div><div class="line">plt.xlabel(&apos;I am X&apos;)</div><div class="line">plt.ylabel(&apos;I am Y&apos;)</div><div class="line">new_ticks = np.linspace(-1, 2, 5) # steps</div><div class="line">plt.xticks(new_ticks)</div><div class="line">plt.yticks([-2, -1.8, 0, 1.22, 3], [r&apos;$really\ bad$&apos;, r&apos;$bad$&apos;, r&apos;$normal$&apos;, r&apos;$good$&apos;, r&apos;$really\ good$&apos;]) # alpha need write as &apos;\alpha&apos;</div><div class="line"></div><div class="line"># gca = &apos;get current axis&apos;</div><div class="line">ax = plt.gca()</div><div class="line">ax.spines[&apos;right&apos;].set_color(&apos;none&apos;) # right side of boundarys</div><div class="line">ax.spines[&apos;top&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.xaxis.set_ticks_position(&apos;bottom&apos;)</div><div class="line">ax.yaxis.set_ticks_position(&apos;left&apos;)</div><div class="line">ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;, 0)) # &apos;data&apos; can set to &apos;outward&apos; , &apos;axes&apos;... </div><div class="line">ax.spines[&apos;left&apos;].set_position((&apos;data&apos;, 0))</div><div class="line"></div><div class="line"># Legend</div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.xlim((-1, 2))</div><div class="line">plt.ylim((-2, 3))</div><div class="line">plt.xlabel(&apos;I am X&apos;)</div><div class="line">plt.ylabel(&apos;I am Y&apos;)</div><div class="line">new_ticks = np.linspace(-1, 2, 5) # steps</div><div class="line">plt.xticks(new_ticks)</div><div class="line">plt.yticks([-2, -1.8, 0, 1.22, 3], [r&apos;$really\ bad$&apos;, r&apos;$bad$&apos;, r&apos;$normal$&apos;, r&apos;$good$&apos;, r&apos;$really\ good$&apos;]) # alpha need write as &apos;\alpha&apos;</div><div class="line">l1, = plt.plot(x, y2, label = &apos;up&apos;) # Don&apos;t forget &apos;,&apos;</div><div class="line">l2, = plt.plot(x, y1, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;, label = &apos;down&apos;)</div><div class="line">plt.legend(handles = [l1, l2], labels = [&apos;line 1&apos;, &apos;line 2&apos;], loc = &apos;best&apos;) # loc = &#123;&apos;best&apos;, &apos;upper&apos;, &apos;lower right&apos;, &apos;center&apos;...&#125;</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Annotation"><a href="#Matplotlib-Annotation" class="headerlink" title="Matplotlib Annotation"></a>Matplotlib Annotation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Annotation********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y = 2 * x + 1</div><div class="line">plt.figure(num = 1, figsize = (8, 5))</div><div class="line">plt.plot(x, y)</div><div class="line">ax = plt.gca()</div><div class="line">ax.spines[&apos;right&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.spines[&apos;top&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.xaxis.set_ticks_position(&apos;bottom&apos;)</div><div class="line">ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;, 0))</div><div class="line">ax.yaxis.set_ticks_position(&apos;left&apos;)</div><div class="line">ax.spines[&apos;left&apos;].set_position((&apos;data&apos;, 0))</div><div class="line"></div><div class="line">X0 = 1</div><div class="line">Y0 = 2 * X0 + 1</div><div class="line"># Point</div><div class="line">plt.scatter(X0, Y0, s = 50, color = &apos;b&apos;)</div><div class="line"># Line</div><div class="line">plt.plot([X0, X0], [Y0, 0], &apos;k--&apos;, lw = 2.5)</div><div class="line"># Choice one</div><div class="line">plt.annotate(r&apos;$2x+1=%s$&apos; % Y0, xy = (X0, Y0), xycoords = &apos;data&apos;, xytext = (+30, -30), textcoords = &apos;offset points&apos;, fontsize = 16, arrowprops = dict(arrowstyle = &apos;-&gt;&apos;, connectionstyle = &apos;arc3, rad = .2&apos;))</div><div class="line"># Choice two</div><div class="line">plt.text(-3.7, 3, r&apos;$This\ is\ some\ text.\ \mu\ \sigma_i\ \alpha_t$&apos;, fontdict = &#123;&apos;size&apos;: 16, &apos;color&apos;: &apos;r&apos;&#125;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Foundation-Summary&quot;&gt;&lt;a href=&quot;#Foundation-Summary&quot; class=&quot;headerlink&quot; title=&quot;Foundation Summary&quot;&gt;&lt;/a&gt;Foundation Summary&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Numpy" scheme="http://yoursite.com/tags/Numpy/"/>
    
      <category term="Pandas" scheme="http://yoursite.com/tags/Pandas/"/>
    
      <category term="Matplotlib" scheme="http://yoursite.com/tags/Matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>利用LSTM模型进行手写识别</title>
    <link href="http://yoursite.com/2017/07/25/RNN/"/>
    <id>http://yoursite.com/2017/07/25/RNN/</id>
    <published>2017-07-25T04:03:41.000Z</published>
    <updated>2017-08-04T06:55:59.054Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Recurrent-Neural-Netword-RNN-Using-Tensorflow"><a href="#Recurrent-Neural-Netword-RNN-Using-Tensorflow" class="headerlink" title="Recurrent Neural Netword(RNN) Using Tensorflow"></a>Recurrent Neural Netword(RNN) Using Tensorflow</h1><h1 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>MNIST database of handwritten digits. <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">Click here</a><br>Input data: Image shape(28*28)<br>Output label: 0~9 </p>
<h2 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h2><ul>
<li>Data_Size<ul>
<li><code>Input_dimension</code>: Dimension of each image</li>
<li><code>Output_dimension</code>: Dimension of predicted label</li>
<li><code>Classes</code>: The number of different outputs</li>
</ul>
</li>
<li>Model_Parameter<ul>
<li><code>Training_iter</code>: The number of iterations for training</li>
<li><code>Batch_size</code>: The length of inputeach epoch</li>
</ul>
</li>
</ul>
<h2 id="Requirement"><a href="#Requirement" class="headerlink" title="Requirement"></a>Requirement</h2><ul>
<li><code>Python 2.7</code></li>
<li><code>Tensorflow 0.12.1</code></li>
</ul>
<h1 id="Model-RNN-LSTM"><a href="#Model-RNN-LSTM" class="headerlink" title="Model(RNN + LSTM)"></a>Model(RNN + LSTM)</h1><p>We use a Recurrent Neural Network with <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">LSTM</a> Cell to implement this model.</p>
<ul>
<li>LSTM (Long Short Term Memory):</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="http://upload-images.jianshu.io/upload_images/42741-b9a16a53d58ca2b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="LSTM_MODEL" title="">
                </div>
                <div class="image-caption">LSTM_MODEL</div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://json0071.gitbooks.io/deeplearning/content/LSTM.png" alt="LSTM" title="">
                </div>
                <div class="image-caption">LSTM</div>
            </figure>
<p>LSTM Composed of three gates which called INPUT_GATE, FORGET_GATE and OUTPUT_GATE.</p>
<p>More information about how to implement LSTM Model is <a href="https://www.tensorflow.org/tutorials/recurrent" target="_blank" rel="external">here</a>.</p>
<ul>
<li><strong>Initialize Step</strong></li>
</ul>
<p>First we should initialize the placeholder and weights of our neural network.<br><code>placeholder</code>: just like the <strong>x</strong> of the function:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large f(x) = x^2" style="border:none;"></p>
<p><code>weights</code>: the weight for converting input data to output label.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</div><div class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</div><div class="line"></div><div class="line">weights = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden, n_classes]))</div><div class="line">&#125;</div><div class="line">biases = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><strong>Training Step</strong></li>
</ul>
<p><strong>First</strong> we define a RNN_Model function.<br>Using linear relationship to combine the output parameters.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def RNN_Model(x, weights, biases):</div><div class="line">    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias = 1.0)</div><div class="line">    output, states = tf.nn.rnn(lstm_cell, x, dtype = tf.float32)</div><div class="line">    return tf.matmul(output[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]</div></pre></td></tr></table></figure>
<p><strong>Second</strong> we have to define the loss function and optmizer of our model.<br><code>loss fuction</code>: softmax_cross_entropy<br><code>optimizer</code>: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">prediction = RNN_Model(x, weights, biases)</div><div class="line">result = tf.nn.softmax(prediction)</div><div class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))</div><div class="line">optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)</div></pre></td></tr></table></figure>
<p><strong>Third</strong> in order to evaluate the efficiency of this model, we define the function to calculate accuracy.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> we can start training after all the initialization.</p>
<ul>
<li>We can use session to run our tensorflow function.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    sess.run(init)</div><div class="line">    while &quot;./epoch&quot; &lt; training_iters</div><div class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">        batch_x = batch_x.reshape((batch_size, n_steps, n_input))</div><div class="line">        sess.run(optimizer, feed_dict = &#123;x: batch_x, y: batch_y&#125;</div><div class="line">        if &quot;./batch_size&quot;:</div><div class="line">            acc = sess.run(accuracy, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div><div class="line">            los = sess.run(loss, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div></pre></td></tr></table></figure>
<p><strong>Tips</strong>: “./“ represent the parameters defined by user own.</p>
<ul>
<li><strong>Testing Step</strong></li>
</ul>
<p>After training we get a weights in the tensorflow session which can be used to predict our test data.</p>
<p><strong>First</strong> generate the testing dataset from mnist generator.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">test_data = mnist.test.images[:&quot;./test_length&quot;].reshape(-1, n_steps, n_input)</div><div class="line">res = sess.run(result, feed_dict = &#123;x: test_data&#125;)</div><div class="line">predict_label = sess.run(tf.argmax(res, 1))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> because tensorflow mnist test dataset have its own ground-truth. So we can estimate if our “predict_label” is correct. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">test_label = mnist.test.labels[:&quot;./test_lenght&quot;]</div><div class="line">sess.run(accuracy, feed_dict = &#123;x: predict_label, y: test_label&#125;)</div></pre></td></tr></table></figure>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><ol>
<li><p>Install tensorflow.</p>
<ul>
<li>If we will run our model on GPU we have to install cuda and cuDNN.<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install tensorflow(-gpu)==0.12.1</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Import tensorflow package.</p>
</li>
<li>Import tensorflow mnist dataset and read the dataset as a generator.</li>
<li>Run our model<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python &quot;./model_name&quot;.py</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples/" target="_blank" rel="external">Googel Tensorflow Example</a></li>
</ul>
<h1 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h1><p>In this experiment we use a simple RNN(LSTM) model to predict the handwritten digits which also catch a good consequence in CNN.<br>RNN model is good for using in NLP processing. But how to explore the most useful <strong>determines</strong> whether our model can get an excellent result or not.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot;&gt;&lt;a href=&quot;#Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;Re
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
      <category term="Tensorflow" scheme="http://yoursite.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04遠端桌面（remote desktop）設置</title>
    <link href="http://yoursite.com/2017/07/25/Remote/"/>
    <id>http://yoursite.com/2017/07/25/Remote/</id>
    <published>2017-07-25T04:00:24.000Z</published>
    <updated>2017-08-04T06:55:43.042Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Ubuntu上的遠端鏈接比起windows系統自帶的Remote Desktop需要配置的條件更多。網上也有許多不同的版本，本人嘗試之後發現了一些常見的問題，特在此總結可行的一般流程與常見問題的解決方式。</p>
<h1 id="System-Config"><a href="#System-Config" class="headerlink" title="System Config"></a>System Config</h1><p><code>Ubuntu16.04</code> <code>Windows 10</code></p>
<h1 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h1><p>1、如果需要從Ubuntu連接到Windows系統，則可以安裝Desktop</p>
<ul>
<li>sudo apt-get install ubuntu-desktop</li>
</ul>
<p>2、若只是從Windows鏈接到Ubuntu則跳過第一步，直接安裝遠端桌面軟體xrdp</p>
<ul>
<li><p>sudo apt-get install xrdp</p>
<ul>
<li>此時若打開xrdp的配置文件，可以看到默認的xrdp協定，遠 端桌面則是根據這個來請求遠端服務的。</li>
</ul>
</li>
<li>sudo vim /etc/xrdp/xrdp.ini</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1tOoyic.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>其中port = -1表示默認port(5910)作為登錄的接口，之後的連接可通過這個port連入相同的session（因為遠端連接的port一般可以兼容port5900到5910）如果需要更改連接的port可以在xrdp.ini文檔中修改port為port = ask59XX來請求連接。</li>
</ul>
<p>修改完畢後記得重啟xrdp：</p>
<ul>
<li>sudo service xrdp restart</li>
</ul>
<p>3、此時可以查看service port看是否處於LISTEN的狀態。</p>
<ul>
<li>netstat -utl</li>
</ul>
<p><strong>Important : 必須確保三個port處於監聽狀態</strong></p>
<ul>
<li>port 3389</li>
<li>port 3350</li>
<li>port 59XX</li>
</ul>
<p><img src="https://i.imgur.com/0BgAP4w.png" alt=""></p>
<p>4、確保Ubuntu系統安裝了vnc服務，大部分系統會自行安裝，可以通過重複安裝確認。</p>
<ul>
<li>sudo apt-get install vnc4server<br>或</li>
<li>sudo apt-get install tightvncserver</li>
</ul>
<p>5、由於xrdp會開放3389的port作為遠端圖形化界面的窗口，因此還需要有相應的圖形化桌面套件。<br><strong>Ubuntu常用的桌面套件有三種，選擇一種安裝即可</strong></p>
<ul>
<li>安裝與設定Xfce<ul>
<li>sudo apt install xfce4</li>
<li>echo “xfce4-session” &gt; ~/.xsession </li>
</ul>
</li>
<li>安裝與設定Lxde<ul>
<li>sudo apt install lxde</li>
<li>echo “lxsession -s LXDE -e LXDE” &gt; ~/.xession </li>
</ul>
</li>
<li>安裝與設定Mate<ul>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/ppa</li>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/trusty-mate</li>
<li>sudo apt update</li>
<li>sudo apt install –no-install-recommends ubuntu-mate-core ubuntu-mate-desktop</li>
<li>echo “mate-session” &gt; ~/.xsession</li>
</ul>
</li>
</ul>
<p>6、之後就可以使用遠端桌面連接Windows和Ubuntu了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PBsp6Sc.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>结果如下（Mate）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a1PmzMs.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Common-Problem"><a href="#Common-Problem" class="headerlink" title="Common Problem"></a>Common Problem</h2><ul>
<li>遠端連接出現error-problem connecting：<ul>
<li>通常是因為vnc服務沒有架好，查看port的監聽狀態（詳見步驟3），如果只有3389和3350沒有5910的情況，則需要手動開啟相應的port進行連接。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>vncserver : 1~9 (引號兩邊都需要空格)</li>
<li>在xrdp設定檔中將prot從-1改為ask剛才開啟的port（vncserver設1則開啟5901以此類推）</li>
</ul>
</li>
<li>遠端桌面連接進入出現灰色網格，無圖像，滑鼠變成X：<ul>
<li>出現這種狀況通常是沒有安裝遠端桌面套件，導致圖形化界面無法呈現。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>安裝三種遠端桌面套件的一種（詳見步驟5）</li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;Ubuntu上的遠端鏈接比起windows系統自帶的Remo
    
    </summary>
    
    
      <category term="Ubuntu" scheme="http://yoursite.com/tags/Ubuntu/"/>
    
      <category term="Remote Desktop" scheme="http://yoursite.com/tags/Remote-Desktop/"/>
    
      <category term="xrdp" scheme="http://yoursite.com/tags/xrdp/"/>
    
  </entry>
  
  <entry>
    <title>Python字符編碼問題</title>
    <link href="http://yoursite.com/2017/07/25/Unicode/"/>
    <id>http://yoursite.com/2017/07/25/Unicode/</id>
    <published>2017-07-25T03:52:58.000Z</published>
    <updated>2017-08-04T07:04:41.769Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是编码"><a href="#什么是编码" class="headerlink" title="什么是编码"></a>什么是编码</h1><p>字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編程語言中，我們經常會處理文本編碼之間的轉化問題，因為文本可能存在不同的編碼格式，例如 ASCII、GBK、UTF-8等等。最近在做NN的過程中面臨Corpus的unicode編碼問題，因此需要弄清楚python不同版本對編碼問題的處理策略。</p>
<h2 id="字符的抽象概念"><a href="#字符的抽象概念" class="headerlink" title="字符的抽象概念"></a>字符的抽象概念</h2><p>看了一些網絡上的介紹，發現我們所謂的字符表示文本中單一的一個符號。然而一個字符不是一個字節，例如 “中” 這個字在文本中是一個基礎字符，但是在計算機中卻不是一個字節。一個字符有許多表示方法，不同的表示方法會使用不同的字節數，這就是所謂的編碼。<strong>字符就是文本中的最小單元</strong>。</p>
<h2 id="編碼的方式"><a href="#編碼的方式" class="headerlink" title="編碼的方式"></a>編碼的方式</h2><p>Unicode是一種編碼規範，用來統一表示世界上的各種語言。其作為Python語言中的一種中間轉換碼，如果要對不同編碼格式的文本進行轉換，就必須對字符串解碼（decode）成Unicode，再從Unicode編碼（encode）成另一種編碼格式：</p>
<p><code>decode</code> : 作用是將編碼的字符串轉換成Unicode。<br><code>encode</code> : 作用是將Unicode傳換成其他編碼格式。</p>
<h1 id="Python2-vs-Python3"><a href="#Python2-vs-Python3" class="headerlink" title="Python2 vs Python3"></a>Python2 vs Python3</h1><p>Python3的編碼形式默認為Unicode</p>
<ul>
<li>那麼Python3的文本可以通過encode傳換成bytes嗎？bytes和str一樣嗎？</li>
</ul>
<p>首先bytes不是字符串，那么b ‘a’ 和 ‘a’ 的区别是什么呢？在Python3运行输入出bytes的时候，它采取的原则是这样的：没读一个字节就和ascii码比对一下，如果符合ascii码的字符（特殊字符，字母和数字等除外），那这个字节就按照ascii码来表示，否则就按照十六进制‘\x’的形式来表示。</p>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ctGhV9P.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>因此bytes对象不能由超过0到127的ascii码范围的unicode字<br>符串表示。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8ou3vVE.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>bytes的表示方式为b + (字符串)，如果不用bytes表示，则直接用 ‘\x’ + 两位十六进制数表示一个字节。</p>
<ul>
<li>那么在Python2表示unicode的时候我们使用u + (字符串)的形式表示unicode编码，而Python3中则无需这么做。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2ji3C8E.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y2rtdQM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>注意在Python3中u‘字符串’和‘\u四位十六进制数’是等价的，而且都为str对象。而‘\u四位十六进制数’和‘\u四位十六进制数’却不相同。</li>
</ul>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RZD8Ptn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是编码&quot;&gt;&lt;a href=&quot;#什么是编码&quot; class=&quot;headerlink&quot; title=&quot;什么是编码&quot;&gt;&lt;/a&gt;什么是编码&lt;/h1&gt;&lt;p&gt;字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編
    
    </summary>
    
    
      <category term="Unicode" scheme="http://yoursite.com/tags/Unicode/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04如何安裝搜狗（Sogou）輸入法</title>
    <link href="http://yoursite.com/2017/07/25/Ubuntu-sogo/"/>
    <id>http://yoursite.com/2017/07/25/Ubuntu-sogo/</id>
    <published>2017-07-25T03:48:07.000Z</published>
    <updated>2017-08-04T07:04:32.461Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>目前Ubuntu常用的中文输入法有：</p>
<ul>
<li>搜狗拼音： 搜狗出品的面向Linux的输入法。</li>
<li>Fcitx： 这个是Ubuntu系统自带的Linux开源的输入法框架，提供了包括Google PinYin、ShuangPin、SunPinYin、Hong Kong和TaiWan繁体等一系列输入法。</li>
</ul>
<p>下面主要讲下如何在Ubuntu 16.04上安装搜狗输入法。</p>
<h2 id="安裝過程"><a href="#安裝過程" class="headerlink" title="安裝過程"></a>安裝過程</h2><p>下載安裝檔之前首先需要確認本機的Ubuntu系統是什麼樣的編碼位元。利用“uname -a”指令查詢系統資訊。</p>
<p>下載安裝包，sogou提供了32位和64位版本:<a href="http://pinyin.sogou.com/linux/?r=pinyin" target="_blank" rel="external">http://pinyin.sogou.com/linux/?r=pinyin</a></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/G7PoJFF.png" alt="Sogou" title="">
                </div>
                <div class="image-caption">Sogou</div>
            </figure>
<p>下載完成后可以直接雙擊下載的deb包裝或執行指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo dpkg -i sogoupinyin*.deb</div><div class="line">$ sudo apt -f install</div></pre></td></tr></table></figure></p>
<ul>
<li><strong>第一行指令會提示sogou的一些鏈接錯誤，需用第二條指令解決。</strong></li>
</ul>
<p>安裝完成之後重啟系統。</p>
<p>再次開啟系統后就能夠在輸入法設置菜單看到Sogou的選項了。</p>
<ul>
<li><strong>Tips</strong>：有些版本會出現搜狗與Fcitx的衝突問題，但是本人沒有遇到這個問題，但是仍然提供一個評價最佳的解決策略：(移除其中一種輸入法架構)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo apt remove fcitx*</div><div class="line">$ sudo apt autoremove</div></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;目前Ubuntu常用的中文输入法有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;搜狗拼音： 搜狗出品的面向Linux的输入法。&lt;/li&gt;
&lt;li&gt;Fcitx
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="Ubuntu 16.04" scheme="http://yoursite.com/tags/Ubuntu-16-04/"/>
    
      <category term="sogou输入法" scheme="http://yoursite.com/tags/sogou%E8%BE%93%E5%85%A5%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习（Machine Learning）简单学</title>
    <link href="http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/"/>
    <id>http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/</id>
    <published>2017-07-24T05:48:31.000Z</published>
    <updated>2017-08-01T09:11:37.582Z</updated>
    
    <content type="html"><![CDATA[<p>本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了<a href="https://morvanzhou.github.io/tutorials/machine-learning/" target="_blank" rel="external">莫烦Python</a>的教学视频，发现其中的内容丰富有趣并且具有很好的阶层学习框架。于是总结了一些精髓并加入了自己从事机器学习研究所工作的一些见解，总结了一些精华的部分以供大家快速入门和学习。</p>
<h1 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h1><p>机器学习（Machine Learning）是由一帮计算机科学家们希望让计算机像人类一样思考而延伸出来的一门计算机理论。机器学习最早来自心理和生物科学，科学家们认为人和计算机其实没有什么差别，都是一大批相互连接的信息传递和存储元素所组成的系统。机器学习是一门典型的跨领域科学，其中包含了概率学、统计学等等方面。随着计算机性能的提升和计算机运算速度的升级，机器学习的应用才真正开始融入我们日常的生活当中。而不久的将来，机器学习必将成为人类探索机器世界的关键钥匙。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>图像识别， AI对话式智慧型家居, 聊天机器人， 股市风险预测…</p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>机器学习的实现方式多种多样，在程式语言中我们称之为算法。<br>Machine Learning的学习方式主要包括：</p>
<ul>
<li><strong>监督式学习（Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and Labels</li>
<li><strong>Principle</strong>: 通过让计算机学习这些label来标记相应的value，从中找出它认为重要的部分作为判断依据。（<strong>既定规律</strong>）</li>
<li><strong>Example</strong>: Logistic Regression、Back Propogation Neural Network</li>
</ul>
</li>
<li><strong>非监督式学习（Un-Supervised Learning）</strong><ul>
<li><strong>Input: Values</strong></li>
<li><strong>Principle</strong>: 只提供value的情况下，计算机事先无法得知value所代表的含义以及需要学习的正确结果，这时候就需要让计算机自己学会分类不同的value，从而总结出不同value背后所隐藏的重要规律作为判断依据。（<strong>生成规律</strong>）</li>
<li><strong>Example</strong>: Apriori、K-Means</li>
</ul>
</li>
<li><strong>半监督式学习（Semi-Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and A few Labels</li>
<li><strong>Principle</strong>: 这种学习方式主要让计算机考虑如何利用少量的label总结出最适合value的判断规则，从而引申到更大范围的value中。</li>
<li><strong>Example</strong>: Laplacisn SVM、Graph Inference</li>
</ul>
</li>
<li><strong>强化学习（Reinforcement Learning）</strong><ul>
<li><strong>Input</strong>: Environment and Set of Operations</li>
<li><strong>Principle</strong>: 通过将计算机设定在一个复杂的环境中，让机器去随机尝试各种可能的操作，并通过环境的回馈（正确加分，不正确扣分）的方式让机器的行为向加分的方面靠近，最终适应环境。</li>
<li><strong>Example</strong>: Alpha GO、Robot Control</li>
</ul>
</li>
</ul>
<p>Machine Leaning的算法主要分为这几类：</p>
<ul>
<li><strong>回归算法（Regression）</strong><ul>
<li>该算法主要是试图通过对误差的衡量来探索变量之间的关系问题。常见的回归算法包括：<strong>最小二乘法（Ordinary Least Square）</strong>、<strong>逻辑回归（Logistic Regression）</strong>、<strong>逐步回归（Stepwise Regression）</strong>、<strong>多元自适应回归样条（Multivariate Adaptive Regression Splines）</strong> 和 <strong>本地散点平滑估计（Locally Estimated Scatterplot Smoothing）</strong> 等。</li>
<li>常用的<strong>情形</strong>有：信用评估、度量成功率、预测收入水平、预测地震发生几率等等。</li>
</ul>
</li>
<li><strong>基于实例的算法（Instance-Based Algorithm）</strong><ul>
<li>该算法常常用来对决策性问题建模，通常会选取一批样本数据，然后根据某些特性和新数据样本的比较，通过匹配度来找到最佳的匹配相性。因此可以理解为 <strong>“赢家通吃”</strong> 的贪婪（Greedy）学习方式。</li>
<li>常见的算法包括：<strong>K-Nearest Neighbor（KNN）</strong>、<strong>学习矢量量化（Learning Vector Quantization，LVQ）</strong> 以及 <strong>自组织映射算法（Self-Organizing Map，SOM）</strong>。</li>
</ul>
</li>
<li><strong>正则化方式（Regular Expression）</strong><ul>
<li>该算法是基于回归算法的延伸，根据算法的复杂度对其进行的调整。正则化方法会对简单模型基于奖励而对复杂模型算法基于惩罚（一个类似强化学习的概念）。</li>
<li>常见的算法包括：<strong>Ridge Regression</strong>、<strong>Least Absolute Shrinkage and Selection Operator（LASSO）</strong> 和 <strong>弹性网络（Elastic Net）</strong>。</li>
</ul>
</li>
<li><strong>决策树（Decision Tree）</strong><ul>
<li>该算法根据数据的属性采用树状的结构建立决策模型，常常被用来解决<strong>分类</strong>和<strong>回归</strong>问题。</li>
<li>常见的算法包括：<strong>分类及回归树（Classification And Regression Tree，CART）</strong>、<strong>Iterative Dichotomiser 3（ID3）</strong>、<strong>随机森林（Random Forest）</strong> 以及 <strong>梯度推进（Gradient Boosting Machine，GBM）</strong>。</li>
</ul>
</li>
<li><strong>贝叶斯（Bayesian）</strong><ul>
<li>该算法是基于贝叶斯定理的一类演算法，主要也是来解决<strong>分类</strong>和<strong>回归</strong>的问题。</li>
<li>常见的算法包括: <strong>朴素贝叶斯（Naive Bayesian）</strong>、<strong>平均单依赖评估（Averaged One-Dependence Estimators，AODE）</strong> 以及 <strong>Bayesian Belief Network（BBN）</strong>。</li>
<li>常用范例：垃圾邮件分类、文章分类、情绪分类、人脸识别等。</li>
</ul>
</li>
<li><strong>基于核的算法（Kernel-Based Algorithm）</strong><ul>
<li>该算法最著名的应该是支持向量机（SVM）了，其将输入数据映射到一个高阶的向量空间中，在这些高阶空间里，有些分类或者回归问题就能得到解决。</li>
<li>常见的算法包括：<strong>支持向量机（Support Vector Machine，SVM）</strong>、<strong>径向基函数（Radial Basis Function，RBF）</strong> 和 <strong>线性判别分析（Linear Discriminate Analysis）</strong>。</li>
</ul>
</li>
<li><strong>聚类算法（Clustering）</strong><ul>
<li>该算法和回归类似，就是在处理分类问题的时候，通常以中心点或者分层的方式输入数据进行归并。所以聚类算法目的是找到数据的内部结构，以便按照最大的共同特征进行归类。</li>
<li>常见的聚类算法包括：<strong>K-Means算法</strong> 以及 <strong>期望最大化算法（Expectation Maximization，EM）</strong>。</li>
<li>聚类的关注特征也分为好多种，包括：质心、连通性、密度、概率、维度以及神经网络结构等。</li>
</ul>
</li>
<li><strong>关联法则（Association Rule）</strong><ul>
<li>该算法通过寻找最能解释数据变量之间关系的规则，从而找出大量多元数据集中的有用关联法则。</li>
<li>常见的算法包括：<strong>Apriori算法</strong> 和 <strong>Eclat算法</strong>。</li>
</ul>
</li>
<li><strong>遗传算法（Genetic Algorithm）</strong><ul>
<li>源自进化理论，淘汰弱者，适者生存。通过不断更新和淘汰的机制去选择最优的设计模型。后诞生的模型会继承先带模型的参数，并能够根据环境自我优化或消失。</li>
</ul>
</li>
<li><strong>人工神经网络（Neural Network）</strong><ul>
<li>该算法主要是模拟生物神经网络，属于模型匹配算法的一种。通常用于解决<strong>分类</strong> 和 <strong>回归</strong>的问题。人工神经网络是机器学习的一个庞大分支，有几百种不同的算法结构（包括深度学习）。</li>
<li>重要的神经网络算法包括：<strong>感知神经网络（Perceptron Neural Network）</strong>、<strong>反向传递（Back Propagation）</strong>、<strong>自组织映射（Self-Organizing Map，SOM）</strong>等。</li>
</ul>
</li>
<li><strong>深度学习（Deep Learning）</strong><ul>
<li>深度学习算法是基于人工神经网络的延伸，通过建立更复杂的神经网络结构来提升神经网络的效果。很多深度学习的算法是半监督式学习算法，用来处理少量未label的数据集。</li>
<li>常见的深度学习算法包括：<strong>受限波尔兹曼机（Restricted Boltzmann Machine，RBN）</strong>、<strong>Deep Belief Networks（DBN）</strong>、<strong>卷积网络（Convolutional Network）</strong> 和 <strong>堆栈式自动编码器（Stacked Auto-encoders）</strong>。</li>
</ul>
</li>
<li><strong>降低维度算法（Reduce Dimension）</strong><ul>
<li>与聚类相似，降低纬度算法也是试图分析数据内部的结构，不过该算法属于非监督学习的方式，在缺乏信息的情况下归纳或解释数据。这类算法利用高维度的数据作为监督的label使用，从而完成迁移的降维动作。</li>
<li>常见的算法包括：<strong>主成分分析（Principle Component Analysis，PCA）</strong>、<strong>偏最小二乘回归（Partial Least Square Regression，PLS）</strong> 和 <strong>投影追踪（Projection Pursuit）</strong>等。</li>
</ul>
</li>
</ul>
<h1 id="十大常见机器学习算法"><a href="#十大常见机器学习算法" class="headerlink" title="十大常见机器学习算法"></a>十大常见机器学习算法</h1><p>常用的机器学习算法，几乎可以用在所有的数据问题上：</p>
<h2 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h2><p>线性回归通常用于根据<strong>连续变量</strong>估计实际数值等问题上。通过拟合最佳的<strong>直线</strong>来建立<strong>自变量（X，features）</strong> 和 <strong>因变量（Y，labels）</strong> 的关系。这条直线也叫做回归线，并用<strong>Y = a* X + b</strong>来表示。</p>
<p>在这个等式中：</p>
<ul>
<li><code>Y</code> : 因变量（也就是Labels）</li>
<li><code>a</code> : 斜率（也就是Weights）</li>
<li><code>X</code> : 自变量（也就是Features）</li>
<li><code>b</code> : 截距（也就是Bias）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PSM7e7e.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>系数 <code>a</code> 和 <code>b</code> 可以通过<strong>最小二乘法</strong>（即让所有pairs带入线性表达式等号两边的方差和最小）获得。</p>
<h2 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h2><p>逻辑回归虽然名字中带有<strong>回归</strong>字样，但其实是一个<strong>分类</strong>算法而不是回归算法。该算法根据已知的一系列因变量估计<strong>离散的数值</strong>（0或1，代表假和真）。该算法通过将数据拟合进一个逻辑函数来预估一个事件发生的<strong>概率</strong>。由于其估计的对象是概率，所以输出的值大都在0和1之间。</p>
<p>逻辑回归通常用于解决二分类的问题，例如判断人是男是女等。逻辑回归就是通过人的一些基本性状特征来判断属于男女的概率。</p>
<p>从数学角度看，几率的对数使用的是<strong>预测变量的线性组合</strong>模型。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Probability of event occurence / not occurence</span></div><div class="line">odds = p / (<span class="number">1</span> - p)</div><div class="line">ln(odds) = ln(p / (<span class="number">1</span> - p))</div><div class="line">logit(p) = ln(p / (<span class="number">1</span> - p)) = b0 + b1X1 + b2X2 + ... + bnXn</div></pre></td></tr></table></figure></p>
<p>式子中 <code>p</code> 指的是特征出现的概率，它选用使观察样本可能性最大的值（<strong>极大似然估计</strong>）作为参数，而不是通过最小二乘法得到。</p>
<ul>
<li><p>那么为什么要取对数log呢？</p>
<ul>
<li>简而言之就是对数这种方式是复制阶梯函数最好的方法之一。</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hq1q9Z5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>关于改进模型的方法：<ul>
<li>加入交互项（<strong>X1 * X2</strong>等）</li>
<li>对输入输出进行正规化</li>
<li>使用非线性模型</li>
</ul>
</li>
</ul>
<h2 id="决策树（Decision-Tree）"><a href="#决策树（Decision-Tree）" class="headerlink" title="决策树（Decision Tree）"></a>决策树（Decision Tree）</h2><p>该算法属于监督式学习的一部分，主要用来处理分类的问题，它能够适用于分类连续因变量。我们将主体分成两个或者更多的类群，根据重要的属性或者自变量来尽可能多地区分开来。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8Nj3E0r.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>根据不同的决策属性，我们可以依次将输入进行分类，最终会得到一个标签（Label）。为了把总体分成不同组别，需要用到许多技术，比如<strong>Gini、Information Gain</strong> 和 <strong>Entropy</strong> 等。</li>
</ul>
<h3 id="Gini"><a href="#Gini" class="headerlink" title="Gini"></a>Gini</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ltVHIxt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中的实际分配曲线（红线）和绝对平衡线（绿线）之间的<strong>面积</strong>为A，和绝对不平衡线（蓝线）之间的面积为B，则横纵坐标之间的比例的<strong>Gini系数</strong>为：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {A \over A + B}" style="border:none;"></p>
<ul>
<li>A为零时，Gini系数为0，表示完全平衡。B为零时，Gini系数为1，表示完全不平衡。</li>
</ul>
<h3 id="Information-Gain-amp-Entropy"><a href="#Information-Gain-amp-Entropy" class="headerlink" title="Information Gain &amp; Entropy"></a>Information Gain &amp; Entropy</h3><p>在我们建立决策树的时候，常常会有许多属性，那么用哪一个属性作为数的根节点呢？这个时候就需要用到 <strong>信息增益（Information Gain）</strong> 来衡量一个属性区分以上数据样本的能力强弱。信息增益越大的属性作为数的根节点，就能使得这棵树更加简洁。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/9vwwsJt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>以图中数据为例，要想知道信息增益，就必须先算出分类系的<strong>熵值（Entropy）</strong>。最终结果的label是yes或者no，所以统计数量之后共有9个yes和5个no。这时候<strong>P（“yes”） = 9 / 14，P（“no”） = 5 / 14</strong>。这里的熵值计算公式为：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(S) = {-(9 / 14) * log2(9 / 14) - (5 / 14) * log2(5 / 14)}" style="border:none;"></p>
<ul>
<li>之后就可以计算每一个属性特征的信息增益（Gain）了。以wind属性为例，Wind为Weak的共有8条，其中yes的有6条，no的有2条；为Strong的共有6条，其中yes的有3条，no的也有3条。因此相应的熵值为：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(Weak) = {-(6 / 8) * log2(6 / 8) - (2 / 8) * log2(2 / 8)}" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(Strong) = {-(3 / 6) * log2(3 / 6) - (3 / 6) * log2(3 / 6)}" style="border:none;"></p>
<ul>
<li>现在就可以计算Wind属性的<strong>信息增益</strong>了：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Gain(Wind) = {Entropy(S) -(8 / 14) * Entropy(Weak) - (6 / 14) * Entropy(Strong)}" style="border:none;"></p>
<h2 id="支持向量机（Support-vector-machine-SVM）"><a href="#支持向量机（Support-vector-machine-SVM）" class="headerlink" title="支持向量机（Support vector machine,SVM）"></a>支持向量机（Support vector machine,SVM）</h2><p>SVM是一种常用的机器学习分类方式。在这个算法过程中，我们将每一笔数据在<strong>N维度的空间中用点表示（N为特征总数，Features）</strong>，每个特征的值是一个坐标的值。</p>
<p>如果以二维空间为例，此时有两个特征变量，我们会在空间中画出这两个变量的分布情况，每个点都有两个坐标（分别为tuples所具有的特征值组合）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ea3Jb95.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>现在我们找一条直线将两组不同的数据在维度空间中分开。分割的曲线满足让两个分组中的距离最近的两个点到直线的距离<strong>动态最优化</strong>（都尽可能最近）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/NGsSXtM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>那么看到这里一定很多人和我一样有一个疑问，那就是这种线性分类的SVM和之前提到的逻辑回归（Logistic Regression）有什么<strong>区别</strong>呢？</li>
</ul>
<p>其实他们在二维空间的<strong>线性分类</strong>中都扮演了重要的角色，其主要区别大致可分为两类：</p>
<ul>
<li><p>寻找最优超平面的方式不同。</p>
<ul>
<li>形象来说就是Logistic模型找的超平面（二维中就是线）是尽可能让所有点都远离它。而SVM寻找的超平面，是只让最靠近的那些点远离，这些点也因此被称为<strong>支持向量样本</strong>，因此模型才叫<strong>支持向量机</strong>。</li>
</ul>
</li>
<li><p>SVM可以处理非线性的情况。</p>
<ul>
<li>比Logistic更强大的是，SVM还可以处理<strong>非线性</strong>的情况（经过优化之后的Logistic也可以，但是却更为复杂）。</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/5seIoZJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="朴素贝叶斯（Naive-Bayesian）"><a href="#朴素贝叶斯（Naive-Bayesian）" class="headerlink" title="朴素贝叶斯（Naive Bayesian）"></a>朴素贝叶斯（Naive Bayesian）</h2><p>在假设变量间<strong>相互独立</strong>的前提下，根据贝叶斯定理（Bayesian Theorem）可以推得朴素贝叶斯这个分类方法。通俗来说，一个朴素贝叶斯分类器假设分类的特性和其他特性不相关。朴素贝叶斯模型容易创建，而且在非监督式学习的大型数据样本集中非常有用，虽然简单，却能超越复杂的分类方法。其基本思想就是：对于给出的待分类项，求解<strong>在此项出现的条件下各个目标类别出现的概率</strong>，哪个最大，就认为此待分类项属于哪个类别。</p>
<p>贝叶斯定理提供了从P（c）、P（x）和P（x | c）计算后验概率P（c | x）的方法:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(c | x) = {P(x | c) P(c) \over P(x)}" style="border:none;"></p>
<p>式子中的变量表示如下：</p>
<ul>
<li>P（c | x）是已知预测变量（属性特征）的前提下，目标发生的后验概率。</li>
<li>P（c）是目标发生的先验概率。</li>
<li>P（x | c）是已知目标发生的前提下，预测变量发生的概率。</li>
<li>P（x）是预测变量的先验概率。</li>
</ul>
<p>举一个例子：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gBuFCBd.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这是一个训练资料集，提供一些身体特征，用来预测人的性别。此时假设特征之间独立且满足高斯分布，则得到下表：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eSwuOJV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通过计算方差、均值等参数，同时确认Label出现的频率来判断训练集的样本分布概率，P（male） = P（female） = 0.5。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qZPw7xC.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>此时给出测试资料，我们希望通过计算得到性别的后验概率从而判断样本的类型：</li>
</ul>
<p><strong>男子的后验概率</strong>:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior(male) = {P(male) P(height | male) P(weight | male) P(footsize | male) \over evidence}" style="border:none;"></p>
<p><strong>女子的后验概率</strong>:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior(female) = {P(female) P(height | female) P(weight | female) P(footsize | female) \over evidence}" style="border:none;"></p>
<p>证据因子（evidence）通常为常数，是用来对结果进行归一化的参数。</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Evidence = {(Posterior(female) + Posterior(male)) * evidence}" style="border:none;"></p>
<ul>
<li>因此我们可以计算出相应结果：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(height | male) = {1 \over \sqrt{2\pi\sigma^2}}exp({-(6 - \mu^2) \over 2\sigma^2})" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(weight | male) = ..." style="border:none;"></p>
<ul>
<li>最后可以得出后验概率:</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior Numerator(male) = {6.1984e^{-09}}" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior Numerator(female) = {5.3778e^{-04}}" style="border:none;"></p>
<ul>
<li>因此女性的概率较大，我们估计结果为女性。</li>
</ul>
<h2 id="K近邻（K-Nearest-Neighbors）"><a href="#K近邻（K-Nearest-Neighbors）" class="headerlink" title="K近邻（K Nearest Neighbors）"></a>K近邻（K Nearest Neighbors）</h2><p>该算法可以用于分类和回归问题，然而我们更常将其被用于解决分类问题上。KNN能够存储所有的案例，通过对比周围K个样本中的大概率情况，从而决定新的对象应该分配在哪一个类别。新的样本会被分配到它的K个最近最普遍的类别中去，因此KNN算法也是一个基于距离函数的算法。</p>
<p>这些<strong>距离函数</strong>可以是欧氏距离、曼哈顿距离、明氏距离或是汉明距离。前三个距离函数用于<strong>连续函数</strong>，最后一个用于<strong>分类变量</strong>。如果K = 1，新的样本就会被直接分到距离最近的那个样本所属的类别中。因此选择K是一个关系到模型精确度的问题。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7sGrxz0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如图所示，如果我们取K = 3，即为中间的圆圈内，我们可以直观地看出此时绿点应该被归为红三角的一类。而如果K = 5，此时延伸到虚线表示的圆，则此时绿点应该被归为蓝色的类。</li>
</ul>
<p>在选择KNN之前，我们需要考虑的事情有：</p>
<ul>
<li>KNN在K数量大的时候的计算成本很高。</li>
<li>变量（Features）应该先标准化（normalized），不然会被更高数量单位级别的范围带偏。</li>
<li>越是<strong>干净</strong>的资料效果越好，如果存在偏离度较高的杂讯噪声，那么在类别判断时就会收到干扰。</li>
</ul>
<h3 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h3><p>空间中点X = （X1，X2，X3，…，Xn）与点Y = （Y1，Y2，Y3，…，Yn）的欧氏距离为：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large d(x, y) := {\sqrt{(X1 - Y1)^2 + (X2 - Y2)^2 + ... + (Xn - Yn)^2}}" style="border:none;"></p>
<h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h3><p>在平面上，坐标（X1，X2，…，Xn）的点和坐标（Y1，Y2，…，Yn）的点之间的曼哈顿距离为:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {|X1 - Y1| + |X2 - Y2| + ... + |Xn - Yn|}" style="border:none;"></p>
<h3 id="明氏距离"><a href="#明氏距离" class="headerlink" title="明氏距离"></a>明氏距离</h3><p>两点 P = (X1，X2，…，Xn) 和 Q = （Y1，Y2，…，Yn）之间的明氏距离为:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {(|X1 - Y1|^p + |X2 - Y2|^p + ... + |Xn - Yn|^p)^{1 \over p}}" style="border:none;"></p>
<ul>
<li>其中p取1时为曼哈顿距离，p取2时为欧氏距离。</li>
</ul>
<h3 id="汉明距离"><a href="#汉明距离" class="headerlink" title="汉明距离"></a>汉明距离</h3><p>对于固定长度n，汉明距离是该长度字符串向量空间上的度量，即表示长度n中不同字符串的个数。</p>
<p>例子：</p>
<ul>
<li><strong>“toned”</strong> 和 <strong>“roses”</strong> 之间的汉明距离就是3。因为其中 <strong>t - &gt; r，n -&gt; s，d -&gt; s</strong> 三个字符不相同。</li>
</ul>
<h2 id="K均值（K-means）"><a href="#K均值（K-means）" class="headerlink" title="K均值（K-means）"></a>K均值（K-means）</h2><p>K-means方法是一种<strong>非监督式学习</strong>的算法，能够解决<strong>聚类</strong>问题。使用K-means算法将一个数据样本归入一定数量的集群中（假设有K个）中，每一个集群的数据点都是均匀齐次的，并且异于其它集群。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/WQlIGo4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>K-means算法如何形成<strong>集群</strong>？</p>
<ul>
<li>给一个集群选择K个点，这些点称为质心。</li>
<li>给每一个数据点与距离最接近的质心形成一个集群，也就是K个集群。</li>
<li>根据现有的类别成员，找出每个类别的质心。</li>
<li>当有新的样本输入后，找到距离每个数据点最近的质心，并与质心对应的集群归为一类，计算新的质心位置，重复这个过程直到数据收敛，即质心位置不再改变。</li>
<li>如果新的数据点到多个质心的距离相同，则将这个数据点作为<strong>新的质心</strong>。</li>
</ul>
<p>如何决定K值？</p>
<ul>
<li>K-means算法涉及到集群问题，每个集群都有自己的质心。一个集群的内的质心和个数据点之间的距离的平方和形成了这个集群的平方值之和。我们能够直观地想象出当集群的内部的数据点增加时，K值会跟着下降（数据点越多，分散开来每个质心能够包揽的范围就变大了，这时候其他的集群就会被吞并或者分解）。<strong>集群元素数量的最优值</strong>也就是在集群的平方值之和最小的时候取得（每个点到质心的距离和最小，分类最精确）。</li>
</ul>
<h2 id="随机森林（Random-Forest）"><a href="#随机森林（Random-Forest）" class="headerlink" title="随机森林（Random Forest）"></a>随机森林（Random Forest）</h2><p>Random Forest是表示<strong>决策树总体</strong>的一个专有名词。在算法中我们有一系列的决策树（因此为<strong>森林</strong>）。为了根据一个新的对象特征将其分类，每一个决策树都有一个分类结果，称之为这个决策树<strong>投票</strong>给某一个分类群。这个森林选择获得其中（所有决策树）<strong>投票数最多</strong>的分类。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/xViexYM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Random Forest中的Decision Tree是如何形成的？</p>
<ul>
<li>如果训练集的样本数量为N，则从N个样本中用重置抽样的方式随机抽取样本。这个样本将作为决策树的训练资料。</li>
<li>假如有N个输入特征变量，则定义一个数字<strong>m &lt;&lt; M</strong>。m表示从M中随机选中的变量，这m个变量中最好的切分特征会被用来当成节点的决策特征（利用Information Gain等方式）。在构建其他决策树的时候，m的值<strong>保持不变</strong>。</li>
<li>尽可能大地建立每一个数的节点分支。</li>
</ul>
<h2 id="降维（Dimensionality-reduction）"><a href="#降维（Dimensionality-reduction）" class="headerlink" title="降维（Dimensionality reduction）"></a>降维（Dimensionality reduction）</h2><p>当今的社会中信息的捕捉量都是呈上升的趋势。各种研究信息数据都在尽可能地捕捉完善，生怕遗漏一些关键的特征值。对于这些数据中包含许多特征变量的数据而言，看似为我们的模型建立提供了充足的<strong>训练材料</strong>。但是这里却存在一个问题，那就是<strong>如何从上百甚至是上千种特征中区分出样本的类别呢？</strong>样本特征的<strong>重要程度</strong>又该如何评估呢？</p>
<ul>
<li>其实随着输入数据特征变量的增多，模型很难拟合众多样本变量（高维度）的数据分类规则。这样训练出来的模型不但<strong>效果差</strong>，而且<strong>消耗大量的时间</strong>。</li>
<li>这个时候，降维算法和别的一些算法（比如<strong>Decision Tree</strong>、<strong>Random Forest</strong>、<strong>主成分分析（PCA）</strong> 和 <strong>因子分析</strong>）就能帮助我们实现根据相关矩阵，压缩维度空间之后总结特征规律，最终再逐步还原到高维度空间的训练模式。</li>
</ul>
<h3 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h3><p>在多元统计分析中，PCA是一种分析、简化数据集的技术，经常用于减少数据集的维数，同时保留数据集中的<strong>对方差贡献最大</strong>的那些特征变量。</p>
<ul>
<li>该算法会根据不同维度的压缩（在这个维度上的<strong>投影</strong>）来测试<strong>各个维度对方差的影响</strong>，从而对每一个维度进行重新排序（影响最大的放在第一维度）。之后只需要取有限个数的维度进行训练，就能够保证模型拟合最佳的数据特征了。</li>
</ul>
<h3 id="因子分析"><a href="#因子分析" class="headerlink" title="因子分析"></a>因子分析</h3><p>该算法主要是从关联矩阵内部的依赖关系出发，把一些重要信息重叠，将错综复杂的变量归结为少数几个不相关的综合因子的多元统计方法。基本思想是：根据<strong>相关性大小</strong>把变量分租，使得同组内的变量之间相关性高，但不同组的变量不相关或者相关性低。每组变量代表一个基本结构，即公共因子。</p>
<h2 id="Gradient-Boost-amp-Adaboost"><a href="#Gradient-Boost-amp-Adaboost" class="headerlink" title="Gradient Boost &amp; Adaboost"></a>Gradient Boost &amp; Adaboost</h2><p>当我们想要处理很多数据来做一个具有高度预测能力的预测模型时，我们会用到Gradient Boost和AdaBoost这两种Boosting算法。<strong>Boosting算法</strong>是一种集成学习算法，它结合了建立在多个基础估计值上的预测结果，来增强单个估计值的准确度。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eOKOw6J.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h3><p>Bossting能够对一份数据建立多个模型（如分类模型），通常这些模型都比较简单，称为<strong>弱分类器（Weak Learner）</strong>。每次分类都将上一次分错的数据权重值调大（放大的圆圈），然后再次进行分类，最终得到更好的结果。最终所有学习器（在这里值分类器）共同组成完整的模型。</p>
<h3 id="Gradient-Boost"><a href="#Gradient-Boost" class="headerlink" title="Gradient Boost"></a>Gradient Boost</h3><p>与Adaboost不同的是，Gradient Boost在迭代的时候选择梯度下降的方向来保证最后的结果最好。损失函数（Loss function）用来描述模型的误差程度，如果模型没有Over fitting，那么loss的值越大则误差越高。如果我们的模型能够让损失函数值下降，说明它在不断改进，而最好的方式就是让函数在<strong>梯度的方向</strong>上改变。（类似神经网络的<strong>Gradient Descend</strong>）</p>
<h1 id="什么是神经网络（Neural-Network）"><a href="#什么是神经网络（Neural-Network）" class="headerlink" title="什么是神经网络（Neural Network）"></a>什么是神经网络（Neural Network）</h1><p>基于生物学的神经结构，将神经细胞的电信号传播机制应用到计算机结构中来，通过对信号传导和演变来组成网络架构。人工神经网络中的每一个“神经元”就是一个Neuron，用来以一定的算法改变输入的信号，从而改变传输的信息，达到对环境做出反应的目的。另一方面，通过神经网络产生的反应收到环境的反馈（做的好或不好），这些反馈和目标行为的误差会通过神经网络的反向传递从原先的路径传送回去，沿途中这些反馈信号会反过来刺激Neuron调整相应的参数从而使得下一次正向传递的结果能够更加贴近目标。如此往复便是整个神经网络训练的过程。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/umtL8L5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>人类通过学习，能够掌握和判别事物的特征从而对事物的本质做出判断，而机器同样是利用这种机制建立起相应的“识别”模型，这些模型对不同的事物具有不同的反应强度，利用强度的不同来区别事物的本质。</p>
<h2 id="神经网络的基本结构"><a href="#神经网络的基本结构" class="headerlink" title="神经网络的基本结构"></a>神经网络的基本结构</h2><p>一个简单的神经网络由3个部分组成：</p>
<ul>
<li><strong>Input Layer</strong><ul>
<li>输入层，用来将资料喂给神经网络</li>
</ul>
</li>
<li><strong>Hidden Layer</strong><ul>
<li>隐藏层，用来尝试改变和调整神经网络的模型和数据的转化</li>
</ul>
</li>
<li><strong>Output Layer</strong><ul>
<li>输出层，用来将神经网络处理后的信号输出成最终的结果</li>
</ul>
</li>
</ul>
<h2 id="神经元（Neuron）的激活函数（Activation-Function）"><a href="#神经元（Neuron）的激活函数（Activation-Function）" class="headerlink" title="神经元（Neuron）的激活函数（Activation Function）"></a>神经元（Neuron）的激活函数（Activation Function）</h2><p>在神经网络学习的过程中，需要对输入的信号做出某种调整，才能真正得到最终的结果。<br>传统的激活函数包括：<br><strong>Sigmoid</strong>、<strong>TanHyperbolic(tanh)</strong>、<strong>ReLu</strong>、 <strong>softplus</strong>以及<strong>softmax</strong>函数</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LT2BXvM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>例如当我们输入一只猫，输入层神经网络会把信号传递给隐藏层的神经元。每一个接收到信息的神经元会通过自己现有的经验对信号做出判断，利用激活函数（activation function）来判断此时的神经元是否需要被激活。激活后的神经元就会对输入信号进行处理并传递给下一层的神经网络层，如此往复当信号传递到输出层时则会经由最终的刺激函数（一般为softmax）产生相应的结果确定输出的信号是属于哪一个标签（label）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vYgqqHJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果此时计算机得到了错误的结果，我们就会通过反向的传递将误差传导回去，改变<strong>所有</strong>的神经元参数，继而那些原本活跃的神经元就会被弱化，在下一次的神经传导过程中就会逐渐被激活函数淘汰。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UHIK2YN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>经过更新的神经网络能够在下一次迭代过程（epoch）中就会改变思路，转而尝试其他的判断方法。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/so90M0c.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>直到得到正确的结果，误差就会小到可以忽略，如此神经网络得以生成。</p>
<h2 id="卷及神经网络（CNN）"><a href="#卷及神经网络（CNN）" class="headerlink" title="卷及神经网络（CNN）"></a>卷及神经网络（CNN）</h2><p>卷积神经网络（Convolution Neural Network）在图片识别方面能够给出不错的结果。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y65bdvJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TZ1jOeO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用<strong>图片</strong>作为例子，任何输入的信号都会被转化成计算机能够识别的数字信号集合，例如矩阵（matrix）。<strong>文字</strong>也是一样的，我们把文字抽象成一个固定维度的向量，在这个维度空间中，每个字都是独立区别开来的，文字的多样性就有这些数字的排列组合来定义。这些信号集会通过输入层读取信息并进入神经网络中。<br>卷积神经网络就是其中的一种网络模式，我们可以把它分成<strong>卷积</strong>和<strong>神经网络</strong>两个部分来理解。</p>
<ul>
<li><strong>卷积</strong>：可以理解为对一个区域信号强弱的总体分析。通过卷积运算可以在一定的区域内总结有用信号的强弱分布，从而对一定区域内信号的变化情况能够有一个较好的认知。卷积能够增强信号的连续性，用区域单位代替点电位。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uOav6gV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><strong>神经网络</strong>：卷积神经网络利用批量过滤的方式，在大范围的信号中不断收集信息，每一次得到的区域信息都是区域中的一小块，之后从这些信息中总结出一些所谓的边缘信号（edges，例如：竖线，横线，斜线，圆圈等基本边缘，其可能分别代表人脸眼睛的左上角，中间，右上角等等部位的区域信息）。同样，用相同的方式从边缘信息组合的图像中总结出更大范围的边缘信息（例如：利用竖线，横线，圆圈等结构组合出整个眼睛）。最后将得到的结果传入全连接层的分类神经网络中就能得到相应的label了。</li>
</ul>
<p><strong>Example：</strong> </p>
<p><img src="https://i.imgur.com/fScPOCU.png" alt=""></p>
<p>图片的维度信息有长、宽和高，长和宽用来表示图片的信号集，高度则是表示颜色的信号分布。被白颜色只有1个高度单位，而彩色的图片则有R、G、B三种基本颜色的信息单位。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VmMQcSI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用批量过滤从图片中收集一定区域中的像素块，而输出的值就是一个高度更高，长和宽都更小的图片。这些图片存储的就是边缘（edges）信息。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/twaqQCR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>反复进行同样的过滤步骤，就可以对图片的信息有更好的理解。之后再对结果进行分类就行了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ikChVno.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在卷积的过程中，神经元可能无意中会丢失一些信息。池化（pooling）就是为了解决这样的问题而被设计出来的。既然我们的信息是在卷积过程中压缩的时候丢失的，那么我们就舍弃这个步骤，直接保留原本的长宽，最后在由池化层统一进行压缩长宽的动作。</p>
<h3 id="CNN常用结构"><a href="#CNN常用结构" class="headerlink" title="CNN常用结构"></a>CNN常用结构</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zugYmYR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>比较流行的<strong>CNN结构</strong>先是输入信号，经过卷积层进行卷积运算，然后经过池化压缩长宽的维度。常用的是Max Pooling的结构：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/T3B3QjS.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在区域中区最大值作为代表这个区域的信号。之后再次对结果进行相同的卷积和池化，进一步压缩信号。之后通过两个全连接层将信号传导给分类器进行分类预测。</p>
<h2 id="递归神经网络（RNN）"><a href="#递归神经网络（RNN）" class="headerlink" title="递归神经网络（RNN）"></a>递归神经网络（RNN）</h2><p>递归神经网络（Recurrent Neural Network）在自然语言处理和序列化信息分析方面能够给出不错的结果。如果说CNN是图像识别的代表性神经网络，那么RNN就是文字处理领域的“CNN”。</p>
<ul>
<li><strong>语言文字</strong>就是一个典型的<strong>序列化信号集</strong>，我们说出的每一句话之间，甚至每一个词之间都有先后关系的依赖，如果抛开字的先后顺序，我们的语言将会失去原本的含义。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/afEYtWN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>假设现在有许多不同的数据信号，如果神经网络只是基于当前的输入信号进行结果的预测，那么就相当于无视了所谓的连续规则，其中必然会丢失重要的时序信息。就好比做菜，酱料A要比酱料B先放，否则就会导致串味的现象。因此一般的NN结构无法让机器了解数据之间的关联。</p>
<p><strong>那么要如何做到让计算机也具有处理连续信号的能力呢？</strong></p>
<ul>
<li>从人的角度出发，不难想到的方式就是记住先前处理过的信号，并将这些信号一同作为输入传递到当前的神经网络中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/AUqu2Ss.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们将先前处理的结果存入记忆中，在分析当前信号时会产生新的记忆。由于记忆之间不会相互关联，因此我们可以直接将先前的记忆调用过来一起进行处理：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/D86UcOA.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如此一来往复多次，神经网络就能携带长期的序列信号进行处理了。<strong>总结之前的流程：</strong></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/MW1BRcu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN运作过程中，每次的结果都会被存储为一个State状态信号，并通过不断迭代传递到下一个乃至更远的神经网络中去。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/iQKtiQP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN下一个时刻到来时，State状态同样会被存储成T+1时刻的State，但这是的 <strong>Y（t）</strong> 不再只是由 <strong>S（t+1）</strong> 来决定的，而是通过 <strong>S（t）</strong> 和 <strong>S（t+1）</strong> 共同处理 <strong>X(t+1)</strong> 得到的结果。因此这个State结构也可以用递回的方式来表示。</li>
</ul>
<h3 id="RNN常用结构"><a href="#RNN常用结构" class="headerlink" title="RNN常用结构"></a>RNN常用结构</h3><p>RNN的形式多种多样，一般需要根据处理的情况不同选择相应适合环境的模型进行建模。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/aZqWHqb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通常可以看到以下几种：</p>
<ul>
<li>如果是用于<strong>分类</strong>的话，例如在判断一句话的情感取向，判断是positive或者negative的情况下，倾向于使用根据最终结点的结果来输出判断的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Noc6AFL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>描述</strong>的话，例如通过一些集成度高的特征信号（图片等）来产生一个描述性的句子或者序列的情况下，倾向于使用根据单一输入来逐步读取时序信息的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2zP4G0h.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>翻译</strong>的话，例如通过一段连续的输入信号来预测下一段连续输出信号的情况下，倾向于使用多对多输出的序列化RNN（Sequence-to-Sequence）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LJSO3JG.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="神经网络非监督式学习实现Autoencoder"><a href="#神经网络非监督式学习实现Autoencoder" class="headerlink" title="神经网络非监督式学习实现Autoencoder"></a>神经网络非监督式学习实现Autoencoder</h1><p>在神经网络训练过程中，往往会需要输入大量的信息，而这些信息对于计算机的学习来说具有十分巨大的负担。想想人类的学习过程，如果一次性塞给我们大量的信息，不但达不到很好的学习效果，还会浪费大量的时间。</p>
<p>因此我们需要一个特殊的神经网络来将原本的信息进行压缩，提取其中最具有代表性的信息，这个网络就是所谓的<strong>编码器（encoder）</strong>。之后再通过放大压缩后的信息，重现原始资料的全部信息，也就是 <strong>解码（decoder）</strong> 的过程。而我们所需要做的就是取得编码器压缩之后的简要信息，送入神经网络进行学习，从而达到我们的目的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/SfOfLbo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>压缩和解压的过程共同构成自编码（Autoencoder）的行为，通过训练编码器和解码器的神经网络结构，依据每次压缩前和解压后数据的对比情况来判断压缩的好坏程度，并利用反向传递来修正误差，从而最大程度上的压缩和还原原始信号。由于从头到尾我们所需要的输入信息为原始信号的信息，整个过程不需要对应的标签信息（label），因此autoencoder属于非监督学习的方式。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BidenDF.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通常会使用到的部分是自编码的结果，也就是压缩过后的概括性讯息。我们建构的其他神经网络只需要对这些精髓的信息进行学习就行了。这样的方式不仅减少了神经网络的负担，还能达到很好的学习效果。</li>
</ul>
<p>自编码的思路和传统的主成分分析算法的精髓类似，都是试图从数据中抓住决定性的关键内容，来概括和分类数据的特征。相比于传统的降维算法中的PCA主成分分析方法，Autoencoder甚至能够取得更好的效果，因此也常被用来对原始数据进行<strong>降维</strong>。</p>
<h1 id="生成对抗网络（GAN）"><a href="#生成对抗网络（GAN）" class="headerlink" title="生成对抗网络（GAN）"></a>生成对抗网络（GAN）</h1><p>生成对抗网络（Generative Adversarial Net）不同于传统的FNN、CNN和RNN是将输入的数据和输出的结果通过某种关系联系起来的神经网络模型，GAN则是一种<strong>凭空生成结果</strong>的模型。</p>
<ul>
<li>当然所谓的 <strong>凭空</strong> 并不是真正意义上的<strong>无</strong>，而是通过一些随机的尝试（随机数组合）创造出一些东西。比如一张图片（像素集合）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/lOfWUK4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们可以把这个随机尝试生成图片的网络比喻成一名新手画家，他们根据自己的灵感用现有的技术生成一些画作。一开始可能有了灵感但是由于作画技术的限制，往往无法生成理想中的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/tU6ZZEW.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>于是这名画家就找到了自己的好朋友新手鉴赏家，可是因为新手鉴赏家本身不具备良好的分辨能力，因此往往给出错误的回答。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a3YNuV0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这个时候就会有外部的干涉参与其中，通过一些标记好的资料来训练这名新手鉴赏家，让他一步步能够辨别画作的好坏。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ou0PBfm.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>最重要的是在训练新手鉴赏家的过程中，随着鉴赏技术不断成熟，鉴赏家开始对新手画家的一些作品做出正确的判断和反馈。这时新手画家就会从这个新手鉴赏家手中得到<strong>真正的有用的标签（label）</strong>，进而利用这些标签改变自己的网络，让自己能够画得更好。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PW7ll1Q.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>总结之前的流程，就是新手鉴赏家这个神经网络利用从外部监督得到的反馈提升自己，然后再利用自己去训练另外一个神经网络，随着新手画家神经网络的不断提升，鉴赏家网络得知自己的能力已经无法鉴赏该画作时，就再次求助外部反馈。就在这一次一次地<strong>对抗</strong>中，两个神经网络就会越来越强大。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/huvFBco.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在GAN网络中，新手画家就是我们的<strong>生成器（Generator）</strong>，新手鉴赏家就是所谓的<strong>Discriminator（辨别器）</strong>，画家的每一幅画都是通过不同的数字排列组合成的像素矩阵，也就是我们说的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BtcBwwU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="GAN的应用"><a href="#GAN的应用" class="headerlink" title="GAN的应用"></a>GAN的应用</h2><p>GAN因为能够通过随机组合产生新的数据，因而常被用在数据的合成和生成新数据的方面。</p>
<ul>
<li>其中一个重要的例子就是数据序列的加减法：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7NxbFvF.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中的二次元人物是通过GAN神经网络的学习，然后利用描述性的选项组合，来生成不同特征的人物图像的一个神经网络网络应用。</p>
<h1 id="理解神经网络的“-黑盒子-”"><a href="#理解神经网络的“-黑盒子-”" class="headerlink" title="理解神经网络的“ 黑盒子 ”"></a>理解神经网络的“ 黑盒子 ”</h1><p>神经网络的成功之处在于它能够从输入和输出的数据中总结出一个抽象的算法函式，基于这个函式的关系我们就能够对未知的数据进行预测。</p>
<p>例如：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y = {ax + b \over 2}" style="border:none;"></p>
<p>这个就相当于一个已经训练好的神经网络模型，对于输入信号<code>X</code>通过网络的处理之后得到输出结果<code>Y</code>。</p>
<p>而神经网络建立的模型就像是把算法公式中所有参数进行一个<strong>封装</strong>，然后开放一个相应的<strong>接口(Interface)</strong>用于呼叫和取值。因此神经网络也被亲切地称之为 <strong>“ 黑匣子 ”</strong> 。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/U5riVAp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>神经网络一般分为三个部分，输入和输出都是人类能够理解的信息，而中间的部分就是所谓的<strong>盲区</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uZpZxdz.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果我们将神经网络的中间层注意拆解后会发现输出的事物往往会是我们看不懂的东西，这就是为什么神经网络 <strong>“黑”</strong> 的原因了。对于人而言，我们在记忆复杂的环境和事物时往往会用一些自己熟知的<strong>记号来标记事物</strong>，使得我们能够更加清楚地记得事物的特征。计算机也是一样的：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gdW7DwM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们知道神经网络处理的信息大都是数字集，通过神经层的分离可以看到这些数字集发生了改变，这些改变在人类看来无法理解，但事实上却是计算机利用自己的方式将这些事物通过它们捕捉到的特征信息转换成<strong>它们眼中的记号</strong>。也就是说计算机正在试图用自己能够理解的方式标记这些特征。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FF8SNDZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在神经网络中，我们称人们能够识别的<strong>特征</strong>记作<strong>Features</strong>，而机器转换后的<strong>特征标记</strong>记作<strong>Feature Representation</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ZrHPbGp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>利用手写数字的特征来理解的话，神经网络的Feature Representation就是空间中不同区域的分布状况。不同的位置聚集了不同的数字集合，落在不同的区域内就说明该输入属于哪一个输出。也就是说计算机把我们熟知的<strong>数字（也就是Features）</strong> 用 <strong>空间坐标区域（也就是Feature Representation）</strong> 来表示。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1GT46F0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>理解神经网络的内部结构和Feature Representation的含义可以很好地利用 <strong>迁移学习（Transform Learning）</strong> 的方式来组合我们的神经网络，从而达到更好的效果。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hE5VgF2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>例如我们已经训练好了从图片中解析物体的神经网络，它能够从图像的序列信息中提取关键的特征事物，此时只需要将输出层替换掉，再加入新的神经网络结构进行连接，就可以生成全新的模型。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qslxK9t.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>新的神经网络重新训练之后就能够具有全新的功能，利用原先的网络优势来拓展生成新的<strong>特征标记</strong>，一定程度上减少了神经网络训练的复杂度。基于先前的图像提取，能够从图中得到事物的<strong>特征信息（Feature Representation）</strong>，再利用新的网络将这些信息进一步转换成表示事物价格的<strong>特征信息</strong>，如此一来神经网络的功能就得以演化了。</li>
</ul>
<h1 id="如何优化神经网络（Optimization）"><a href="#如何优化神经网络（Optimization）" class="headerlink" title="如何优化神经网络（Optimization）"></a>如何优化神经网络（Optimization）</h1><p>优化（Optimization）一直是人类领先于其他生物而在环境中不断成长的重要因素，机器也不例外，通过优化的方式自我更新才能不被复杂的环境所淘汰。</p>
<h2 id="神经网络梯度下降算法（Gradient-Descent）"><a href="#神经网络梯度下降算法（Gradient-Descent）" class="headerlink" title="神经网络梯度下降算法（Gradient Descent）"></a>神经网络梯度下降算法（Gradient Descent）</h2><p>神经网络能够自我学习自我更新不仅仅归功于它能够学习并记忆输入和输出的规律，最重要的是它能够根据学习的规律进行自我调整以让自身适应这个变化的环境。那么机器学习模块又是如何进行优化的呢？答案就是所谓的<strong>梯度下降</strong>了。</p>
<ul>
<li>先前说过神经网络的自我调整是基于结果的反馈，也就是所谓的误差来修正自己：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost = {(predicted - real)^2}" style="border:none;"></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/jwReIP2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Cost函式表达的结果近似可以看成一条平滑的二次曲线，而在更高纬度的层面上就是一个<strong>弯曲的面</strong>，越是接近曲面的底部，误差的Cost就会越小。而梯度下降（Gradient Descent）就是在这个曲面中通过微分的方式找到一个能够向最低点移动的方向，并以此作为动力开始优化自己。当达到最低点时，求导的结果和二次曲线相切，这个时候梯度就消失了，也就是所谓的最佳化状态。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RGjpuX3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>然而按照理论而言，这样的方式也太容易得到想要的结果了，那么神经网络的优化（Optimization）也太神了吧，其实这一切是<strong>很难实现</strong>的。</p>
</li>
<li><p>不同于之前所看到的梯度下降曲面，我们生活中的信号往往需要有许多的维度来表示，尤其是复杂的信号（例如图片或者文字）。这些信号在低纬度的时候几乎无法将他们区别分类，因此我们只能将他们丢到更高的维度上面进行非线性分割。这时候就会存在一个问题了，随着维度的提高，我们所熟知的曲面渐渐变得不再平滑了：</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3UNJkcZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这样的曲面反映出一个关键问题就是<strong>优化的不确定性</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/4PmjIUv.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在多维的复杂曲面中，我们能够找到不止一个梯度消失的点，而这些至低点并不都是我们所谓的<strong>最优解</strong>。当我们初始化的位置不同，我们的结果就会随着梯度下降（Gradient Descent）的优化模式寻找距离自己最近的一些至低点。如此一来<strong>不同的初始值</strong>就会很大程度上影响我们优化的结果。针对这个问题，目前比较好的解决方式就是给信号加上一个 <strong>动量（Momentum）</strong> 以至于在运动至最低点的时候，动量会趋势信号的Cost继续改变（此时梯度又恢复了）。如果我们设定的动量足以让信号摆脱当前的梯度曲面（说明曲面不够深，也就是所谓的局部最优解），信号就会继续去寻找一个更加<strong>难以摆脱的梯度曲面（更深）</strong>，如此一来就能够尽量靠近<strong>全局最优解</strong>。</li>
</ul>
<h1 id="如何评估神经网络的优越性"><a href="#如何评估神经网络的优越性" class="headerlink" title="如何评估神经网络的优越性"></a>如何评估神经网络的优越性</h1><p>机器学习的过程中，神经网络往往会存在一些问题，例如学习效率低，学习误差（loss）变化幅度摇摆不定，或是因为杂讯和信号太多没有办法找到有效的规律和结论。而这些问题可能来自<strong>数据</strong>、<strong>参数</strong>以及<strong>模型结构本身</strong>等各方面的因素。</p>
<h2 id="数据集评估"><a href="#数据集评估" class="headerlink" title="数据集评估"></a>数据集评估</h2><p>在评估数据和模型的吻合度上，我们需要对数据进行一个初步的认知，也就是确定数据集和结果之间的特征关系，也就是所谓的<strong>Features</strong>。这些Features能够很大程度地影响神经网络的学习效率。</p>
<ul>
<li>传统的机器学习算法通常会通过采用 <strong>Cross-Validation</strong> 的方式来对数据进行评估。也就是现将数据集依照6:2:2（不固定）的比例进行拆分，分别表示为<strong>训练集（Training Data）</strong>、<strong>验证集（Validating Data）</strong> 和 <strong>测试集（Testing Data）</strong> 三个部分。</li>
</ul>
<p>评估模型最终结果的好坏往往是测试集决定的，这里面会有训练的时候不曾出现过的输入信号，这也是对神经网络效能的一个<strong>考验</strong>。而要在学习的过程中让学习训练集的模型意识到不单单是要学好那些见过的部分，<strong>没见过的部分</strong>也需要充分地准备，这时候就会用到验证数据集的检验了。在训练完毕之后，我们重新划分3个资料集的比例和分布，就可以重新定义出新的训练资料了。在不断变换数据集的同时，我们可以对模型的<strong>参数进行更加科学的优化和分析</strong>。</p>
<ul>
<li>评价机器学习的方式（Evaluation Function）包括了<strong>误差（Error或Loss）</strong> 以及 <strong>精确度（Accuracy）</strong>，误差就是预测结果和实际结果的差值，而精确度就是在预测过程中的正确率了。</li>
</ul>
<p>有的时候在训练的时候往往结果让人满意，可是到了测试的时候结果却不尽人意，这又是为什么呢？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BbwFVzg.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>原来在训练过程中，神经网络太过优秀了，以至于它将自身优化成为了完全符合这个输入数据的一个模型。而一旦我们测试的输入和训练样本差别很大，就会让模型无从下手，这种现象就是所谓的过拟合（Overfitting）。</p>
<ul>
<li>比较常用来解决Overfitting的方式为<strong>Dropout</strong>，也就是在训练的过程中随机舍弃掉一些数据，从而让自己的模型留有一些变通的空间，来适应突发的情况。</li>
</ul>
<h1 id="为什么要对特征进行标准化（Normalization）"><a href="#为什么要对特征进行标准化（Normalization）" class="headerlink" title="为什么要对特征进行标准化（Normalization）"></a>为什么要对特征进行标准化（Normalization）</h1><p>现实中的数据可能来自不同的地方，不同来源的数据有各自的取值范围。而在学习的过程中，这些取值范围往往<strong>差距悬殊</strong>，这样就会对训练产生障碍。想象一下，如果我们两个权重矩阵M1和M2,我们给M1一个三位数量级的输入参数，给M2一个一位数量级的输入参数，会发生什么事情呢？答案很明显，当我们改变M1的参数时，对于总体的影响是十分巨大的，而相比之下想要达到这样的差距，就必须对M2进行很大幅度的调整。</p>
<h2 id="如何标准化"><a href="#如何标准化" class="headerlink" title="如何标准化"></a>如何标准化</h2><p>延续之前的例子，如果这时候的误差值是：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Error = {predicted - real}" style="border:none;"></p>
<p>那么对这个误差我们应该确保对所有的权重矩阵（Weight Matrix）具有类似的跨度。</p>
<p>通常用于标准化（Normalization）的方法有两种：</p>
<ul>
<li><p>一种是<strong>最小-最大标准化（Minmax Normalization）</strong>。它会将所有的数据按照一个缩放比例转换到0和1的区间中。对单独的特征而言，这个权重是唯一的（全局适用）。</p>
</li>
<li><p>另一种方法是<strong>标准正规化（Standard Normalization）</strong>。它会将所有数据转换成平均值为0，标准差（Std）为1的数据。</p>
</li>
</ul>
<p>这样的标准化问题不但能够平衡数据间的波动和差异，还能提高学习的效率，让机器学习能够正常地平衡每一个特征变数的优化和调节。</p>
<p>LICENCE： 图片摘录自网络引擎，未经授权请勿用于盈利性活动<br>更多详细内容 ： <a href="https://morvanzhou.github.io/" target="_blank" rel="external">Link</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了&lt;a href=&quot;https://morvanzhou.github.io/tutorials/machine-learning/&quot; targe
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="Reinforcement Learning" scheme="http://yoursite.com/tags/Reinforcement-Learning/"/>
    
  </entry>
  
</feed>
