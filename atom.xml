<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>指尖の岁月</title>
  <subtitle>世间点滴，莫忘于心</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-10-17T15:58:33.134Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Eternal</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>对抗生成网络(GAN)</title>
    <link href="http://yoursite.com/2017/10/17/GAN/"/>
    <id>http://yoursite.com/2017/10/17/GAN/</id>
    <published>2017-10-17T15:55:32.000Z</published>
    <updated>2017-10-17T15:58:33.134Z</updated>
    
    <content type="html"><![CDATA[<h1 id="对抗生成网络（Generative-Adversarial-Network-GAN）"><a href="#对抗生成网络（Generative-Adversarial-Network-GAN）" class="headerlink" title="对抗生成网络（Generative Adversarial Network, GAN）"></a>对抗生成网络（Generative Adversarial Network, GAN）</h1><h1 id="介绍（Introduction）"><a href="#介绍（Introduction）" class="headerlink" title="介绍（Introduction）"></a>介绍（Introduction）</h1><p>当今AI时代在人工智慧领域取得许多伟大的突破，其中机器学习与深度学习等计算机算法的崛起更是带来了一波又一波的浪潮。如今的深度学习模型已经数不胜数，而Generative Adversarial Network就是其中耀眼的一部分。在Quora上Facebook的AI研究团队主任Yann LeCun说了这样一句话：<strong>“Adversarial training is the coolest thing since sliced bread.”</strong></p>
<ul>
<li>说起GAN的种类，可谓是层出不穷：<br><a href="https://github.com/hindupuravinash/the-gan-zoo" target="_blank" rel="external">https://github.com/hindupuravinash/the-gan-zoo</a></li>
<li>在训练GAN网络的同时也存在许多Tricks:<br><a href="https://github.com/soumith/ganhacks" target="_blank" rel="external">https://github.com/soumith/ganhacks</a></li>
</ul>
<h1 id="用途（Usage）"><a href="#用途（Usage）" class="headerlink" title="用途（Usage）"></a>用途（Usage）</h1><ul>
<li><code>Drawing</code><br><a href="https://zhuanlan.zhihu.com/p/24767059" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/24767059</a></li>
<li><code>Writing Poems</code></li>
</ul>
<h1 id="主要思想（Basic-Idea）"><a href="#主要思想（Basic-Idea）" class="headerlink" title="主要思想（Basic Idea）"></a>主要思想（Basic Idea）</h1><p>GAN的本质和大多数的神经网络模型一样,都是通过一系列Function的变化来拟合输入和输出的关系。GAN内部可以分为两个部分：1、Generator 2、Discriminator ，顾名思义Generator的职责就是根据输入的Vector中所隐含的Feature信息来生成结果所需要的形式（如图片或文字等）。</p>
<h2 id="生成器（Generator）"><a href="#生成器（Generator）" class="headerlink" title="生成器（Generator）"></a>生成器（Generator）</h2><ul>
<li><code>Input</code> : Vector</li>
<li><code>Hidden</code> : NN or Function</li>
<li><code>Output</code> : Image or Text …</li>
</ul>
<p>Generator的输入为一个固定维度的Vector，经过隐藏层的变化之后得到相应的输出。而这个隐藏层内部可以是一个<strong>神经网络（Neural Network）</strong> 或者是一个 <strong>方法（Function）</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3HJh3Vq.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如图所示，Input端的Vector中不同的Feature会有不同的含义，而它们都决定了最终结果输出时候所具有的<strong>某个特征</strong>（Each dimension of input vector represents some characteristics）。只是这个特征被计算机量化成了一个人为无法辨识的数字罢了。只要能够掌握这些Features所代表的<strong>特征含义</strong>，我们就能够根据<strong>自己的意愿</strong>来调整结果的形态了。</p>
<ul>
<li><strong>Tips：</strong> 我们可以通过改变特征值来改变特征在结果中的表现。这个侧面说明了特征feature在数值上是连续的。只有当信号在一定区间范围内是<strong>连续的分布</strong>时，我们才能根据自己的意愿去调整特征的表象。</li>
</ul>
<h2 id="判别器（Discriminator）"><a href="#判别器（Discriminator）" class="headerlink" title="判别器（Discriminator）"></a>判别器（Discriminator）</h2><ul>
<li><code>Input</code> : Image or Text …</li>
<li><code>Hidden</code> : NN or Function</li>
<li><code>Output</code> : Scalar (Always normalize to 0~1)</li>
</ul>
<p>Discriminator的结构和Generator类似，只是它的输入转而变成了Generator所产生的输出而已。输入同样经过一系列隐藏层（NN或Function）得到相应的结果，而结果是一个Scalar，表示<strong>对输入的评价</strong>（Larger value means real, smaller value means fake）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qLfZcNo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="GAN网络-GAN-Network"><a href="#GAN网络-GAN-Network" class="headerlink" title="GAN网络(GAN Network)"></a>GAN网络(GAN Network)</h2><p>GAN的工作原理就是依靠生成器和判别器的对抗来让彼此变得更强，一个类似进化论的概念。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/JH5nUxS.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>以图中的例子来说：生成器不断产生不同的图片，然后由初代的判别器判断图片的好坏，直到能够符合第一代的判别器的要求。这时判别器已经<strong>没有能力再去打击生成器</strong>说它不够强大了，而这个情况并不是判别器想要看到的，于是它只能通过利用Real Images来训练我们的判别网络，使之<strong>进化</strong>到L2，而此时生成器也需要继续改变才能适应新的判别器的判别方式。就这样一方越来越好，一方越来越严格，<strong>两个模型都在不断变得更强</strong>（This is where the term “adversarial” comes from）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/E6Xi2Xl.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="为什么需要GAN（Why-GAN）"><a href="#为什么需要GAN（Why-GAN）" class="headerlink" title="为什么需要GAN（Why GAN）"></a>为什么需要GAN（Why GAN）</h1><p>了解了GAN的运作机制后，很多人可能会有这样一些疑问：</p>
<h2 id="Why-generator-cannot-learn-by-itself"><a href="#Why-generator-cannot-learn-by-itself" class="headerlink" title="Why generator cannot learn by itself"></a>Why generator cannot learn by itself</h2><ul>
<li><strong>Question1</strong> ： 既然生成器能够生成物件，那么为什么生成器不自己学习那些Real images呢？</li>
</ul>
<p><strong>第一个问题是：</strong> 我们的Generator是从随机的code信息中生成相应的物件（object），但是这些<strong>code又从何而来</strong>呢？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/DuJAJr1.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们可以借助Auto-Encoding的方式来帮助找寻code。利用encoder和decoder的联合作用，就能够利用已知的数据产生数据表示向量，也就是我们的code。</p>
<p><strong>第二个问题是：</strong> 我们已经解决了code的来源问题，那么针对code中不同的Feature我们虽然能够准确辨识，但是对于结果的Feature Representation而言都太过绝对了。一个值表示一个特征，如果我们想要的特征不在这些Code向量的表示范围内，应该如何改变它们呢？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/dVJEQG0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>这个时候直觉的做法应该是找两个最<strong>接近</strong>这个特征的其他特征，然后通过<strong>加权组合</strong>来建构新的特征。而这种方式可以通过VAE来实现：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/pt3i9UX.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Variational Auto-encoder通过将Auto-encoder中encoder生成的code向量进行维度的拆分。利用一部分特征维度来进行<strong>分布扩散</strong>，最后和剩下的保留维度特征进行加总得到一个新的code向量。</p>
<ul>
<li>为什么要这么做呢？它的结果又会对Feature Representation造成哪些影响呢？</li>
</ul>
<p>我们可以通过下面这种图来理解：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LYWAFnw.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>传统的Auto-encoder让我们每一个Feature都能够对应结果产生的某一个特定的Feature Representation，但是相对的浮动范围却很有限（相当于一个个<strong>离散的点</strong>）。如果Feature的向量和真实的向量存在<strong>些许偏差</strong>，产生的code将无法表示成为特定的Representation。而VAE将某些<strong>特征向量的分布进行了拓展</strong>，使得<strong>原本离散的点在一定范围内连续了起来</strong>。这样即使code的特征向量存在偏差，还是能够运用这些偏差进行调试。此外<strong>最关键的一点</strong>，如果让两个向量的特征拓展后存在交集，那么<strong>交集上的特征将具有两个特征的加权组合结果</strong>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Vector -&gt; Encoder -&gt; Low dimension code + Noise -&gt; decoder -&gt; Vector</div></pre></td></tr></table></figure>
<ul>
<li>那么回归问题，既然这些问题都解决了，还存在什么使得GAN的Generator不能自己训练呢？</li>
</ul>
<p>那么就是所谓的<strong>第三个问题了：</strong> 原来，如果直接训练我们的神经网络让他来自行判断并产生objects，势必会存在这样的问题——结果越像训练资料越好（这是SGD的想法）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/mh6jOyu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中上半部分由于改变了一个新的像素点，因此误差error = 1，神经网络觉得是比较好的结果，但是在人为看来却不再是2这个数字了；相对的下半部分结果多了6个像素点error = 6，神经网络觉得它不够优秀，需要重新训练，但是在人为的角度却是ok的。</p>
<ul>
<li>导致这种问题的原因在于，我们的神经网络输出层往往是根据结果的类别所建立的one-hot vector，而这就使得结果的层级之间处于相对平行的状态，层内的neuron之间无法相互传递信息所导致的：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/pvOvZv4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>neuron之间无法沟通就会使得输出结果<strong>无法掌握全局的最优</strong>情况。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/4ofbgc3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>上图是Generator产生的two-dimension的one-hot vector。从结果可以看出，在X2的坐标轴上，蓝点的分布十分散乱，这是因为神经网络在考虑输出的时候，负责输出X2结果的neuron没有考虑X1的分布情况；相对的X1的情况也是一样。</p>
<p><strong>因此</strong>，我们迫切需要一个能够将输出结果进行统整的结构，而最适合的结构就是神经网络了。因此我们<strong>引入了Discriminator来整合Generator的输出结果</strong>。</p>
<h2 id="Why-discriminator-don’t-generate-object-itself"><a href="#Why-discriminator-don’t-generate-object-itself" class="headerlink" title="Why discriminator don’t generate object itself"></a>Why discriminator don’t generate object itself</h2><ul>
<li><strong>Question2</strong> ： 既然判别器能够学习什么样的物件是好的物件，那为什么判别器不自己生成物件呢？</li>
</ul>
<p>判别器在训练过程中，我们通过Real Data作为输入来让它能够识别好的物件：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/iqhoAGe.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>但是这种训练只能让模型拟合好的例子，对于不好的例子随着训练的进行模型会一直降低它们的分数（Scalar），到最后模型就成为了一个<strong>二分类器了</strong>（只有0和1），显然这个不是我们想要的结果。</p>
</li>
<li><p>如何选择negative examples呢？</p>
</li>
</ul>
<p>我们不能够选择那些距离real sample很远的examples作为反面例子，而是需要选择<strong>尽可能接近的</strong>作为反面教材，因为只有这样模型才能学到细致的区分特性。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TTe5Zhw.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们还需要给我们的模型一些<strong>反面的训练数据</strong>，好让它能够预测scalar值介于0和1之间的情况从而进行SGD的动态更新。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/OrbOJnv.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>总而言之就是判别器比起生成器无法保证每次产生的结果都能够用在提升模型效能，特别是在模型的结构是“Deep”的时候。另一个重要的一点就是我们可以通过Argmax函数确定好的模型，但是却 <strong>无法判断哪些生成的图片是不好的（Difficult to recognize the negative sampling）</strong> 。(因为不够灵活，不符合训练资料的很难判定为好的图片)</p>
<h2 id="How-discriminator-and-generator-interact"><a href="#How-discriminator-and-generator-interact" class="headerlink" title="How discriminator and generator interact"></a>How discriminator and generator interact</h2><ul>
<li><strong>Question3</strong> ： 判别器和生成器之间是如何互动的呢？</li>
</ul>
<p>GAN神经网络被广泛应用在<strong>Structured Learning</strong>领域中，而这种机器学习方式的可靠指出在于它能够适应更加复杂的环境。对于<strong>One-shot、Zero-shot Learning</strong>的问题上，传统的机器学习分类模式讲究的是利用监督式学习的方法用大量例子来拟合网络结构。而Structured Learning除了能够拟合那些带有Label的数据外，还能够在输出范围较大的时候<strong>主动去尝试拟合</strong>那些模型从未处理过的数据类别。从而<strong>创造出全新的类别成员</strong>，因此该学习方式也要求模型的结构更加智能。</p>
<p>利用Structured Learning的这些特性，我们就能够将两个神经网络结合进行训练，让他们彼此竞争相互学习，最后双双得到提升。</p>
<ul>
<li><strong>General Algorithm</strong></li>
</ul>
<p>在训练两个网络的时候，我们通过一些positive examples和由Generator随机生成的negative examples来作为训练数据。在每个迭代中，利用positive examples训练Discriminator，将数据标记为1。然后将Generator生成的negative examples标记成0，利用Gradient Ascent的方式提升GAN网络的最大似然结果（argmax）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/v1N0tD7.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Gradient Ascent是用来提高Generator产生结果的最大似然分数（scalar），如果评估标准换成计算Discriminator的反馈和Generator生成结果之间的误差时，则用的是Gradient Descent。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ktbNjER.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="如何提升GAN的效能（How-to-improve-GAN）"><a href="#如何提升GAN的效能（How-to-improve-GAN）" class="headerlink" title="如何提升GAN的效能（How to improve GAN）"></a>如何提升GAN的效能（How to improve GAN）</h1><p>了解了GAN的用途之后，我们就要开始了解如何才能提升GAN的效能，GAN的种类有很多，不同的GAN网络具有自己独特的功能。但是在训练过程中仍然有一些细节是共通的。</p>
<h2 id="Binary-classifier-as-Discriminator"><a href="#Binary-classifier-as-Discriminator" class="headerlink" title="Binary classifier as Discriminator"></a>Binary classifier as Discriminator</h2><p>训练效果的好坏只是评估模型的学习能力如何，关键还是要看在实战（Testing）中的表现。为了能让模型更灵活而不仅仅是依赖于训练资料，我们要防止过拟合的出现。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/jNBZ9Jp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>那么防止过拟合的方法又可以有哪些呢？</p>
<h2 id="Least-Square-GAN（LSGAN）"><a href="#Least-Square-GAN（LSGAN）" class="headerlink" title="Least Square GAN（LSGAN）"></a>Least Square GAN（LSGAN）</h2><p>首先想到的应该就是用线性的方法取代传统的非线性模型，用简化边缘区分度的方式来防止过拟合的出现。而将传统二分类的Sigmoid function换成Linear的方式就是LSGAN的做法，即利用最小二乘法拟合一条直线来对样本进行分类。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/aR05euq.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Wasserstein-GAN（WGAN）"><a href="#Wasserstein-GAN（WGAN）" class="headerlink" title="Wasserstein GAN（WGAN）"></a>Wasserstein GAN（WGAN）</h2><p>既然Discriminator是将real data的结果当成1，而来自Generator的结果当成0，那么就必然希望real data训练出来的分数越大越好，Generator产生结果的分数越小越好。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/upBP2iP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p><strong>Original WGAN</strong>的做法势必会带来一些问题：</p>
<ul>
<li><p>Generator的学习过程是有一定的幅度的，根据<strong>Shrinkage</strong>的想法每次走一小步的结果去逼近最终答案比起每次走一大步去逼近更容易防止过拟合。因此我们要求Discirminator的分类曲线的区分度需要满足1-Lipschitz function（利普希茨函数）。</p>
</li>
<li><p>对优越值的无限优化会导致模型无法收敛。</p>
</li>
<li><p>过大的误差反而会增大Generator的学习负担，入不敷出。因此我们会选择设定一个阈值，当超过这个阈值的时候我们就利用Clipping的方式将值重置为阈值。这就是<strong>Improved WGAN</strong>模型的思想。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/cf2TtUT.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="Lipschitz-function-利普希茨函数"><a href="#Lipschitz-function-利普希茨函数" class="headerlink" title="Lipschitz function(利普希茨函数)"></a>Lipschitz function(利普希茨函数)</h3><p>该函数要求函数满足算子：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large ||D(x _{1}) - D(x _{2})|| \leq K ||x _{1} - x _{2}||" style="border:none;"></p>
<p>而1-Lipschitz 就是当K=1时的函数。从函数关系式不难看出需要满足这个的条件就是在任意时刻函数的斜率不能高于1。</p>
<h3 id="Sentence-Generation-Real-sentence-V-S-WGAN"><a href="#Sentence-Generation-Real-sentence-V-S-WGAN" class="headerlink" title="Sentence Generation(Real sentence V.S. WGAN)"></a>Sentence Generation(Real sentence V.S. WGAN)</h3><p>我们用one-hot vector表示句子：</p>
<p><strong>Real sentence:</strong><br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UguRdtq.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure><br><strong>Generator:</strong><br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/4JmnKrn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>可以看出利用三角函数进行分类的WGAN在句子生成上能够做到比较好的效果。</p>
<h2 id="Loss-sensitive-GAN-LSGAN"><a href="#Loss-sensitive-GAN-LSGAN" class="headerlink" title="Loss-sensitive GAN(LSGAN)"></a>Loss-sensitive GAN(LSGAN)</h2><p>传统的WGAN会无限提升优质物件的scalar并且降低不理想物件的scalar值，这样训练的结果会让模型变得异常严格，难以客观评估。因此Loss-sensitive GAN就提出了利用<strong>分布式拟合</strong>的方法一步步逼近最终的结果：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/dV7AZrt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>我们可以先定义一个“好”的标准，并把生成器的结果编辑为“不好”。利用每一次训练慢慢减小这两者之间的差距。然后再将原先“好”的标准定义为“不好”，把更接近real data的图片定义为“好”，如此一点点进步。</p>
</li>
<li><p>利用LSGAN训练需要保证两极端值不能无限增长和下降，因此需要辅助以Improved WGAN或者Energy-based GAN作为Discriminator的训练瞄准。</p>
</li>
</ul>
<h2 id="Energy-based-GAN-EBGAN"><a href="#Energy-based-GAN-EBGAN" class="headerlink" title="Energy-based GAN(EBGAN)"></a>Energy-based GAN(EBGAN)</h2><p>如果一个物件足够优秀并且特征明确，我们就一定能够通过autoencoder的方式提取code特性。Energy-based GAN的Discriminator正式利用了autoencoder的方式进行训练的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/l4yYXxR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们的目的是要最大化结果scalar X，从而使误差为0。与WGAN不同的是，利用autoencoder训练的Discriminator会尽可能让优化区间在一个<strong>有限</strong>的区间内增长。对于下降的趋势不需要太过强烈，同样通过clipping的方式进行修剪：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/tidc0Ip.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>EBGAN的训练过程中，我们会分成两个部分，最大化Real object，和最小化Gen object。而我们设置一个region来限制对gen的惩罚，因为惩罚远比reconstruct要容易，而因为这个限制，我们的模型最后只能通过提高Real object的值来更新参数。</li>
</ul>
<p>如此一来通过Gen区间不断向Real Data移动，最终得到一个有限的区间就是所谓的“优秀区间”。为了避免区间之间的过度太剧烈，同样能够让评估曲线满足Lipschitz function的条件。</p>
<h1 id="如何评估GAN的结果好坏（Evaluation）"><a href="#如何评估GAN的结果好坏（Evaluation）" class="headerlink" title="如何评估GAN的结果好坏（Evaluation）"></a>如何评估GAN的结果好坏（Evaluation）</h1><p>对于模型结果的评估，通常利用连个指标来区分，其中一个就是<strong>Likelihood</strong>，而另一个是<strong>Quality</strong>。</p>
<ul>
<li>Likelihood顾名思义就是生成的Object和Real Data特征分布的相似程度。</li>
<li>Quality则是指生成的Object中优秀样本的多少，无需和Real Data完全相似，而是关注训练样本本身是否优秀。</li>
</ul>
<p>如下列举两种极端条件：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FkPZQzY.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如上图所示，生成样本和评估样本结果的相似度为0，但是其样本本身的质量OK。也就是生成器完全没有学习特征的匹配，而是尽可能提升结果的质量。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TERNFKa.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>相对而言对于模型训练相似度高的模型，如果换一种新的样本主题（不同的特征组合），那么结果就会急速下降。也就是模型本身过于拟合那些特征的分布，而忽略了灵活变通的能力。</p>
<ul>
<li>有了上面两个例子，我们所要得到的就是介于两者之间，既能够一定程度上还原样本的特征分布，又能产生不错的结果的模型。</li>
</ul>
<h1 id="为什么GAN很难训练"><a href="#为什么GAN很难训练" class="headerlink" title="为什么GAN很难训练"></a>为什么GAN很难训练</h1><p>我们的generator能够产生一个范围作为它自身认为的正确的范围，然后通过和正确结果的范围误差来缩小距离（likelihood）。如下图所示：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/J4eNy6M.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>但是generator无法计算两者之间的差距，因此需要Discriminator来判断两者是否相似，然后通过不同的GAN模型来达成不同的判别器的目的，用来以不同的方式评估范围的差距，然后更新范围。因此不同的GAN就是用不同的方法来实作error的计算。panelty的不同会让两者形状更新不同，谁包含谁范围会不一样大。</p>
<ul>
<li>那么GAN的训练究竟有那些难点呢？</li>
</ul>
<p>选择一个合适的结构来表示我们的feature是十分重要的，因为这个关系到optimizer对结果优化时候计算误差的标准。不同的标准带来的结果也不一样：</p>
<ul>
<li>Jensen–Shannon divergence（JSD）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gaHxy42.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qknd7jy.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/72TTfky.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>JSD利用传统的KL散度（Kullback–Leibler divergence）来衡量两个几率分布之间的差异性。因而也被称作<strong>information radius (IRad)</strong> 或 <strong>total divergence to the average</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/pejHfsi.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>由图中可以看出：JS计算相似度的时候关注的是数值本身的差异性，而忽略了数值之间的相对距离因素。所以如果使用JSD进行评估的话，会导致样本训练过程中无法判断模型训练趋势的好坏。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LF1aUSa.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Earth Mover’s Distance（EMD）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hn804Zn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>EMD与JSD都是评估两个几率分布的差异性，不同的是EMD通过region D计算两个样本之间的相对距离，从而反应从一个样本转换到另一个样本的cost。这种评估方式无意可以让训练的reward变得清晰。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/l7ohobS.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h1><p>条件生成模型顾名思义就是能够按照我们设定的条件参数来动态生成一些相关的物件特征的模型。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ziam2Aw.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如上图所示，我们输入的特征给Generator的Noise不再只是一连串毫无关联的特征向量，而是含有一些人为标记的<strong>条件参数</strong>。</p>
<p>要实现Conditional Generation需要具备一些要求。</p>
<h2 id="Modifying-Input-Code"><a href="#Modifying-Input-Code" class="headerlink" title="Modifying Input Code"></a>Modifying Input Code</h2><p>要想让生成器产生的资料具有人为规定的特定特征表现，最直观的思维就是理解Input Code中每一个变量对应的含义，然后有选择性地改变它们。为此就衍生出了所谓的<strong>InfoGAN</strong>。</p>
<h3 id="InfoGAN"><a href="#InfoGAN" class="headerlink" title="InfoGAN"></a>InfoGAN</h3><p>我们通过可视化模型特征向量可以在维度空间中构建特征的表示（Representation）。我们理想中的特征往往是均匀分布的，然而事实真是如此吗？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FnrwtHR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>事实上特征的分布比我们想象的还要杂乱，并不容易发现其中的关联性。例如改变了一个特征对结果没有变化，而改变两个特征结果却发生了变化，然而单独改变其中一者又会是另外一种结果。因此对于这些众多的特征组合，我们应该如何发现其中有用的信息呢？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/75q09l4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通过训练一个decoder来对特征进行压缩，其结果就是生成能够有效还原物件本身的特征集合（Code）。如图所示：Z的特征包括了有用的c和没用的特征Z’，通过autoencoder的方式能够利用X重新生成X。而训练的过程中，我们的classifier得到的中间产物（hidden layer output）就包含了我们所要的特征集合（Code）。通过共享decoder和Discriminator input part的参数，我们就能够完美的将X的特征毫无泄漏地输入Discriminator中。</p>
<ul>
<li>AutoEncoder还可以用来解决特征消失和模型缺口的问题（Mode Collapse）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/kCcFoFQ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如图所示，我们模型在训练过程中会根据自身参数选择特征，而如果对特征的前处理不够完整，模型可能会遗漏掉一些重要的特征，这个过程就被称为“Missing Mode”。而为了避免这种问题，我们就可以使用infoGAN的方式来对特征进行前处理。</p>
<h2 id="Controlling-By-Input-Objects"><a href="#Controlling-By-Input-Objects" class="headerlink" title="Controlling By Input Objects"></a>Controlling By Input Objects</h2><p>Input Data的不同种类也会对训练模型产生不同程度的影响。一般的Input可以分为3个类别：Paired data、Unpaired data、Unsupervised。</p>
<h3 id="Paired-Data"><a href="#Paired-Data" class="headerlink" title="Paired Data"></a>Paired Data</h3><p>传统的监督式学习就是使用了Paired Data，一个pair包含了input和label两个部分。以依照描述生成图片为例：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Aw35RPg.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果输入包括了input：Description 和 label：image。这时候Traditional Supervised Learning就会通过训练学习文字和图片之间的对应关系。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vmqNkzX.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Traditional Supervised Neural Network通过设定输入为一段描述，输出为一张对应的图片。通过梯度下降的方式拟合描述的文字和图片之间的权重。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ENtDXOp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>测试时同样输入一段描述，根据权重生成图片。而这个图片往往是所有满足该描述的图片的加权平均结果，因此会是一个相对模糊的结果（Blurry Result）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/899BYmb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>GAN的方式不同与传统的监督式神经网络拟合描述和图片，而是利用生成器生成一个分布表示描述下所有可能图片的出现条件。然后用判别器判断新的描述是否落在分布的合理位置。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/rRe88if.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果输入包括Image和Distribution，则我们的判别器不单单是判断图片产生的好不好，还会挖掘描述和图片之间的关联程度，依照关联度判断是否输出相应的图片。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/fRqZLsu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如上图所示，利用条件分布来表示图片和描述是GAN的一个优势所在。不同与Traditional Supervised Learning只是单纯建立描述到图片的映射关系，GAN网络还能判断从图片到描述的关联程度。我们还可以将判别器产生的结果加入训练资料来完善分布曲线。</p>
<h3 id="Unpaired-Data"><a href="#Unpaired-Data" class="headerlink" title="Unpaired Data"></a>Unpaired Data</h3><p>除了成对存在的Paired Data之外，还存在一些原本只有单独出现的数据，通过对数据本身进行一些改变而生成另一组数据，这样的数据在原先的训练集中并不存在（没有label），因此称之为<strong>Unpaired Data</strong>。</p>
<ul>
<li>以图片的风格转换为例：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BZ283yx.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>上图中展示了两种不同风格的图片，每种图片具有自己的Datasets，我们需要利用这些data将Domain X的图片转换成Domain Y的图片。</p>
<p>如果按照GAN的训练思路来看，我们可能很容易想到下面的训练方式：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/YqZ2dJk.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通过Generator训练生成随机的图片（即随意改变原先图片的像素值）。然后通过Discriminator来判断生成的图片和Domain Y图片的相似程度。但是这样的方式存在一个很大的问题：</p>
<ul>
<li>在判别器的作用下，为了让判别器觉得产生的图片好，因此生成器可能选择完全无视Input的图片，只需要致力于生成带有特定Feature的Output，这样就会偏离我们的目的。为了解决这个问题，我们引入了<strong>Cycle GAN</strong>的概念。</li>
</ul>
<h4 id="Cycle-GAN"><a href="#Cycle-GAN" class="headerlink" title="Cycle GAN"></a>Cycle GAN</h4><p>在处理Unpaired Data的时候，我们需要注意让生成器不会完全放弃生成器原本输入的信息，那么如何锁住一个输入信息的Feature呢？</p>
<ul>
<li>AutoEncoder应该是一个绝佳的选择，能够通过建立AutoEncoder的网络来提取和压缩Generator的Input Data中潜在的Feature。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vZSsbgv.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>有了AutoEncoder的限制和Discriminator的辅助我们就能够对生成的中间产物进行scalar的计算了。但这种判断方式也要求两个Domain的feature不能相差太大。</p>
<h3 id="Unsupervised"><a href="#Unsupervised" class="headerlink" title="Unsupervised"></a>Unsupervised</h3><p>我们只有一堆物件（如图片），却没有图片的Label，因此我们利用所有图片的Features来对Input进行Embedding(Feature Embedding)。此时我们在组合Feature的时候，不需要将两个Feature进行直接的组合，而是在Embedding的Code中寻找Vector相似的那个Output作为新的Output。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2iWi9S2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h2><p>有了输入资料和模型架构，剩下的就是需要让输入的资料能够表示成模型能够识别和方便处理的<strong>形态</strong>了。而这个所谓的形态就是资料feature的表示和提取。</p>
<h3 id="Domain-Independent-Feature"><a href="#Domain-Independent-Feature" class="headerlink" title="Domain Independent Feature"></a>Domain Independent Feature</h3><p>在使用神经网络训练和识别不同Domain的Feature时，神经元除了需要学习物件本身的特征之外，还需要区分不同的Domain。使用Traditional Neural Network拟合Training Data的同时，网络也会记住Training Data的Domain Feature，这样在预测Testing Data的时候一定会产生很大的问题。（问题本质：Training Data和Testing Data之间存在本质区别的Domain Feature）</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Pn64xtb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h4 id="Domain-Adversarial-Training"><a href="#Domain-Adversarial-Training" class="headerlink" title="Domain-Adversarial Training"></a>Domain-Adversarial Training</h4><p>如果使用Training Data Domain Feature来预测Testing Data Domain Feature势必会有很大的误差，因此我们除了训练Label本身的特征，还需要训练Domain Feature的差异性。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/iVAKPT4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如上图所示：为了解决Domian依赖的问题，我们需要训练三个不同的网络来组合成一个总体的大网络结构。这个大网络中的训练目的各有些许不同，Feature Extractor的结果会极力接近Label predictor(Minimize Label Loss)，同时<strong>排斥</strong>Domain classifier(Maximize Domain Loss)。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2Wa1pnl.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>要实现排斥Domain Label的结果，我们需要对Domain classifier的反馈进行一个负向的更新，这样就能够让Domain的Information完全消失，摆脱Domain的束缚。</p>
<h3 id="Improving-Auto-encoder"><a href="#Improving-Auto-encoder" class="headerlink" title="Improving Auto-encoder"></a>Improving Auto-encoder</h3><p>Auto-encoder在对Generator的训练过程中的特征降维以及保持特征本质特征等方面做出了极大的贡献。如何应用Auto-encoder也成为了GAN的一个重要过程。</p>
<h4 id="VAE-GAN"><a href="#VAE-GAN" class="headerlink" title="VAE-GAN"></a>VAE-GAN</h4><p>之前提到的利用VAE不仅能保存物件特征，还能够通过扩散特征的表示范围来产生新的特征。而利用这样的方法能够有效提升Generator的效能。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2lLehdU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h4 id="BiGAN"><a href="#BiGAN" class="headerlink" title="BiGAN"></a>BiGAN</h4><p>与VAE相似的BiGAN network利用一个双向的网络结构来进行训练。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/rZxxaMv.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Encoder输入为real data，输出为固定Dimension的code z。而Decoder利用这个code z重新还原data的模样，成为generated data。实际上就是将AutoEncoder网络拆分开来训练。</p>
<p>这个时候因为Encoder的输入为real data，这种思想就是希望获取真实资料的所有信息，因此与Discriminator的目的一致。此时Discriminator network就会尽可能提高Encoder的scalar值，而降低Decoder的scalar值。相反，Decoder的目的就是所谓的Generator所要做的事情，因此Encoder和Decoder在训练过程中就会尽可能提高code到object的转换能力，相对的encoder的能力就会相对减小了。</p>
<h1 id="GAN-Examples"><a href="#GAN-Examples" class="headerlink" title="GAN Examples"></a>GAN Examples</h1><p>当今的GAN network被广泛应用于图片的生成和Dataset的产生。</p>
<h2 id="Anime-Face-Generation"><a href="#Anime-Face-Generation" class="headerlink" title="Anime Face Generation"></a>Anime Face Generation</h2><p>Example Code:</p>
<ul>
<li><a href="https://github.com/mattya/chainer-DCGAN" target="_blank" rel="external">https://github.com/mattya/chainer-DCGAN</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/24767059" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/24767059</a></li>
<li><a href="https://github.com/jayleicn/animeGAN" target="_blank" rel="external">https://github.com/jayleicn/animeGAN</a></li>
</ul>
<p>Dataset Collection:</p>
<ul>
<li><a href="http://konachan.net/post/show/239400/aikatsu-clouds-flowers-hikami_sumire-hiten_goane_r" target="_blank" rel="external">http://konachan.net/post/show/239400/aikatsu-clouds-flowers-hikami_sumire-hiten_goane_r</a></li>
<li><a href="https://drive.google.com/open?id=0BwJmB7alR-AvMHEtczZZN0EtdzQ" target="_blank" rel="external">https://drive.google.com/open?id=0BwJmB7alR-AvMHEtczZZN0EtdzQ</a></li>
</ul>
<p>Text-to-image:</p>
<ul>
<li><a href="https://github.com/paarthneekhara/text-to-image" target="_blank" rel="external">https://github.com/paarthneekhara/text-to-image</a></li>
</ul>
<h1 id="Decision-Making-and-Control"><a href="#Decision-Making-and-Control" class="headerlink" title="Decision Making and Control"></a>Decision Making and Control</h1><p>Widely Studies:</p>
<ul>
<li>Gym: <a href="https://gym.openai.com/" target="_blank" rel="external">https://gym.openai.com/</a></li>
<li>Universe: <a href="https://openai.com/blog/universe/" target="_blank" rel="external">https://openai.com/blog/universe/</a></li>
</ul>
<p>无论是GAN还是普通的神经网络结构，在解决特定问题的过程中都离不开决策和调控的平衡问题。AI的精髓在与自我调控和学习，因此神经网络结构不同，也会导致机器认知和判断决策的不同：</p>
<ul>
<li>Self-driving car</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/I7MIMTO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Dialogue System</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3EtailO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Go playing</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/il9vg7y.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="What-do-we-miss"><a href="#What-do-we-miss" class="headerlink" title="What do we miss?"></a>What do we miss?</h2><p>当Decision making的议题出现之后，紧跟着的一个棘手的问题就是：Machine dosen’t know the influence of each action.而这个问题的根本原因就在于模型所有的行为都取决于它能够接收到的资讯，对于那些具有延迟性或者<strong>没有办法及时反馈</strong>的reward就没有办法很好地照顾到。</p>
<p>针对这种情况现有的解决方案：</p>
<ul>
<li><p>Reinforcement Learning</p>
<ul>
<li>从环境中获得reward。</li>
</ul>
</li>
<li><p>Learning by demonstration</p>
<ul>
<li>从过往经验中学习和总结。</li>
</ul>
</li>
</ul>
<h3 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h3><p>一个好的强化学习模型能够针对环境中的变化做出总结，并试图理解环境的本质。例如Alpha Go综合了Policy-based、Value-based和Model-based等不同模式于一身，这些模式相互协调帮助模型更好地学习环境中的反馈。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/nbDuGGn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>首先根据环境得到一个状态S，根据状态再去预测接下来的行为a，如此反复最终达到一个结果状态结束。</p>
</li>
<li><p>以上过程中我们的每一个时刻表示为（S，a）的pair，所以全局的Actor、Environment信息就能够表示成：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/0S2qt1X.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</li>
<li><p>而根据S和推导出来的a，我们就能够得到一个环境的反馈（可能不是即时的），最终的Reward可以表示成：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/kVWISaV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</li>
<li><p>最后，最大化reward就是我们模型所到达到的目标了。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/fZq8eQt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>对于Reward的计算有一些值得注意的地方：</li>
</ul>
<p><img src="" alt="Uploading file..._8mxhhffj3"></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/0zdd0iY.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>以上是Reward进行反向传递时候的<strong>误差</strong>，因为一般情况下，可能会出现无论如何改变参数，决策的行为会一直被判断成positive的情况（环境很温和），这种情况往往会让模型产生极端分化。因此我们通常会加入一个Baseline来减缓这种太过温和的环境反馈，让模型从一个相对优越的起点开始学习，降低学习成本。</p>
<h3 id="Neural-network"><a href="#Neural-network" class="headerlink" title="Neural network"></a>Neural network</h3><p>除了强化学习的方式以外，神经网络也能够作为行为预测的模型。利用NN来predict最终结果所要表示行为的one-hot vector，利用argmax来选择几率最大的行为输出也是一种Actor的决策方式。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/5SPToYI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>与Reinforcement Learning结构相似的，神经网络只是将Actor的决策交给神经元来计算得到。Actor模型需要对环境进行编码，然后再利用权重计算得到相应的行为分数，取最大的行为进行输出。</p>
</li>
<li><p>然而传统的神经网络利用SGD等梯度下降的方式进行反向传递更新参数，而在环境中的决策问题往往是不可微分的，行为与行为之间属于离散分布，这个时候通常会借助强化学习的Policy Gradient来帮助输出的决策。</p>
</li>
</ul>
<h1 id="RNN-Generation-with-GAN"><a href="#RNN-Generation-with-GAN" class="headerlink" title="RNN Generation with GAN"></a>RNN Generation with GAN</h1><p>GAN在自然语言生成方面的应用：</p>
<h2 id="Sentence-Generation"><a href="#Sentence-Generation" class="headerlink" title="Sentence Generation"></a>Sentence Generation</h2><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gWNkcVu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>具体操作流程如下：</p>
<ul>
<li>Initialize generator G and discriminator D</li>
<li><p>In each iteration:</p>
<ul>
<li>Sample real sentences x from datasets</li>
<li>Generate sentences x’ by G</li>
<li>Update D to increase D(x) and decrease D(x’)</li>
<li>Update G such that increase scalar</li>
</ul>
</li>
<li><p>到了这里就会有一个<strong>关键的问题</strong>出现了：在句子生成的序列化决策行为上，我们可以对GAN网络做反向传递吗？</p>
<ul>
<li>答案是No！因为vocabulary字典序列的不连续性（Discrete），反向传递改变的细微变化无法改变原先的结果。</li>
<li>因此我们会使用输出为固定行为的Policy Gradient来取代输出为一个区间范围取值的传统神经网络模型。以一个例子来看：如果我的结果是token，而传统神经网络通过预测token’的取值来逼近结果，然而如果预测的token不在字典集中就会回传UNK，因为token的数值能够进行梯度下降的运算。但是Policy Gradient是通过计算每一个token出现的概率来选择合适的token输出，因此更新的参数也只是token出现的概率，避免了梯度下降计算的误差出现的UNK现象。（NN：label=1，prediction_sequence = [0.2, 0.4, 0.5, 0.8, 0.9, 0.95, 1.0]；PG：label=1，prediction_sequence = [0, 0, 1, 0, 1, 1, 1]）</li>
</ul>
</li>
</ul>
<h3 id="SeqGAN"><a href="#SeqGAN" class="headerlink" title="SeqGAN"></a>SeqGAN</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/IEKMQP0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Neural Network + GAN + Reinforcement learning = SeqGAN</li>
</ul>
<p>SeqGAN</p>
<ul>
<li>Consider the discriminator as reward function</li>
<li>Consider the output of discriminator as total reward</li>
<li>Update generator to increase discriminator to get maximum total reward</li>
<li>Generator is a neural network updated with reinforcement learning</li>
</ul>
<h2 id="Chat-bot-with-GAN"><a href="#Chat-bot-with-GAN" class="headerlink" title="Chat-bot with GAN"></a>Chat-bot with GAN</h2><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/T2g8iPg.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>GAN在聊天机器人的应用和Sentence Generation十分类似，都是应用序列化决策的方式决定句子的生成问题。其主要的注意点如下：</p>
<ul>
<li>Genrator is composed of Encoder and Decoder</li>
<li>Using paired or unpaired data to train with conditional GAN</li>
<li>Reinforcement learning and attention mechanism are useful for obtaining reward and conmunicating context</li>
</ul>
<h3 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor + Critic"></a>Actor + Critic</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/5AL8ssb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Actor通过神经网络预测当下的输出行为，通过TD或MC的方式结合环境因素进行模拟，最后根据Learning Critic来判断行为的reward新型反向更新。</p>
<p><a href="https://hackmd.io/IYdgTAxgzALFBsBaAnAViiRMYCMwoAYATVRVAgqVZARmQDN54ag=?view#actor-critic" target="_blank" rel="external">更多介绍</a></p>
<h1 id="Inverse-Reinforcement-Learning"><a href="#Inverse-Reinforcement-Learning" class="headerlink" title="Inverse Reinforcement Learning"></a>Inverse Reinforcement Learning</h1><p>Inverse Reinforcement Learning的思想其实就是<strong>跟着大佬走不吃亏！</strong>。</p>
<p>在训练过程中我们需要通过一些专家序列（Expert sequence）的行为新型模拟，然后制定相应的reward function，根据这个function一步步优化我们的模型。细节如下：</p>
<ul>
<li>Define a principle</li>
<li>Initialize an actor</li>
<li>In each iteration<ul>
<li>The actor interacts with the environment to obtain some trajectories</li>
<li>Define a reward function, which makes the trajectories of the teacher better than the actor</li>
<li>The actor learns to maximize the reward based on the new reward function</li>
</ul>
</li>
<li>Output the reward funciton and the actor learned from the reward function</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8BfZ2PJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="对比GAN和IRL"><a href="#对比GAN和IRL" class="headerlink" title="对比GAN和IRL"></a>对比GAN和IRL</h2><p>GAN网络和IRL在结构和功能上具有一定的相似性：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UpJKs64.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>GAN通过discriminator的到的scalar来评估Generator的好坏，进而促使Generator以提高scalar为目标不断提升。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/arTM2Py.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>IRL的Expert相当于GAN中的Discriminator，Actor则相当于Generator。Reward function反馈给Expert一个较高的分数，而给予Actor一个较低的分数，促使Actor为了提高奖励就不断向Expert靠拢，一步步得到提升。</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.youtube.com/watch?v=0CKeqXl5IY0&amp;lc=z13zuxbglpvsgbgpo04cg1bxuoraejdpapo0k" target="_blank" rel="external">Generative Adversarial Network</a></p>
<p><a href="https://www.youtube.com/watch?v=0CKeqXl5IY0&amp;lc=z13zuxbglpvsgbgpo04cg1bxuoraejdpapo0k" target="_blank" rel="external">Improving Generative Adversarial Network</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;对抗生成网络（Generative-Adversarial-Network-GAN）&quot;&gt;&lt;a href=&quot;#对抗生成网络（Generative-Adversarial-Network-GAN）&quot; class=&quot;headerlink&quot; title=&quot;对抗生成网络（G
    
    </summary>
    
    
      <category term="GAN" scheme="http://yoursite.com/tags/GAN/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Single Cycle MIPS CPU</title>
    <link href="http://yoursite.com/2017/08/29/CPU/"/>
    <id>http://yoursite.com/2017/08/29/CPU/</id>
    <published>2017-08-29T09:28:33.000Z</published>
    <updated>2017-08-29T09:29:29.377Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>The goal of this experience is to understand how a single-cycle MIPS work and how to use Verilog hardware description language (Verilog HDL) to model electronic systems. We need to implement a single cycle MIPS CPU that can execute all the instructions shown in the MIPS ISA section. We need to follow the instruction table and satisfy all the requirements .In addition, we need to verify our CPU by using Modelsim. Testing steps will provide test fixtures that will run a MIPS program for the CPU.</p>
<h1 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h1><ul>
<li><code>Verilog</code></li>
<li><code>ModelSim</code></li>
</ul>
<h1 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h1><ul>
<li>The single-cycle CPU use one cycle to execute instruction. There are five main components in CPU: controller, regfile, arithmetic logic unit (ALU), program counter(PC), and jump controller.</li>
<li>The controller control most of the multiplexers, DM write enable, ALU, Jump Controller, and regfile. The file Controller.v implements the controller.</li>
<li>The regfile is used to store data between memory and the functional units. The file Regfile.v implements the regfile.</li>
<li>The arithmetic logic unit do arithmetic and bitwise operations. The file ALU.v implements the arithmetic logic unit.</li>
<li>The program counter is stored in the PC module. The file PC.v implements the program counter. It is triggered by positive clock edges.</li>
<li>The jump controller select a memory address and send to PC. The file Jump_Ctrl.v implements the jump controller.</li>
<li>The instruction memory is used to store instructions and it is implemented in IM.v files. The data memory is used to store data and it is implemented in DM.v file.</li>
<li>The MIPS ISA is shown in the following. Figure 2 shows the R-type instructions in the MIPS ISA. Figure 3 shows the I-type instructions in the MIPS ISA. Figure 4 shows the J-type instructions in the MIPS ISA.</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/jJ6ajUH.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/d89KFdi.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/MeLucnx.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Figure 5 shows the datapath of the single-cycle CPU. This single-cycle CPU is similar to the single-cycle in the textbook. However, to simply the CPU design, only smaller instruction and data memory are used and only 18-bit addresses are needed to obtain data in the memory.</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/71fKMwP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h1&gt;&lt;p&gt;The goal of this experience is to understand h
    
    </summary>
    
    
      <category term="Verilog" scheme="http://yoursite.com/tags/Verilog/"/>
    
      <category term="CPU" scheme="http://yoursite.com/tags/CPU/"/>
    
  </entry>
  
  <entry>
    <title>自编码（Auto-encoder）</title>
    <link href="http://yoursite.com/2017/08/21/auto-encoder/"/>
    <id>http://yoursite.com/2017/08/21/auto-encoder/</id>
    <published>2017-08-21T02:33:32.000Z</published>
    <updated>2017-08-21T02:34:48.442Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是自编码"><a href="#什么是自编码" class="headerlink" title="什么是自编码"></a>什么是自编码</h1><p>在神经网络训练过程中，往往会需要输入<strong>大量的信息</strong>，而这些信息对于计算机的学习来说具有十分巨大的负担。想想人类的学习过程，如果一次性塞给我们大量的信息，不但达不到很好的学习效果，还会浪费大量的时间。</p>
<p>因此我们需要一个特殊的神经网络来将原本的信息进行压缩，提取其中最具有代表性的信息，这个网络就是所谓的编码器（encoder）。之后再通过放大压缩后的信息，重现原始资料的全部信息，也就是 解码（decoder） 的过程。而我们所需要做的就是取得编码器压缩之后的简要信息，送入神经网络进行学习，从而达到我们的目的。</p>
<h1 id="General-Auto-encoder"><a href="#General-Auto-encoder" class="headerlink" title="General Auto-encoder"></a>General Auto-encoder</h1><p>通常我们会利用神经网络的结构将输入和输出的vector进行维度的变化，从而拟合二者，而auto-encoder就是利用非监督式学习来自动找到能够表示输入信号的低维度（Low Dimension）特征向量。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/w1FOwlL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如上图所示，如果单独想要依靠一个神经网络得到好的特征向是不可能的。因为是非监督式学习，对于NN Encoder而言，我们无法评估结果code的好坏；相对的NN Decoder而言我们无从得到code的信息。因此两者必须相互沟通，共同训练才能达到最终的目的。</p>
<h1 id="Deep-Auto-encoder"><a href="#Deep-Auto-encoder" class="headerlink" title="Deep Auto-encoder"></a>Deep Auto-encoder</h1><p>如果说传统的Auto-encoder只是使用了简单的机器学习方法或是简单的神经网络作为encoder和decoder的内部构造，那么Deep Auto-encoder就是将这些网络结构替换成了更为复杂，从资料形态和特征出发的神经网络。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/u3zi7BE.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>从图中可以看出，Deep Auto-encoder能够利用神经网络的特性将输入和输出（同样的输入资料）进行转换，最终得到资料的精华部分（code）。因此我们可以说：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Deep\ Auto\ Encoder\ Network = DNN\ encoder + DNN\ decoder" style="border:none;"></p>
<ul>
<li>下图是通过PCA和t-SNE对输入信号进行降维后在二维空间中的手写数字分类结果：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gmqBwil.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>而经过Deep Auto-encoder之后的结果如下：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/0NRrwu8.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>不难看出，Auto-encoder在特征的分类上还是有一定程度能够超越传统的主成分分析模型。</p>
<h1 id="Sequence-to-Sequence-Auto-encoder"><a href="#Sequence-to-Sequence-Auto-encoder" class="headerlink" title="Sequence-to-Sequence Auto-encoder"></a>Sequence-to-Sequence Auto-encoder</h1><p>Sequence-to-Sequence的Auto-encoder主要是用在提取输入信号是一个<strong>时序的特征向量</strong>。这个时候我们需要借助RNN的模型来对时序特征向量进行encode和decode的动作。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/fzLQuVT.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>同样的利用Sequence-to-Sequence Model定义的Encoder对输入信号进行编码，输出的Vector通过Decoder重新解码。不同的是解码的结果需要拟合的是原先编码前的信号。如此一来解码器和编码器就能够准确地将<strong>原始输入信号的特征压缩和保存了</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/WL6H0GX.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Encoder输出的Vector就是我们需要的输入信息的精华，其中的Feature都能够对信息本身造成关键性的影响。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是自编码&quot;&gt;&lt;a href=&quot;#什么是自编码&quot; class=&quot;headerlink&quot; title=&quot;什么是自编码&quot;&gt;&lt;/a&gt;什么是自编码&lt;/h1&gt;&lt;p&gt;在神经网络训练过程中，往往会需要输入&lt;strong&gt;大量的信息&lt;/strong&gt;，而这些信息对于计算机的学习
    
    </summary>
    
    
      <category term="Auto-Encoder" scheme="http://yoursite.com/tags/Auto-Encoder/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘（Data Mining）十大经典算法</title>
    <link href="http://yoursite.com/2017/08/16/data/"/>
    <id>http://yoursite.com/2017/08/16/data/</id>
    <published>2017-08-16T09:25:15.000Z</published>
    <updated>2017-08-16T09:27:21.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="算法介绍（Introduction）"><a href="#算法介绍（Introduction）" class="headerlink" title="算法介绍（Introduction）"></a>算法介绍（Introduction）</h1><h2 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h2><p>C4.5是机器学习中的一个分类决策树（Decision Tree）算法，它是决策树的一个核心，ID3的改进算法。因此想要构造C4.5的结构，只需要了解决策树的构造方法即可实现大半。而总的来说就是每次选择一个好的特征以及分裂点作为当前节点的判断条件（树的分岔路口）。</p>
<h3 id="C4-5相比于ID3改进的方面包括："><a href="#C4-5相比于ID3改进的方面包括：" class="headerlink" title="C4.5相比于ID3改进的方面包括："></a>C4.5相比于ID3改进的方面包括：</h3><ul>
<li><p>使用了信息增益率作为选择节点的标准。</p>
<ul>
<li>传统的ID3算法使用了<a href="https://eternalfeather.github.io/2017/08/08/ML-algorithms/#Information-Gain-amp-Entropy" target="_blank" rel="external">信息增益(Information Gain)</a>作为衡量节点优异度的标准，也就是熵值（Entropy）的变化程度，而这个情况往往会导致选择属性的时候偏向选择取值多的属性。例如同样是跑步，一个人的速度为5m/s，另一个人的速度为3m/s，之后两人分别加速到了10m/s和6m/s。如果利用信息增益来评估两人的速度变化，那么显然前者的信息增益更强（10-5 &gt; 6-3）。然而如果使用信息增益率来说两人的加速度是一致的((10-5) / 5 = (6-3) / 3)。</li>
</ul>
</li>
<li><p>在构建决策树的过程中对分支进行了修剪。</p>
<ul>
<li>剪去那些只有几个节点的分支，因为选择方式少而单一，容易造成Overfitting。</li>
</ul>
</li>
<li><p>能够处理不完整的数据。</p>
</li>
</ul>
<h2 id="The-K-means-Algorithm-K-means"><a href="#The-K-means-Algorithm-K-means" class="headerlink" title="The K-means Algorithm(K-means)"></a>The K-means Algorithm(K-means)</h2><p><a href="https://eternalfeather.github.io/2017/08/08/ML-algorithms/#K均值（K-means）" target="_blank" rel="external">K-means算法</a>在机器学习中属于一个聚类算法，它是把n个对象根据他们的属性差异（Feature维度空间中的距离）来将彼此分成K群。它与处理混合正态分布的最大期望类似，因为都是试图找到数据中的聚类中心。<br>K-means计算假设对象属性来自于空间向量，并且目标是使各个群组内部的误差最小化。</p>
<h2 id="Support-Vector-Machine（SVM）"><a href="#Support-Vector-Machine（SVM）" class="headerlink" title="Support Vector Machine（SVM）"></a>Support Vector Machine（SVM）</h2><p><a href="https://eternalfeather.github.io/2017/08/08/ML-algorithms/#支持向量机（Support-vector-machine-SVM）" target="_blank" rel="external">支持向量机</a>是一种监督式学习的方法，被广泛应用在分类和回归的分析中。它的原理是将空间中的向量映射到一个更高纬度的空间中，然后在空间中找到一个最大间隔超平面。通俗的来说就是在原有的维度空间中无法分割的情况下，我们先提高向量表示的维度空间，然后在高纬度空间中找到一个超平面，能够将不同类别的向量集合分割开来。我们在这个超平面两侧各取两个平行的超平面，然后最大化这两个平面的距离。</p>
<h2 id="The-Apriori-algorithm"><a href="#The-Apriori-algorithm" class="headerlink" title="The Apriori algorithm"></a>The Apriori algorithm</h2><p>Apriori算法是一种最有影响力关联法则应用算法。其核心是结合了关联法则和递归的思想，我们会定义一个最小支持度（minimum support）来生成我们的频繁数据集。<br>首先从所有数据中计算出频繁项集L1，之后再利用L1生成L2项集，以此类推最后能够得到频繁k项集。每次检索需要扫描所有数据一次。</p>
<h3 id="关联度分析的基本概念"><a href="#关联度分析的基本概念" class="headerlink" title="关联度分析的基本概念"></a>关联度分析的基本概念</h3><ul>
<li><p>支持度</p>
<ul>
<li>关联规则 A-&gt;B 的支持度（Support）= P（AB），指的是A和B同时发生的概率</li>
</ul>
</li>
<li><p>置信度</p>
<ul>
<li>A对B的置信度（confidence）= P（B | A）= P（AB）/ P（A），指的是A发生的情况下B发生的概率</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/g2ND7QL.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="最大期望（EM）算法"><a href="#最大期望（EM）算法" class="headerlink" title="最大期望（EM）算法"></a>最大期望（EM）算法</h2><p>在统计计算中，最大期望算法是在概率模型中寻找最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐性变量（Latent Variable）。</p>
<p>举个例子就是：</p>
<ul>
<li>两个人分食物，我们没有必要利用十分精确的仪器来将食物分成完全相等的两份，而是先随便将食物分成两群，然后观察是否一样多，把比较多的那一份取出一部分到少的那一群。久而久之两群的差距就会越来越小最后收敛。</li>
</ul>
<h2 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h2><p>PageRank，又称网页排名，是一种根据相互的超链接计算关联度的技术。它通过网页的外部链接和内部链接的数量和质量来衡量网站的价值。PageRank背后的机制是投票，也就是每一次访问网页的链接都是对该页面的一次投票，票数越多代表网站的权重越高。</p>
<p>假设有一个4个对象组成的小团体A，B，C，D。如果所有对象都提到A，那么A的PageRank值就是B，C，D三个PageRanks的总和。<br>即:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large PR(A) = PR(B) + PR(C) + PR(D)" style="border:none;"></p>
<p>如果此时B有提到C，D也有提到A，B，C。由于一个页面不能出现两次，因此权重会被一个权重分配：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large PR(A) = {PR(B) \over 2} + {PR(C) \over 1} + {PR(D) \over 3}" style="border:none;"></p>
<h2 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h2><p><a href="https://eternalfeather.github.io/2017/08/08/ML-algorithms/#Adaboost" target="_blank" rel="external">AdaBoost</a>是一种迭代的算法，其核心思想是针对同一个训练集训练不同的分类器，也叫作弱分类器。然后通过把这些弱分类器整合起来，构造出一个最终的强分类器。<br>AdaBoost算法本身是通过动态改变数据的分布情况来实现的，根据每次训练样本的正确与否，以及上次分类的准确率，来调整每个样本的权重比例。然后再将结果送给下一次分类器的迭代中进行训练，以此类推。</p>
<h2 id="K-nearest-neighbor-classification-KNN"><a href="#K-nearest-neighbor-classification-KNN" class="headerlink" title="K-nearest neighbor classification(KNN)"></a>K-nearest neighbor classification(KNN)</h2><p><a href="https://eternalfeather.github.io/2017/08/08/ML-algorithms/#K近邻（K-Nearest-Neighbors）" target="_blank" rel="external">KNN算法</a>可以用于分类和回归问题，然而我们更常将其被用于解决分类问题上。KNN能够存储所有的案例，通过对比周围K个样本中的大概率情况，从而决定新的对象应该分配在哪一个类别。新的样本会被分配到它的K个最近最普遍的类别中去，因此KNN算法也是一个基于距离函数的算法。</p>
<h2 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h2><p>在所有的分类模型中，应用最为广泛的无非是两种分类模型了，它们分别是决策树模型和<a href="https://eternalfeather.github.io/2017/08/08/ML-algorithms/#朴素贝叶斯（Naive-Bayesian）" target="_blank" rel="external">朴素贝叶斯（Naive Bayes）</a>模型。在结构上，Naive Bayes所需估计的参数较少，对缺失数据不太敏感，算法也比较简单。<br>Naive Bayes模型假设属性之间相互独立。通俗来说，一个朴素贝叶斯分类器假设分类的特性和其他特性不相关。朴素贝叶斯模型容易创建，而且在非监督式学习的大型数据样本集中非常有用，虽然简单，却能超越复杂的分类方法。其基本思想就是：对于给出的待分类项，求解在此项出现的条件下各个目标类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。</p>
<h2 id="CART（分类与回归树）"><a href="#CART（分类与回归树）" class="headerlink" title="CART（分类与回归树）"></a>CART（分类与回归树）</h2><p>Classification and Regression Trees是在分类树下面总结两个关键的思想。一个是关于递归的划分自变量空间，第二个是用验证数据对树结构进行剪枝。<br>我们知道分类树的输出是样本的类别标签。回归树的输出则是一个固定的数值。而CART包含了上述的两种决策树。它的结构是一棵二叉树，且每个非叶子节点都有两个Child，所以叶子节点数总是比非叶子节点数多1。<br>CART中用于选择变量的不纯性度量标准是用<a href="https://eternalfeather.github.io/2017/08/08/ML-algorithms/#Gini" target="_blank" rel="external">Gini指数</a>来处理的，也就是说树内部的属性越杂乱，Gini指数就越大。如果目标变量是离散的，并且具有两个以上的类别，则CART可能考虑将这些目标类别进行合并，最终合并成两个超类别（这个过程叫做双化）。如果目标变量是连续的，则CART会找出一组基于树的回归方程来预测目标变量的结果。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;算法介绍（Introduction）&quot;&gt;&lt;a href=&quot;#算法介绍（Introduction）&quot; class=&quot;headerlink&quot; title=&quot;算法介绍（Introduction）&quot;&gt;&lt;/a&gt;算法介绍（Introduction）&lt;/h1&gt;&lt;h2 id=&quot;C
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Data Mining" scheme="http://yoursite.com/tags/Data-Mining/"/>
    
  </entry>
  
  <entry>
    <title>An Implementation of Attention is all you need with Chinese Corpus</title>
    <link href="http://yoursite.com/2017/08/15/attention/"/>
    <id>http://yoursite.com/2017/08/15/attention/</id>
    <published>2017-08-15T09:42:49.000Z</published>
    <updated>2017-08-15T09:46:10.921Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Link"><a href="#Link" class="headerlink" title="Link"></a>Link</h1><p><a href="https://github.com/EternalFeather/Transformer-in-generating-dialogue" target="_blank" rel="external">Github</a></p>
<h1 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h1><ul>
<li>Numpy &gt;= 1.13.1</li>
<li>Tensorflow-gpu &gt;= 1.2.1</li>
<li>tqdm</li>
<li>nltk</li>
</ul>
<h1 id="Construction-Details"><a href="#Construction-Details" class="headerlink" title="Construction Details"></a>Construction Details</h1><p>As we all know Translation System can be used in implementing conversational model just by replacing the paris of two different sentences to questions and answers. After all, the basic conversation model named “Sequence-to-Sequence” is develped from translation system. Therefore, why we not to improve the efficiency of conversation model in generating dialogues?<br><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/x5FRdRo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>This is the structure of transformer which is the core of implementing our model. Now let’s split it into several points:</p>
<ul>
<li>First one is Input Datasets(Get the batch datasets from generator, which is represented as a list of token ids in this experiment).</li>
<li>Second one is Embedding layers(Including two parts:<strong>Dataset Embedding</strong> and <strong>Positional Embedding</strong>)<ul>
<li>Dataset Embedding transform input token ids into a one-hot vector whose size is the length of vocabulary.</li>
<li>Positional Embedding also called positional encoding. It considered the index of each word in the list of sentence as the position symbol.</li>
<li>Third we have a multi-head attention model to split the output of embedding layers into many pieces and run through different attention models parallelly. Finally we can get the result by concating all the outputs from every models.</li>
<li>Finally, going through a feed forward layer and combining with residual items, so that we can get the result. </li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/YfKUgIC.png" alt=""></p>
<h1 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h1><ul>
<li>STEP 1. Download dialogue corpus with format like sample datasets and extract them to <code>data/</code> folder.</li>
<li>STEP 2. Adjust hyper parameters in <code>params.py</code> if you want.</li>
<li>STEP 3. Run <code>make_dic.py</code> to generate vocabulary files to a new folder named <code>dictionary</code>.</li>
<li>STEP 4. Run <code>train.py</code> to build the model. Checkpoint will be stored in <code>checkpoint</code> folder while the tensorflow event files can be found in <code>logdir</code>. </li>
<li>STEP 5. Run <code>eval.py</code> to evaluate the result with testing data. Result will be stored in <code>Results</code> folder.</li>
</ul>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line">- Source: 肥 宅 初 夜 可 以 賣 多 少 `</div><div class="line">- Ground Truth: 肥 宅 還 是 去 打 手 槍 吧</div><div class="line">- Predict: 肥 宅 還 是 去 打 手 槍 吧</div><div class="line"></div><div class="line">- Source: 兇 的 女 生 484 都 很 胸</div><div class="line">- Ground Truth: 我 看 都 是 醜 的 比 較 凶</div><div class="line">- Predict: 我 看 都 是 醜 的 比 較 &lt;UNK&gt;</div><div class="line"></div><div class="line">- Source: 留 髮 不 留 頭</div><div class="line">- Ground Truth: 還 好 我 早 就 禿 頭 了</div><div class="line">- Predict: 還 好 我 早 就 禿 頭 了</div><div class="line"></div><div class="line">- Source: 當 人 好 痛 苦 R 的 八 卦</div><div class="line">- Ground Truth: 去 中 國 就 不 用 當 人 了</div><div class="line">- Predict: 去 中 國 就 不 會 有 了 -</div><div class="line"></div><div class="line">- Source: 有 沒 有 今 天 捷 運 的 八 卦</div><div class="line">- Ground Truth: 有 - 真 的 有 多</div><div class="line">- Predict: 有 - 真 的 有 多</div><div class="line"></div><div class="line">- Source: 2016 帶 走 了 什 麼 `</div><div class="line">- Ground Truth: HellKitty 麥 當 勞 歡 樂 送 開 門 -</div><div class="line">- Predict: &lt;UNK&gt; 麥 當 勞 歡 樂 送 開 門 -</div><div class="line"></div><div class="line">- Source: 有 沒 有 多 益 很 賺 的 八 卦</div><div class="line">- Ground Truth: 比 大 型 包 裹 貴</div><div class="line">- Predict: 比 大 型 包 &lt;UNK&gt; 貴</div><div class="line"></div><div class="line">- Source: 邊 緣 人 收 到 地 震 警 報 了</div><div class="line">- Ground Truth: 都 跑 到 窗 邊 了 才 來</div><div class="line">- Predict: 都 跑 到 &lt;UNK&gt; 邊 了 才 來</div><div class="line"></div><div class="line">- Source: 車 震</div><div class="line">- Ground Truth: 沒 被 刪 版 主 是 有 眼 睛 der</div><div class="line">- Predict: 沒 被 刪 版 主 是 有 眼 睛 der</div><div class="line"></div><div class="line">- Source: 在 家 跌 倒 的 八 卦 `</div><div class="line">- Ground Truth: 傷 到 腦 袋 - 可 憐</div><div class="line">- Predict: 傷 到 腦 袋 - 可 憐</div><div class="line"></div><div class="line">- Source: 大 家 很 討 厭 核 核 嗎 `</div><div class="line">- Ground Truth: 核 核 欠 幹 阿</div><div class="line">- Predict: 核 核 欠 幹 阿</div><div class="line"></div><div class="line">- Source: 館 長 跟 黎 明 打 誰 贏 -</div><div class="line">- Ground Truth: 我 愛 黎 明 - 我 愛 黎 明 -</div><div class="line">- Predict: 我 愛 &lt;UNK&gt; 明 - 我 愛 &lt;UNK&gt; 明 -</div><div class="line"></div><div class="line">- Source: 嘻 嘻 打 打</div><div class="line">- Ground Truth: 媽 的 智 障 姆 咪 滾 喇 幹</div><div class="line">- Predict: 媽 的 智 障 姆 咪 滾 喇 幹</div><div class="line"></div><div class="line">- Source: 經 典 電 影 台 詞</div><div class="line">- Ground Truth: 超 時 空 要 愛 裡 滿 滿 的 梗</div><div class="line">- Predict: 超 時 空 要 愛 裡 滿 滿 滿 的</div><div class="line"></div><div class="line">- Source: 2B 守 得 住 街 亭 嗎 `</div><div class="line">- Ground Truth: 被 病 毒 滅 亡 真 的 會 -</div><div class="line">- Predict: &lt;UNK&gt; 守 得 住</div></pre></td></tr></table></figure>
<h1 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h1><h2 id="Implement-feedforward-through-fully-connected"><a href="#Implement-feedforward-through-fully-connected" class="headerlink" title="Implement feedforward through fully connected."></a>Implement feedforward through fully connected.</h2><ul>
<li>Training Accuracy</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/wZW34e8.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Training Loss</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/p5MSVVQ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Implement-feedforward-through-convolution-in-only-one-dimention"><a href="#Implement-feedforward-through-convolution-in-only-one-dimention" class="headerlink" title="Implement feedforward through convolution in only one dimention."></a>Implement feedforward through convolution in only one dimention.</h2><ul>
<li>Training Accuracy</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/y2Q9yM8.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Training Loss</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/MJdMnvt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h1><p>Thanks for <a href="https://github.com/Kyubyong/transformer" target="_blank" rel="external">Transformer</a></p>
<ul>
<li>本文在原先的模组上添加了Attention is all you need提到的Position encoding的部分</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Link&quot;&gt;&lt;a href=&quot;#Link&quot; class=&quot;headerlink&quot; title=&quot;Link&quot;&gt;&lt;/a&gt;Link&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/EternalFeather/Transformer-in-gene
    
    </summary>
    
    
      <category term="Transformer" scheme="http://yoursite.com/tags/Transformer/"/>
    
      <category term="Attention is all you need" scheme="http://yoursite.com/tags/Attention-is-all-you-need/"/>
    
      <category term="Conversation Model" scheme="http://yoursite.com/tags/Conversation-Model/"/>
    
  </entry>
  
  <entry>
    <title>tensorflow快速入门</title>
    <link href="http://yoursite.com/2017/08/14/tensorflow/"/>
    <id>http://yoursite.com/2017/08/14/tensorflow/</id>
    <published>2017-08-14T06:08:47.000Z</published>
    <updated>2017-08-14T06:09:41.304Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍（Introduction）"><a href="#介绍（Introduction）" class="headerlink" title="介绍（Introduction）"></a>介绍（Introduction）</h1><p>Tensorflow是一个使用数据流图（Data flow graphs）技术进行数值运算的函式库。每一张图都是由节点（Node）和边（Edge）组成的。Tensorflow具有以下几点特性：</p>
<h2 id="灵活性"><a href="#灵活性" class="headerlink" title="灵活性"></a>灵活性</h2><p>Tensorflow不是一个严格意义上的神经网络函式库，只要是能够使用数据流图来描述的计算问题，都能够通过Tensorflow来实现。与此同时还能够用简单的Python来实现高层次的功能。</p>
<h2 id="可迁移性"><a href="#可迁移性" class="headerlink" title="可迁移性"></a>可迁移性</h2><p>Tensorflow可以在任何具备CPU或者GPU的设备上运行，无需考虑复杂的环境配置问题，。</p>
<h2 id="高效性"><a href="#高效性" class="headerlink" title="高效性"></a>高效性</h2><p>Tensorflow可以提升神经网络的训练效率，且具备代码统一的有优势，便于和同行分享。</p>
<h1 id="配置支持"><a href="#配置支持" class="headerlink" title="配置支持"></a>配置支持</h1><ul>
<li><code>Python</code></li>
<li><code>C++</code></li>
<li><code>CUDA</code>   (GPU环境)</li>
<li><code>CUDNN</code> （GPU环境）</li>
</ul>
<h1 id="Tensorflow的结构"><a href="#Tensorflow的结构" class="headerlink" title="Tensorflow的结构"></a>Tensorflow的结构</h1><h2 id="数据流图（Graph）"><a href="#数据流图（Graph）" class="headerlink" title="数据流图（Graph）"></a>数据流图（Graph）</h2><p>数据流图是一种描述有向图的数值计算过程产物。图中的节点通常是代表数学运算，但也可以表示数据的输入、输出和读写等操作。图中的边（Edge）表示节点之间的某种关联，负责在节点之间传递各种数据单元，而Tensorflow的基本运算单元是Tensor。Tensorflow的flow也因此得名。</p>
<p>节点可以被分配到多个设备上运算，也就是所谓的异步并行操作。因为是有向图，所以只有等到先前的节点结束工作时，当前的节点才能够执行相应的操作。</p>
<h2 id="节点（Ops）"><a href="#节点（Ops）" class="headerlink" title="节点（Ops）"></a>节点（Ops）</h2><p>Tensorflow中的节点也被称为Operation。一个Ops通常使用0个或者以上的Tensors，通过执行某个特定的运算，产生新的Tensors。一个Tensor表示的是一个<strong>多维数组</strong>，例如[batch, height, width, channels]这样的形式，数组中的数多为浮点数。</p>
<h2 id="边（Edge）"><a href="#边（Edge）" class="headerlink" title="边（Edge）"></a>边（Edge）</h2><p>Tensorflow各节点之间的通道被成为边，也可以理解为流（FLow），作用是在每个节点的计算过程中传输数据Tensor。因为是有向图的关系，边的传输方向也是有自己的规则，因此在Tensorflow的运算过程中往往需要安排好节点和边的关系。</p>
<h1 id="Tensorflow的常见使用步骤"><a href="#Tensorflow的常见使用步骤" class="headerlink" title="Tensorflow的常见使用步骤"></a>Tensorflow的常见使用步骤</h1><ul>
<li>将计算流程表示成图的形式</li>
<li>通过Session来执行图计算</li>
<li>将数据表示为Tensors</li>
<li>通过Variable储存模型的状态数值</li>
<li>使用feeds和fetches来填充数据和抓取数据</li>
</ul>
<p>Tensorflow运行中通过Session来执行图中各节点的运算，Session将Ops放置到CPU或者GPU中，然后执行他们。执行完毕后，返回相应的结果（Tensors），在Python中这些Tensors的形式是numpy ndarray的objects。</p>
<h2 id="创建数据流图"><a href="#创建数据流图" class="headerlink" title="创建数据流图"></a>创建数据流图</h2><p>Tensorflow在使用过程中通常分为<strong>施工阶段</strong> 和 <strong>建设阶段</strong>两部分。在施工阶段我们创建一个神经网络的结构和功能，在建设阶段通过Session来反复执行我们所构建的神经网络。</p>
<p>和大多数编程语言类似，Tensorflow的Constant是一种没有输入的ops（常量），但是它本身可以作为其他ops的输入。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">matrix1 = tf.constant([[3., 3.]])</div><div class="line">matrix2 = tf.constant([[2.], [2.]])</div><div class="line">product = tf.matmul(matrix1, matrix2)</div></pre></td></tr></table></figure>
<p>这时我们已经在一个Default的Graph里面加入了三个Nodes，两个Constant ops和一个matmul的ops。为了能够得到两个矩阵运算的结果，我们就必须使用<strong>session来启动图</strong>。</p>
<h2 id="在Session中执行数据流图"><a href="#在Session中执行数据流图" class="headerlink" title="在Session中执行数据流图"></a>在Session中执行数据流图</h2><p>刚才已经完成了施工的阶段，现在要开始建设阶段了，这样才能实作出我们想要的结果。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sess = tf.Session()</div><div class="line">result = sess.run(product)</div><div class="line">print(result)</div><div class="line">sess.close()</div></pre></td></tr></table></figure>
<p>用定义式的Session执行需要一个结束的判定，或者我们可以使用with的方式来定义我们的执行过程:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">with tf.Session() as sess:</div><div class="line">    result = sess.run(product)</div><div class="line">    print(result)</div></pre></td></tr></table></figure>
<p>Tensorflow这些节点可以被分配到不同的设备上进行计算。如果是GPU，默认会在第一个GPU（id = 0）上执行，如果想在其他的GPU上执行相应的session，需要进行手动配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">with tf.Session() as sess:</div><div class="line">    # 也可以用‘/cpu:0’</div><div class="line">    with tf.device(&quot;/gpu:1&quot;):</div><div class="line">        matrix1 = tf.constant([[3., 3.]])</div><div class="line">        matrix2 = tf.constant([[2.], [2.]])</div><div class="line">        product = tf.matmul(matrix1, matrix2)</div><div class="line">        print(sess.run(product))</div></pre></td></tr></table></figure>
<p>在一些交互界面（例如Ipython或者cmd）运行tensorflow的时候，我们往往不需要编译全局而用分布式运算的方式。因此我们可以使用InteractiveSession和eval()、Ops_name.run()等方式来进行分布式运算:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">sess = tf.InteractiveSession()</div><div class="line"></div><div class="line">a = tf.Variable([1.0, 2.0])</div><div class="line">a.initializer.run()</div><div class="line">b = tf.constant([3.0, 3.0])</div><div class="line"></div><div class="line">sub = tf.subtract(a, b)</div><div class="line">print(sub.eval())</div><div class="line"></div><div class="line">sess.close()</div></pre></td></tr></table></figure>
<h2 id="运算中的数据结构Tensors"><a href="#运算中的数据结构Tensors" class="headerlink" title="运算中的数据结构Tensors"></a>运算中的数据结构Tensors</h2><p>Tensorflow中使用的数据结构不同于其他语言中的结构，而是一种叫作Tensor的结构，它的本质是一个多维的数据集的表示形式，用来在数据流图中的各节点之间传递信息，一个Tensor具有固定的类型和大小（静态型别）。</p>
<h3 id="变量Variable"><a href="#变量Variable" class="headerlink" title="变量Variable"></a>变量Variable</h3><p>变量在图的执行过程中，保持着自己特有的状态信息，能够为图模型的运作保存变化的数值信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">state = tf.Variable(0, name = &quot;counter&quot;)</div><div class="line">one = tf.constant(1)</div><div class="line">new_value = tf.add(state, one)</div><div class="line"># 赋值函数</div><div class="line">update = tf.assign(state, new_value)</div><div class="line"></div><div class="line">init_op = tf.initializer_all_variables()</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    sess.run(init_op)</div><div class="line">    print(sess.run(state))</div><div class="line">    for _ in range(3):</div><div class="line">        sess.run(update)</div><div class="line">        print(sess.run(state))</div></pre></td></tr></table></figure>
<p>一般我们会将神经网络的参数初始化为一些变量，等到训练的时候再通过Session来对参数进行更新。</p>
<h2 id="抓取（Fetches）和填充（Feeds）"><a href="#抓取（Fetches）和填充（Feeds）" class="headerlink" title="抓取（Fetches）和填充（Feeds）"></a>抓取（Fetches）和填充（Feeds）</h2><p>我们在使用神经网络的过程中，每一个节点的图往往不是封闭的，也就是说它们需要传入和输出一些东西。而为了抓取ops的输出，我们需要执行Session的run函数，然后通过print的方式抓取它们的参数:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">input1 = tf.constant(3.0)</div><div class="line">input2 = tf.constant(2.0)</div><div class="line">input3 = tf.constant(5.0)</div><div class="line">intermed = tf.add(input2, input3)</div><div class="line">mul = tf.multiply(input1, intermed)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    result = sess.run(mul)</div><div class="line">    print(result)</div></pre></td></tr></table></figure>
<ul>
<li>其中的result计算过程中，虽然mul的计算过程需要用到intermed的计算结果，但是我们不需要另外写入sess.run(intermed)。原因是Tensorflow是一个有向图集，因此我们定义后面的图，它就会自动去追溯先前的所有图并且实作它们。</li>
</ul>
<p>有的时候我们在计算过程中有些参数我们是在之后<strong>建设</strong>的过程中才会得到的，因此我们在施工的时候就可以先用一个占位符把它的位置保留：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">input1 = tf.placeholder(tf.float32)</div><div class="line">input2 = tf.placeholder(tf.float32)</div><div class="line">output = tf.multiply(input1, input2)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    print(sess.run(output, feed_dict = &#123;input1 : [7.], input2: [2.]&#125;))</div></pre></td></tr></table></figure>
<p>或者传入一个numpy array：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">n = 5</div><div class="line">a = tf.placeholder(dtype = tf.float32)</div><div class="line">b = tf.placeholder(&quot;float&quot;, [None, n])</div><div class="line">output = tf.multiply(a, b)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    temp = np.asarray([[1., 2., 3., 4., 5.]])</div><div class="line">    print(sess.run(output, feed_dict = &#123;a: [2.], b: temp&#125;))</div></pre></td></tr></table></figure>
<h1 id="Tensorflow范例"><a href="#Tensorflow范例" class="headerlink" title="Tensorflow范例"></a>Tensorflow范例</h1><h2 id="拟合曲线的计算"><a href="#拟合曲线的计算" class="headerlink" title="拟合曲线的计算"></a>拟合曲线的计算</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x_data = np.random.randn(100).astype(&quot;float32&quot;)</div><div class="line">y_data = x_data * 0.1 + 0.3</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))</div><div class="line">b = tf.Variable(tf.zeros([1]))</div><div class="line">y = W * x_data + b</div><div class="line"></div><div class="line">loss = tf.reduce_mean(tf.square(y - y_data))</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)</div><div class="line"></div><div class="line">init = tf.initialize_all_variables()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(101):</div><div class="line">    sess.run(optimizer)</div><div class="line">    if step % 20 == 0:</div><div class="line">        print(step, sess.run(W), sess.run(b))</div></pre></td></tr></table></figure>
<h2 id="MNIST手写识别"><a href="#MNIST手写识别" class="headerlink" title="MNIST手写识别"></a>MNIST手写识别</h2><p>利用线性分类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line"># mnist.train, mnist.test, mnist.validation</div><div class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot = True)</div><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">batch_size = 64</div><div class="line">train_iter = 1000</div><div class="line"></div><div class="line"># input_size = [batch_size, 28, 28]; output_size = one_hot</div><div class="line">x = tf.placeholder(tf.float32, [None, 784])</div><div class="line">y = tf.placeholder(tf.float32, [None, 10])</div><div class="line"></div><div class="line">W = tf.Variable(tf.zeros([784, 10]))</div><div class="line">b = tf.Variable(tf.zeros([10]))</div><div class="line">pred = tf.nn.softmax(tf.matmul(x, W) + b)</div><div class="line"></div><div class="line">loss = -tf.reduce_sum(y * tf.log(pred))</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)</div><div class="line">correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</div><div class="line"></div><div class="line">init = tf.initialize_all_variables()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(train_iter):</div><div class="line">    batch_xs, batch_ys = mnist.train.next_batch(64)</div><div class="line">    sess.run(optimizer, feed_dict = &#123;x: batch_xs, y: batch_ys&#125;)</div><div class="line">    if step % 100 == 0:</div><div class="line">        print(sess.run(accuracy, feed_dict = &#123;x: mnist.test.images, y: mnist.test.labels&#125;))</div></pre></td></tr></table></figure>
<p>利用RNN（GRU）神经网络：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line">mnist = input_data.read_data_sets(&quot;MNIST/&quot;, one_hot = True)</div><div class="line"></div><div class="line">n_input = 28</div><div class="line">time_step = 28</div><div class="line">n_hidden = 128</div><div class="line">n_output = 10</div><div class="line"></div><div class="line">learning_rate = 0.001</div><div class="line">train_iters = 1000</div><div class="line">batch_size = 64</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32, [None, time_step, n_input])</div><div class="line">y = tf.placeholder(tf.float32, [None, n_output])</div><div class="line"></div><div class="line">W = &#123;</div><div class="line">	&apos;hidden&apos; : tf.Variable(tf.random_normal([n_input, n_hidden])),</div><div class="line">	&apos;output&apos; : tf.Variable(tf.random_normal([n_hidden, n_output]))</div><div class="line">&#125;</div><div class="line"></div><div class="line">b = &#123;</div><div class="line">	&apos;hidden&apos; : tf.Variable(tf.random_normal([n_hidden])),</div><div class="line">	&apos;output&apos; : tf.Variable(tf.random_normal([n_output]))</div><div class="line">&#125;</div><div class="line"></div><div class="line">def RNN(x, W, b):</div><div class="line">	x = tf.transpose(x, [1, 0, 2])</div><div class="line">	x = tf.reshape(x, [-1, n_input])</div><div class="line">	x = tf.matmul(x, W[&apos;hidden&apos;]) + b[&apos;hidden&apos;]</div><div class="line">	x = tf.split(x, time_step, 0)</div><div class="line"></div><div class="line">	lstm_cell = tf.nn.rnn_cell.GRUCell(n_hidden)</div><div class="line">	outputs, _ = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype = tf.float32)</div><div class="line">	return tf.matmul(outputs[-1], W[&apos;output&apos;]) + b[&apos;output&apos;]</div><div class="line"></div><div class="line">pred = RNN(x, W, b)</div><div class="line"></div><div class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))</div><div class="line">optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)</div><div class="line"></div><div class="line">corrent_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(corrent_pred, tf.float32))</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">	with tf.device(&apos;/cpu:0&apos;):</div><div class="line">		sess.run(init)</div><div class="line">		for step in range(train_iters):</div><div class="line">			batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">			batch_x = batch_x.reshape(batch_size, time_step, n_input)</div><div class="line">			sess.run(optimizer, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div><div class="line">			if step % 100 == 0:</div><div class="line">				acc = sess.run(accuracy, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div><div class="line">				cost = sess.run(loss, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div><div class="line">				print(&quot;MSG : Epoch &#123;&#125;, Training_accuracy = &#123;:.6f&#125;, Training_loss = &#123;:.5f&#125;&quot;.format((step // 100) + 1, acc, cost))</div><div class="line"></div><div class="line">		test_data = mnist.test.images.reshape(-1, time_step, n_input)</div><div class="line">		test_labels = mnist.test.labels</div><div class="line">		print(&quot;MSG : Testing_accuracy = &#123;:.6f&#125;&quot;.format(sess.run(accuracy, feed_dict = &#123;x: test_data, y: test_labels&#125;)))</div></pre></td></tr></table></figure>
<p>利用CNN神经网络：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div></pre></td><td class="code"><pre><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">import tensorflow as tf</div><div class="line">mnist = input_data.read_data_sets(&apos;MNIST/&apos;, one_hot = True)</div><div class="line"></div><div class="line">time_step = 28</div><div class="line">n_input = 28</div><div class="line">n_output = 10</div><div class="line">n_hidden = 1024</div><div class="line">learning_rate = 0.001</div><div class="line">train_iters = 20000</div><div class="line">batch_size = 64</div><div class="line">dropout = 0.5</div><div class="line"></div><div class="line">strides_size = 1</div><div class="line">kernal_size = 2</div><div class="line">window_size = 5</div><div class="line"></div><div class="line">def weight_variable(shape):</div><div class="line">	initial = tf.truncated_normal(shape, stddev = 0.1)</div><div class="line">	return tf.Variable(initial)</div><div class="line"></div><div class="line"></div><div class="line">def bias_variable(shape):</div><div class="line">	initial = tf.constant(0.1, shape = shape)</div><div class="line">	return tf.Variable(initial)</div><div class="line"></div><div class="line"></div><div class="line">def conv(x, W):</div><div class="line">	return tf.nn.conv2d(x, W, strides = [strides_size] * 4, padding = &apos;SAME&apos;)</div><div class="line"></div><div class="line"></div><div class="line">def max_pooling(x):</div><div class="line">	return tf.nn.max_pool(x, ksize = [1, window_size, window_size, 1], strides = [1, 2, 2, 1], padding = &apos;SAME&apos;)</div><div class="line"></div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32, [None, time_step, n_input])</div><div class="line">x_image = tf.reshape(x, [-1, time_step, n_input, 1])</div><div class="line">y = tf.placeholder(tf.float32, [None, n_output])</div><div class="line">keep_prob = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line"># conv1 layer</div><div class="line">W_conv1 = weight_variable([window_size, window_size, 1, 32])</div><div class="line">b_conv1 = bias_variable([32])</div><div class="line"></div><div class="line"># conv2 layer</div><div class="line">W_conv2 = weight_variable([window_size, window_size, 32, 64])</div><div class="line">b_conv2 = bias_variable([64])</div><div class="line"></div><div class="line"># linear flatten layer</div><div class="line">W_fc1 = weight_variable([7*7*64, n_hidden])</div><div class="line">b_fc1 = bias_variable([n_hidden])</div><div class="line"></div><div class="line"># softmax layer</div><div class="line">W_fc2 = weight_variable([n_hidden, n_output])</div><div class="line">b_fc2 = bias_variable([n_output])</div><div class="line"></div><div class="line"></div><div class="line">def CNN(x, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2, keep_prob):</div><div class="line">	# [-1, 28, 28, 1]</div><div class="line">	h_conv1 = tf.nn.relu(conv(x, W_conv1) + b_conv1)</div><div class="line">	h_pool1 = max_pooling(h_conv1)</div><div class="line">	h_pool1_drop = tf.nn.dropout(h_pool1, keep_prob)</div><div class="line"></div><div class="line">	# [-1, 14, 14, 32]</div><div class="line">	h_conv2 = tf.nn.relu(conv(h_pool1_drop, W_conv2) + b_conv2)</div><div class="line">	h_pool2 = max_pooling(h_conv2)</div><div class="line">	h_pool2_drop = tf.nn.dropout(h_pool2, keep_prob)</div><div class="line"></div><div class="line">	# [-1, 7, 7, 64]</div><div class="line">	h_fc1 = tf.reshape(h_pool2_drop, [-1, 7*7*64])</div><div class="line">	h_fc1 = tf.nn.relu(tf.matmul(h_fc1, W_fc1) + b_fc1)</div><div class="line">	h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</div><div class="line"></div><div class="line">	# [-1, n_hidden] -&gt; [-1, n_output]</div><div class="line">	# return tf.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)</div><div class="line">	return tf.matmul(h_fc1_drop, W_fc2) + b_fc2</div><div class="line"></div><div class="line">pred = CNN(x_image, W_conv1, b_conv1, W_conv2, b_conv2, W_fc1, b_fc1, W_fc2, b_fc2, keep_prob)</div><div class="line"></div><div class="line"># loss = -tf.reduce_sum(y * tf.log(pred))</div><div class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))</div><div class="line">optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)</div><div class="line"></div><div class="line">corrent_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(corrent_pred, tf.float32))</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">	with tf.device(&apos;/gpu:0&apos;):</div><div class="line">		sess.run(init)</div><div class="line">		for step in range(train_iters):</div><div class="line">			batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">			batch_x = batch_x.reshape(batch_size, time_step, n_input)</div><div class="line">			sess.run(optimizer, feed_dict = &#123;x: batch_x, y: batch_y, keep_prob: dropout&#125;)</div><div class="line">			if step % 100 == 0:</div><div class="line">				acc = sess.run(accuracy, feed_dict = &#123;x: batch_x, y: batch_y, keep_prob: 1.0&#125;)</div><div class="line">				cost = sess.run(loss, feed_dict = &#123;x: batch_x, y: batch_y, keep_prob: 1.0&#125;)</div><div class="line">				print(&quot;MSG : Epoch &#123;&#125;, Training accuracy = &#123;:.6f&#125;, Training loss = &#123;:.5f&#125;&quot;.format((step // 100) + 1, acc, cost))</div><div class="line"></div><div class="line">		test_data = mnist.test.images.reshape(-1, time_step, n_input)</div><div class="line">		test_labels = mnist.test.labels</div><div class="line">		print(sess.run(accuracy, feed_dict = &#123;x: test_data, y: test_labels, keep_prob: 1.0&#125;))</div></pre></td></tr></table></figure>
<p>至此，基本能够掌握Tensorflow在神经网络构建过程中的一些流程细节。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍（Introduction）&quot;&gt;&lt;a href=&quot;#介绍（Introduction）&quot; class=&quot;headerlink&quot; title=&quot;介绍（Introduction）&quot;&gt;&lt;/a&gt;介绍（Introduction）&lt;/h1&gt;&lt;p&gt;Tensorflow是一个使
    
    </summary>
    
    
      <category term="Tensorflow" scheme="http://yoursite.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>挖掘神经网络的本质</title>
    <link href="http://yoursite.com/2017/08/09/Feature/"/>
    <id>http://yoursite.com/2017/08/09/Feature/</id>
    <published>2017-08-09T03:10:11.000Z</published>
    <updated>2017-08-09T03:11:43.872Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Features-amp-Feature-Representation"><a href="#Features-amp-Feature-Representation" class="headerlink" title="Features &amp; Feature Representation"></a>Features &amp; Feature Representation</h1><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>在神经网络训练过程中，我们往往会因为无法理解输入和输出数据之间的关系而面临无从选择神经网络结构模块的问题。为了进一步理解神经网络的功能和明白每一层神经网络层对输出的贡献程度，我们就必须了解这些输入在经过神经网络处理后是如何改变和反应在输出数据中的。</p>
<h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><p>以传统的分类问题为例，想要利用神经网络解决分类的问题，就必须明确我们的输入数据拥有的哪些 <strong>特征（Features）</strong> 能够帮助我们区分这些输入从而将他们分配到不同的 <strong>类别（Labels）</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/jzBDTBp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>不同的特征数据对分类的结果具有不同的影响力，这也使得我们的神经网络需要学习一个能够区分特征的能力，而这个能力就是我们所谓的 <strong>权重值（Weights）</strong>。不同的权重值控制输入的特征值能够以不同的力度作用在最终的结果上，从而达到区分标记的作用。</p>
<ul>
<li>以二维空间的散点二分类问题为例子，图中的点具有两个Label值，分别为 <strong>“蓝色”</strong> 和 <strong>“橙色”</strong>。而反应他们分布情况的特征可能有很多，比如空间的坐标值（X1 和 X2）或是距离原点（0, 0）的距离等。这里我们取坐标值作为输入的特征值。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2wzMVJM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>特征值的输入方式有很多，除了特征值自己本身，我们还可以通过数学模型将这些特征值进行组合和转换，从而衍生出另一种特征值。这和神经网络层所做的事情十分类似，他们都是通过现有的特征想方设法组合出一些更加具有代表性的区分特征，从而拉近输入数据和Label之间的距离。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/QVsmwpV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/dV8dNYU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>假设我们的特征值 <strong>X1</strong> 能够将数据空间的分布从<strong>X1 = 0</strong>处切分开来。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/J3lsiIP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UQ2aBYH.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>而组合特征值 <strong>X1X2</strong> 能够将数据空间的分布从<strong>X1 = 0和X2 = 0</strong>处同时切分开来，这时我们就可以利用这些特征表示法对最终的分布集合进行一个调整：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/WZbaqm1.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>图中左边为我们选择使用的输入特征值和对应的区分方式。经过3层的神经网络层，它能够将这些特征的区分方式进行组合（动态增强某些部分）和调整（动态削弱某个部分），得到另外一个特征的表示（Feature Representation），这些表示方式会对最后的模型进行直接的影响。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/xIKLGIq.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>神经网络的全连接（Fully Connected）也是有权重之分的，图中橙色的连接表示传入的Feature对当前的特征构建是有负向的影响（需要削弱）的，而相反蓝色的连接表示传入的Feature对当前的特征构建是有正向影响（需要加强）的。而线条的深浅则表示Feature对神经网络层的作用强度，越深的颜色表示影响越强烈。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/X2SQyYj.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果我们观察每一个神经网络层中产生的任何一个新的特征表示（Feature Representation），我们就能观察到它们是如何作用在神经网络分配中的。原先的Feature无法在图中画出圆形的间隔区域，因此我们需要通过神经网络的计算来对Feature进行 <strong>变形和组合</strong>，让这些Feature能够更好地拟合我们的数据集。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vSK3uLp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>训练过程中，神经网络会通过反向传递的方式动态调整layer中的Feature Representation，让这些形成的分割区域在经过了每次迭代之后能够更好的优化边缘，形成更完美的分类器。如果资料内部的噪声（Noise）比较少的时候，甚至可以达到100%的区分率（即loss = 0）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/SBUWfnO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>但是现实生活中的数据是无法做到完全没有噪声干扰的，些许的噪声都会让资料集看起来无法完全区隔开来（如上图所示）。这时候我们通常就会选择使用维度扩充的方式，让他们在更高维度上进行收敛（也就是寻找其他特征，其中X1为第一维度，X2为第二维度），然后在将这些特征压缩成其他的Feature Representation。</li>
</ul>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>训练完毕的模型可以很好地通过Feature Representation将数据集在有限维度空间中区隔开来。但是不能忽视的一点是，我们的模型是用来最终判断资料特性而选择的模型，不是为了完全拟合训练数据的产物。因此我们往往不会选择训练误差最小的模型作为我们的最终模型，原因是因为这些模型的灵活度太低。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/iMVS7Rs.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如上图所示，深色的点表示我们测试集资料，不难看出测试集的分布情况和训练集还是具有一定的差距的，如果我们的模型过分依赖训练集的边缘特性，那么在预测过程中就没有办法很好地区分那些全新的（训练集中未出现的）数据，反而造成测试误差的提升。因此我们需要通过类似Cross Validation等评估方式来让模型训练结果保持在较好的一个的动态范围内。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Features-amp-Feature-Representation&quot;&gt;&lt;a href=&quot;#Features-amp-Feature-Representation&quot; class=&quot;headerlink&quot; title=&quot;Features &amp;amp; Feature
    
    </summary>
    
    
      <category term="Feature" scheme="http://yoursite.com/tags/Feature/"/>
    
      <category term="Feature Representation" scheme="http://yoursite.com/tags/Feature-Representation/"/>
    
      <category term="Neural Netword" scheme="http://yoursite.com/tags/Neural-Netword/"/>
    
  </entry>
  
  <entry>
    <title>十大常见机器学习算法</title>
    <link href="http://yoursite.com/2017/08/08/ML-algorithms/"/>
    <id>http://yoursite.com/2017/08/08/ML-algorithms/</id>
    <published>2017-08-08T08:09:23.000Z</published>
    <updated>2017-08-08T08:11:02.738Z</updated>
    
    <content type="html"><![CDATA[<p>常用的机器学习算法，几乎可以用在所有的数据问题上：</p>
<h2 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h2><p>线性回归通常用于根据<strong>连续变量</strong>估计实际数值等问题上。通过拟合最佳的<strong>直线</strong>来建立<strong>自变量（X，features）</strong> 和 <strong>因变量（Y，labels）</strong> 的关系。这条直线也叫做回归线，并用<strong>Y = a* X + b</strong>来表示。</p>
<p>在这个等式中：</p>
<ul>
<li><code>Y</code> : 因变量（也就是Labels）</li>
<li><code>a</code> : 斜率（也就是Weights）</li>
<li><code>X</code> : 自变量（也就是Features）</li>
<li><code>b</code> : 截距（也就是Bias）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PSM7e7e.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>系数 <code>a</code> 和 <code>b</code> 可以通过<strong>最小二乘法</strong>（即让所有pairs带入线性表达式等号两边的方差和最小）获得。</p>
<h2 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h2><p>逻辑回归虽然名字中带有<strong>回归</strong>字样，但其实是一个<strong>分类</strong>算法而不是回归算法。该算法根据已知的一系列因变量估计<strong>离散的数值</strong>（0或1，代表假和真）。该算法通过将数据拟合进一个逻辑函数来预估一个事件发生的<strong>概率</strong>。由于其估计的对象是概率，所以输出的值大都在0和1之间。</p>
<p>逻辑回归通常用于解决二分类的问题，例如判断人是男是女等。逻辑回归就是通过人的一些基本性状特征来判断属于男女的概率。</p>
<p>从数学角度看，几率的对数使用的是<strong>预测变量的线性组合</strong>模型。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Probability of event occurence / not occurence</span></div><div class="line">odds = p / (<span class="number">1</span> - p)</div><div class="line">ln(odds) = ln(p / (<span class="number">1</span> - p))</div><div class="line">logit(p) = ln(p / (<span class="number">1</span> - p)) = b0 + b1X1 + b2X2 + ... + bnXn</div></pre></td></tr></table></figure></p>
<p>式子中 <code>p</code> 指的是特征出现的概率，它选用使观察样本可能性最大的值（<strong>极大似然估计</strong>）作为参数，而不是通过最小二乘法得到。</p>
<ul>
<li><p>那么为什么要取对数log呢？</p>
<ul>
<li>简而言之就是对数这种方式是复制阶梯函数最好的方法之一。</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hq1q9Z5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>关于改进模型的方法：<ul>
<li>加入交互项（<strong>X1 * X2</strong>等）</li>
<li>对输入输出进行正规化</li>
<li>使用非线性模型</li>
</ul>
</li>
</ul>
<h2 id="决策树（Decision-Tree）"><a href="#决策树（Decision-Tree）" class="headerlink" title="决策树（Decision Tree）"></a>决策树（Decision Tree）</h2><p>该算法属于监督式学习的一部分，主要用来处理分类的问题，它能够适用于分类连续因变量。我们将主体分成两个或者更多的类群，根据重要的属性或者自变量来尽可能多地区分开来。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8Nj3E0r.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>根据不同的决策属性，我们可以依次将输入进行分类，最终会得到一个标签（Label）。为了把总体分成不同组别，需要用到许多技术，比如<strong>Gini、Information Gain</strong> 和 <strong>Entropy</strong> 等。</li>
</ul>
<h3 id="Gini"><a href="#Gini" class="headerlink" title="Gini"></a>Gini</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ltVHIxt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中的实际分配曲线（红线）和绝对平衡线（绿线）之间的<strong>面积</strong>为A，和绝对不平衡线（蓝线）之间的面积为B，则横纵坐标之间的比例的<strong>Gini系数</strong>为：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {A \over A + B}" style="border:none;"></p>
<ul>
<li>A为零时，Gini系数为0，表示完全平衡。B为零时，Gini系数为1，表示完全不平衡。</li>
</ul>
<h3 id="Information-Gain-amp-Entropy"><a href="#Information-Gain-amp-Entropy" class="headerlink" title="Information Gain &amp; Entropy"></a>Information Gain &amp; Entropy</h3><p>在我们建立决策树的时候，常常会有许多属性，那么用哪一个属性作为数的根节点呢？这个时候就需要用到 <strong>信息增益（Information Gain）</strong> 来衡量一个属性区分以上数据样本的能力强弱。信息增益越大的属性作为数的根节点，就能使得这棵树更加简洁。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/9vwwsJt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>以图中数据为例，要想知道信息增益，就必须先算出分类系的<strong>熵值（Entropy）</strong>。最终结果的label是yes或者no，所以统计数量之后共有9个yes和5个no。这时候<strong>P（“yes”） = 9 / 14，P（“no”） = 5 / 14</strong>。这里的熵值计算公式为：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(S) = {-(9 / 14) * log2(9 / 14) - (5 / 14) * log2(5 / 14)}" style="border:none;"></p>
<ul>
<li>之后就可以计算每一个属性特征的信息增益（Gain）了。以wind属性为例，Wind为Weak的共有8条，其中yes的有6条，no的有2条；为Strong的共有6条，其中yes的有3条，no的也有3条。因此相应的熵值为：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(Weak) = {-(6 / 8) * log2(6 / 8) - (2 / 8) * log2(2 / 8)}" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(Strong) = {-(3 / 6) * log2(3 / 6) - (3 / 6) * log2(3 / 6)}" style="border:none;"></p>
<ul>
<li>现在就可以计算Wind属性的<strong>信息增益</strong>了：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Gain(Wind) = {Entropy(S) -(8 / 14) * Entropy(Weak) - (6 / 14) * Entropy(Strong)}" style="border:none;"></p>
<h2 id="支持向量机（Support-vector-machine-SVM）"><a href="#支持向量机（Support-vector-machine-SVM）" class="headerlink" title="支持向量机（Support vector machine,SVM）"></a>支持向量机（Support vector machine,SVM）</h2><p>SVM是一种常用的机器学习分类方式。在这个算法过程中，我们将每一笔数据在<strong>N维度的空间中用点表示（N为特征总数，Features）</strong>，每个特征的值是一个坐标的值。</p>
<p>如果以二维空间为例，此时有两个特征变量，我们会在空间中画出这两个变量的分布情况，每个点都有两个坐标（分别为tuples所具有的特征值组合）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ea3Jb95.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>现在我们找一条直线将两组不同的数据在维度空间中分开。分割的曲线满足让两个分组中的距离最近的两个点到直线的距离<strong>动态最优化</strong>（都尽可能最近）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/NGsSXtM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>那么看到这里一定很多人和我一样有一个疑问，那就是这种线性分类的SVM和之前提到的逻辑回归（Logistic Regression）有什么<strong>区别</strong>呢？</li>
</ul>
<p>其实他们在二维空间的<strong>线性分类</strong>中都扮演了重要的角色，其主要区别大致可分为两类：</p>
<ul>
<li><p>寻找最优超平面的方式不同。</p>
<ul>
<li>形象来说就是Logistic模型找的超平面（二维中就是线）是尽可能让所有点都远离它。而SVM寻找的超平面，是只让最靠近的那些点远离，这些点也因此被称为<strong>支持向量样本</strong>，因此模型才叫<strong>支持向量机</strong>。</li>
</ul>
</li>
<li><p>SVM可以处理非线性的情况。</p>
<ul>
<li>比Logistic更强大的是，SVM还可以处理<strong>非线性</strong>的情况（经过优化之后的Logistic也可以，但是却更为复杂）。</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/5seIoZJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="朴素贝叶斯（Naive-Bayesian）"><a href="#朴素贝叶斯（Naive-Bayesian）" class="headerlink" title="朴素贝叶斯（Naive Bayesian）"></a>朴素贝叶斯（Naive Bayesian）</h2><p>在假设变量间<strong>相互独立</strong>的前提下，根据贝叶斯定理（Bayesian Theorem）可以推得朴素贝叶斯这个分类方法。通俗来说，一个朴素贝叶斯分类器假设分类的特性和其他特性不相关。朴素贝叶斯模型容易创建，而且在非监督式学习的大型数据样本集中非常有用，虽然简单，却能超越复杂的分类方法。其基本思想就是：对于给出的待分类项，求解<strong>在此项出现的条件下各个目标类别出现的概率</strong>，哪个最大，就认为此待分类项属于哪个类别。</p>
<p>贝叶斯定理提供了从P（c）、P（x）和P（x | c）计算后验概率P（c | x）的方法:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(c | x) = {P(x | c) P(c) \over P(x)}" style="border:none;"></p>
<p>式子中的变量表示如下：</p>
<ul>
<li>P（c | x）是已知预测变量（属性特征）的前提下，目标发生的后验概率。</li>
<li>P（c）是目标发生的先验概率。</li>
<li>P（x | c）是已知目标发生的前提下，预测变量发生的概率。</li>
<li>P（x）是预测变量的先验概率。</li>
</ul>
<p>举一个例子：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gBuFCBd.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这是一个训练资料集，提供一些身体特征，用来预测人的性别。此时假设特征之间独立且满足高斯分布，则得到下表：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eSwuOJV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通过计算方差、均值等参数，同时确认Label出现的频率来判断训练集的样本分布概率，P（male） = P（female） = 0.5。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qZPw7xC.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>此时给出测试资料，我们希望通过计算得到性别的后验概率从而判断样本的类型：</li>
</ul>
<p><strong>男子的后验概率</strong>:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior(male) = {P(male) P(height | male) P(weight | male) P(footsize | male) \over evidence}" style="border:none;"></p>
<p><strong>女子的后验概率</strong>:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior(female) = {P(female) P(height | female) P(weight | female) P(footsize | female) \over evidence}" style="border:none;"></p>
<p>证据因子（evidence）通常为常数，是用来对结果进行归一化的参数。</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Evidence = {(Posterior(female) + Posterior(male)) * evidence}" style="border:none;"></p>
<ul>
<li>因此我们可以计算出相应结果：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(height | male) = {1 \over \sqrt{2\pi\sigma^2}}exp({-(6 - \mu^2) \over 2\sigma^2})" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(weight | male) = ..." style="border:none;"></p>
<ul>
<li>最后可以得出后验概率:</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior Numerator(male) = {6.1984e^{-09}}" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior Numerator(female) = {5.3778e^{-04}}" style="border:none;"></p>
<ul>
<li>因此女性的概率较大，我们估计结果为女性。</li>
</ul>
<h2 id="K近邻（K-Nearest-Neighbors）"><a href="#K近邻（K-Nearest-Neighbors）" class="headerlink" title="K近邻（K Nearest Neighbors）"></a>K近邻（K Nearest Neighbors）</h2><p>该算法可以用于分类和回归问题，然而我们更常将其被用于解决分类问题上。KNN能够存储所有的案例，通过对比周围K个样本中的大概率情况，从而决定新的对象应该分配在哪一个类别。新的样本会被分配到它的K个最近最普遍的类别中去，因此KNN算法也是一个基于距离函数的算法。</p>
<p>这些<strong>距离函数</strong>可以是欧氏距离、曼哈顿距离、明氏距离或是汉明距离。前三个距离函数用于<strong>连续函数</strong>，最后一个用于<strong>分类变量</strong>。如果K = 1，新的样本就会被直接分到距离最近的那个样本所属的类别中。因此选择K是一个关系到模型精确度的问题。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7sGrxz0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如图所示，如果我们取K = 3，即为中间的圆圈内，我们可以直观地看出此时绿点应该被归为红三角的一类。而如果K = 5，此时延伸到虚线表示的圆，则此时绿点应该被归为蓝色的类。</li>
</ul>
<p>在选择KNN之前，我们需要考虑的事情有：</p>
<ul>
<li>KNN在K数量大的时候的计算成本很高。</li>
<li>变量（Features）应该先标准化（normalized），不然会被更高数量单位级别的范围带偏。</li>
<li>越是<strong>干净</strong>的资料效果越好，如果存在偏离度较高的杂讯噪声，那么在类别判断时就会收到干扰。</li>
</ul>
<h3 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h3><p>空间中点X = （X1，X2，X3，…，Xn）与点Y = （Y1，Y2，Y3，…，Yn）的欧氏距离为：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large d(x, y) := {\sqrt{(X1 - Y1)^2 + (X2 - Y2)^2 + ... + (Xn - Yn)^2}}" style="border:none;"></p>
<h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h3><p>在平面上，坐标（X1，X2，…，Xn）的点和坐标（Y1，Y2，…，Yn）的点之间的曼哈顿距离为:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {|X1 - Y1| + |X2 - Y2| + ... + |Xn - Yn|}" style="border:none;"></p>
<h3 id="明氏距离"><a href="#明氏距离" class="headerlink" title="明氏距离"></a>明氏距离</h3><p>两点 P = (X1，X2，…，Xn) 和 Q = （Y1，Y2，…，Yn）之间的明氏距离为:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {(|X1 - Y1|^p + |X2 - Y2|^p + ... + |Xn - Yn|^p)^{1 \over p}}" style="border:none;"></p>
<ul>
<li>其中p取1时为曼哈顿距离，p取2时为欧氏距离。</li>
</ul>
<h3 id="汉明距离"><a href="#汉明距离" class="headerlink" title="汉明距离"></a>汉明距离</h3><p>对于固定长度n，汉明距离是该长度字符串向量空间上的度量，即表示长度n中不同字符串的个数。</p>
<p>例子：</p>
<ul>
<li><strong>“toned”</strong> 和 <strong>“roses”</strong> 之间的汉明距离就是3。因为其中 <strong>t - &gt; r，n -&gt; s，d -&gt; s</strong> 三个字符不相同。</li>
</ul>
<h2 id="K均值（K-means）"><a href="#K均值（K-means）" class="headerlink" title="K均值（K-means）"></a>K均值（K-means）</h2><p>K-means方法是一种<strong>非监督式学习</strong>的算法，能够解决<strong>聚类</strong>问题。使用K-means算法将一个数据样本归入一定数量的集群中（假设有K个）中，每一个集群的数据点都是均匀齐次的，并且异于其它集群。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/WQlIGo4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>K-means算法如何形成<strong>集群</strong>？</p>
<ul>
<li>给一个集群选择K个点，这些点称为质心。</li>
<li>给每一个数据点与距离最接近的质心形成一个集群，也就是K个集群。</li>
<li>根据现有的类别成员，找出每个类别的质心。</li>
<li>当有新的样本输入后，找到距离每个数据点最近的质心，并与质心对应的集群归为一类，计算新的质心位置，重复这个过程直到数据收敛，即质心位置不再改变。</li>
<li>如果新的数据点到多个质心的距离相同，则将这个数据点作为<strong>新的质心</strong>。</li>
</ul>
<p>如何决定K值？</p>
<ul>
<li>K-means算法涉及到集群问题，每个集群都有自己的质心。一个集群的内的质心和个数据点之间的距离的平方和形成了这个集群的平方值之和。我们能够直观地想象出当集群的内部的数据点增加时，K值会跟着下降（数据点越多，分散开来每个质心能够包揽的范围就变大了，这时候其他的集群就会被吞并或者分解）。<strong>集群元素数量的最优值</strong>也就是在集群的平方值之和最小的时候取得（每个点到质心的距离和最小，分类最精确）。</li>
</ul>
<h2 id="随机森林（Random-Forest）"><a href="#随机森林（Random-Forest）" class="headerlink" title="随机森林（Random Forest）"></a>随机森林（Random Forest）</h2><p>Random Forest是表示<strong>决策树总体</strong>的一个专有名词。在算法中我们有一系列的决策树（因此为<strong>森林</strong>）。为了根据一个新的对象特征将其分类，每一个决策树都有一个分类结果，称之为这个决策树<strong>投票</strong>给某一个分类群。这个森林选择获得其中（所有决策树）<strong>投票数最多</strong>的分类。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/xViexYM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Random Forest中的Decision Tree是如何形成的？</p>
<ul>
<li>如果训练集的样本数量为N，则从N个样本中用重置抽样的方式随机抽取样本。这个样本将作为决策树的训练资料。</li>
<li>假如有N个输入特征变量，则定义一个数字<strong>m &lt;&lt; M</strong>。m表示从M中随机选中的变量，这m个变量中最好的切分特征会被用来当成节点的决策特征（利用Information Gain等方式）。在构建其他决策树的时候，m的值<strong>保持不变</strong>。</li>
<li>尽可能大地建立每一个数的节点分支。</li>
</ul>
<h2 id="降维（Dimensionality-reduction）"><a href="#降维（Dimensionality-reduction）" class="headerlink" title="降维（Dimensionality reduction）"></a>降维（Dimensionality reduction）</h2><p>当今的社会中信息的捕捉量都是呈上升的趋势。各种研究信息数据都在尽可能地捕捉完善，生怕遗漏一些关键的特征值。对于这些数据中包含许多特征变量的数据而言，看似为我们的模型建立提供了充足的<strong>训练材料</strong>。但是这里却存在一个问题，那就是<strong>如何从上百甚至是上千种特征中区分出样本的类别呢？</strong>样本特征的<strong>重要程度</strong>又该如何评估呢？</p>
<ul>
<li>其实随着输入数据特征变量的增多，模型很难拟合众多样本变量（高维度）的数据分类规则。这样训练出来的模型不但<strong>效果差</strong>，而且<strong>消耗大量的时间</strong>。</li>
<li>这个时候，降维算法和别的一些算法（比如<strong>Decision Tree</strong>、<strong>Random Forest</strong>、<strong>主成分分析（PCA）</strong> 和 <strong>因子分析</strong>）就能帮助我们实现根据相关矩阵，压缩维度空间之后总结特征规律，最终再逐步还原到高维度空间的训练模式。</li>
</ul>
<h3 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h3><p>在多元统计分析中，PCA是一种分析、简化数据集的技术，经常用于减少数据集的维数，同时保留数据集中的<strong>对方差贡献最大</strong>的那些特征变量。</p>
<ul>
<li>该算法会根据不同维度的压缩（在这个维度上的<strong>投影</strong>）来测试<strong>各个维度对方差的影响</strong>，从而对每一个维度进行重新排序（影响最大的放在第一维度）。之后只需要取有限个数的维度进行训练，就能够保证模型拟合最佳的数据特征了。</li>
</ul>
<h3 id="因子分析"><a href="#因子分析" class="headerlink" title="因子分析"></a>因子分析</h3><p>该算法主要是从关联矩阵内部的依赖关系出发，把一些重要信息重叠，将错综复杂的变量归结为少数几个不相关的综合因子的多元统计方法。基本思想是：根据<strong>相关性大小</strong>把变量分租，使得同组内的变量之间相关性高，但不同组的变量不相关或者相关性低。每组变量代表一个基本结构，即公共因子。</p>
<h2 id="Gradient-Boost-amp-Adaboost"><a href="#Gradient-Boost-amp-Adaboost" class="headerlink" title="Gradient Boost &amp; Adaboost"></a>Gradient Boost &amp; Adaboost</h2><p>当我们想要处理很多数据来做一个具有高度预测能力的预测模型时，我们会用到Gradient Boost和AdaBoost这两种Boosting算法。<strong>Boosting算法</strong>是一种集成学习算法，它结合了建立在多个基础估计值上的预测结果，来增强单个估计值的准确度。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eOKOw6J.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h3><p>Bossting能够对一份数据建立多个模型（如分类模型），通常这些模型都比较简单，称为<strong>弱分类器（Weak Learner）</strong>。每次分类都将上一次分错的数据权重值调大（放大的圆圈），然后再次进行分类，最终得到更好的结果。最终所有学习器（在这里值分类器）共同组成完整的模型。</p>
<h3 id="Gradient-Boost"><a href="#Gradient-Boost" class="headerlink" title="Gradient Boost"></a>Gradient Boost</h3><p>与Adaboost不同的是，Gradient Boost在迭代的时候选择梯度下降的方向来保证最后的结果最好。损失函数（Loss function）用来描述模型的误差程度，如果模型没有Over fitting，那么loss的值越大则误差越高。如果我们的模型能够让损失函数值下降，说明它在不断改进，而最好的方式就是让函数在<strong>梯度的方向</strong>上改变。（类似神经网络的<strong>Gradient Descend</strong>）</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;常用的机器学习算法，几乎可以用在所有的数据问题上：&lt;/p&gt;
&lt;h2 id=&quot;线性回归（Linear-Regression）&quot;&gt;&lt;a href=&quot;#线性回归（Linear-Regression）&quot; class=&quot;headerlink&quot; title=&quot;线性回归（Linear R
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Algorithm" scheme="http://yoursite.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>医疗管理系统</title>
    <link href="http://yoursite.com/2017/08/04/database/"/>
    <id>http://yoursite.com/2017/08/04/database/</id>
    <published>2017-08-04T06:51:50.000Z</published>
    <updated>2017-08-04T06:54:32.035Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本系统主要是基于 <code>Struts2 MVC架构</code> + <code>mysql资料库</code> 共同开发的医疗信息管理系统模型。利用JSP打造简易的网页与接口，让用户能够通过系统纪录和查询医疗的细节流程。</p>
<p><a href="https://github.com/EternalFeather/Medical_Management_System_with_Database" target="_blank" rel="external">下載鏈接</a></p>
<h1 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h1><ul>
<li><code>操作系统</code>：Windows10</li>
<li><code>资料库</code>：Mysql</li>
<li><code>IDE</code>：Eclipse</li>
<li><code>开发语言</code>：Jsp + Sql + Java</li>
</ul>
<h1 id="SQL-Table"><a href="#SQL-Table" class="headerlink" title="SQL Table"></a>SQL Table</h1><p>资料库端分为五个Table，分别为 <code>Department</code>、<code>Employee</code>、<code>Hospital</code>、<code>Patient</code> 和 <code>Report</code>。</p>
<h2 id="Attribute-Introduction"><a href="#Attribute-Introduction" class="headerlink" title="Attribute Introduction"></a>Attribute Introduction</h2><p><strong>Hospital Table:</strong> 記錄醫院的具體信息</p>
<ul>
<li>Hospital_ID:每間醫院的編號（唯一）</li>
<li>Hospital_Name:醫院的名稱</li>
<li>Hospital_Address:醫院的地理位置</li>
<li>Hospital_Scale:醫院的規模大小</li>
</ul>
<p><strong>Department Table:</strong> 記錄醫院里各個不同部門的具體信息</p>
<ul>
<li>Department_ID:醫院裏面不同部門的編號（唯一）</li>
<li>Department_Subject:部門的名稱</li>
<li>Department_People:部門的人數</li>
<li>Field:部門所掌管的職能</li>
</ul>
<p><strong>Employee Table:</strong> 記錄醫院工作人員的具體信息</p>
<ul>
<li>Doctor_ID:每個員工的編號（唯一）</li>
<li>Doctor_Name:員工的姓名</li>
<li>Doctor_Age:員工的年齡</li>
<li>Doctor_Specialty:員工的專長</li>
</ul>
<p><strong>Patient Table:</strong> 記錄病人的具體信息</p>
<ul>
<li>Patient_ID:每個病人的編號（唯一）</li>
<li>Patient_Name:病人的姓名</li>
<li>Patient_Age:病人的年齡</li>
<li>Patient_Disease:病人的癥狀</li>
</ul>
<p><strong>Report Table:</strong> 記錄病人病歷記錄的具體信息</p>
<ul>
<li>Report_ID:每個病歷記錄的編號（唯一）</li>
<li>Report_Disease:病歷記錄的病人癥狀</li>
<li>Report_PatientName:病歷記錄的病人姓名</li>
<li>Report_Medicine:病歷記錄的病人用藥情況</li>
</ul>
<h1 id="ER-Diagram"><a href="#ER-Diagram" class="headerlink" title="ER Diagram"></a>ER Diagram</h1><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qdBYNZI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="Relation-Schema"><a href="#Relation-Schema" class="headerlink" title="Relation Schema"></a>Relation Schema</h1><table>
<thead>
<tr>
<th style="text-align:center">Hospital Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Hospital_ID</td>
<td style="text-align:center">Hospital_Name</td>
<td style="text-align:center">Hospital_Address</td>
<td style="text-align:center">Hospital_Scale</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Department Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Department_ID</td>
<td style="text-align:center">Department_Subject</td>
<td style="text-align:center">Department_People</td>
<td style="text-align:center">Field</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Employee Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Doctor_ID</td>
<td style="text-align:center">Doctor_Name</td>
<td style="text-align:center">Doctor_Name</td>
<td style="text-align:center">Doctor_Specialty</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Patient Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Patient_ID</td>
<td style="text-align:center">Patient_Name</td>
<td style="text-align:center">Patient_Age</td>
<td style="text-align:center">Patient_Disease</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Report Schema</th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Report_ID</td>
<td style="text-align:center">Report_Disease</td>
<td style="text-align:center">Report_PatientName</td>
<td style="text-align:center">Report_Medicine</td>
</tr>
</tbody>
</table>
<h1 id="Relationship-Introduction"><a href="#Relationship-Introduction" class="headerlink" title="Relationship Introduction"></a>Relationship Introduction</h1><ul>
<li>每個醫院都會有許多不同的部門，每個部門都是隸屬於某一家醫院。</li>
<li>每個醫院部門都會招聘不同數量的員工，未退休的員工會屬於某一個部門。</li>
<li>所有負責醫療工作的員工都會給病人開具病歷證明，所有的病歷證明都是由醫療工作員工開具的。</li>
<li>所有的病人都有自己的病歷記錄，所有的病歷記錄記錄著該病人的醫療情況。</li>
<li>負責醫療工作的員工會給病人看病，同時醫院的員工也有可能是病人。</li>
</ul>
<h1 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h1><p>配置好sql和server之后，就可以通过localhost或者IP来访问系统网址了，这里用的是Tomcat Server來訪問資料庫系統首頁。。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/OAdFgoI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/czWAFBo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>左邊的功能列表可以選擇需要操作的Entity進行不同的資料庫操作。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ukIeIjX.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>以醫院管理為例，進入醫院管理操作介面，系統會自動列出所有的數據庫資料。點擊左上角的<strong>添加</strong>按鈕可以添加新的醫院信息到database；同時可以通過<strong>Search</strong>的選項來索引資料庫裏面的資料；點擊操作欄位的<strong>修改和刪除</strong>可以分別對相應的資料進行修改和刪除；最後點擊右上角的<strong>手動修改和查詢</strong>可以分別通過手動輸入SQL指令來進行修改動作（insert，delete，update）和查詢動作（select）。</p>
<ul>
<li>添加介面：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PDo43C2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>可以<strong>添加</strong>醫院的相關信息到數據庫。</p>
<ul>
<li>選擇操作：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/mYQk0G0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>系統會給出相應的<strong>檢索</strong>結果：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UGf1VbP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>修改和刪除：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/9jEEf1k.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>點擊修改操作系統會自動捕捉當前的資料信息，方便進行<strong>修改</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/EZVj52s.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>點擊刪除操作系統會提示<strong>是否刪除</strong>，點擊確定則會從資料庫移除相應信息。</p>
<ul>
<li>手動修改和刪除：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eknZV1t.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/fqo6fRa.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>點擊<strong>手動修改和刪除</strong>操作，系統會跳出相應的輸入框，可以通過手動輸入SQL指令來進行Select檢索或者Insert，Update，Delete等操作。</p>
<ul>
<li>Nested Query和Aggregate Query（以醫生管理為例）：<br>點擊Nested Query會跳轉至如下畫面。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/9P6SJ1w.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>分別點擊不同的按鈕可以<strong>跳轉</strong>至相應功能對應的介面。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Cp7doj5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通過選項可以自動通過Button的方式呼叫資料庫，通過sql指令也可以進行資料庫的操作。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/df2ElPC.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通過選項操作同樣可以用button的方式呼叫資料庫操作，sql指令同樣也能夠進行相應的操作。（注：在sql對於Aggregate操作過程中需要對應下方的欄位進行as重命名）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本系统主要是基于 &lt;code&gt;Struts2 MVC架构&lt;/
    
    </summary>
    
    
      <category term="Database" scheme="http://yoursite.com/tags/Database/"/>
    
      <category term="System" scheme="http://yoursite.com/tags/System/"/>
    
      <category term="Struts MVC" scheme="http://yoursite.com/tags/Struts-MVC/"/>
    
  </entry>
  
  <entry>
    <title>Word2Vec on Wikipedia</title>
    <link href="http://yoursite.com/2017/08/04/word2vec/"/>
    <id>http://yoursite.com/2017/08/04/word2vec/</id>
    <published>2017-08-04T06:51:25.000Z</published>
    <updated>2017-08-04T07:53:29.800Z</updated>
    
    <content type="html"><![CDATA[<p>我们知道语言在人际交往当中充当了重要的角色，理解语言的编码就能够了解对方所要表达的意思。而机器不同于人，无法从繁杂的文字当中快速提取有用的信息，因此需要借助一个能够代表文字语言的编码单位，也就是我们说的<strong>向量（Vector）</strong>。因此训练Word2Vec的模型，用来计算词语之间的相似度似乎成为了解决文字编码问题的不可或缺的重要途径之一。</p>
<h1 id="配置需求"><a href="#配置需求" class="headerlink" title="配置需求"></a>配置需求</h1><ul>
<li><code>Python3</code></li>
<li><code>Gensim</code> &gt;= 2.3.0 (<strong>沒試過更低的版本</strong>)</li>
<li><code>Opencc</code></li>
<li><code>jieba</code></li>
</ul>
<h1 id="模型训练语料"><a href="#模型训练语料" class="headerlink" title="模型训练语料"></a>模型训练语料</h1><ul>
<li>维基百科官方提供了大约11G的很好的英文語料： <a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2" target="_blank" rel="external">開源數據鏈接</a>。</li>
<li>同時也提供了大約1.5G的中文語料： <a href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2" target="_blank" rel="external">開源數據鏈接</a>。</li>
</ul>
<p>其主要的文档格式以 <code>.xml</code> 为主。</p>
<h1 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h1><ul>
<li>下載相應的Python執行檔：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/EternalFeather/Word2Vec-on-Wikipedia-Corpus.git</div></pre></td></tr></table></figure>
<h2 id="資料前處理"><a href="#資料前處理" class="headerlink" title="資料前處理"></a>資料前處理</h2><p>前處理第一階段需要將wiki的 <code>.xml</code> 格式的數據轉換成 <code>text</code> 格式的數據:</p>
<ul>
<li><p>通過 <code>word2vec_process.py</code> 實現，基本參數包括：</p>
<ul>
<li><code>-data</code>： 輸入的維基百科數據集。</li>
<li><code>-output</code>： 輸出的文件位置和名稱。</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python word2vec_process.py -data enwiki-latest-pages-articles.xml.bz2 -output wiki.en.text</div></pre></td></tr></table></figure>
<p><strong>Tips:</strong> </p>
<ul>
<li>如果是中文維基百科的語料訓練時，會存在一些繁體和簡體混雜的中文字，如果想要統一字體格式，就可以使用Opencc將字體進行轉換：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">opencc -i wiki.zh.text -o wiki.zh.text.jianti -c zht2zhs.ini</div></pre></td></tr></table></figure>
<ul>
<li>中文的維基百科數據接下來就是需要進行斷詞處理了，這裏使用的<strong>中文斷詞工具</strong>是 <code>jieba</code>。</li>
</ul>
<p>這裏利用了gensim裏面處理維基百科的class <code>WikiCorpus</code>，通過 <code>get_texts</code> function將每篇文章換行輸出成text文本，並且已經完成了去標點的工作。運行之後就能夠得到英文維基百科的數據文檔 <code>wiki.en.text</code>(參數可自行設定名稱)。</p>
<h2 id="模型訓練"><a href="#模型訓練" class="headerlink" title="模型訓練"></a>模型訓練</h2><p>有了文章的text數據集之後，無論是word2vec binary版本還是gensim的word2vec，都可以用來訓練我們的模型，不過後者的運算速度比較快。</p>
<ul>
<li><p>模型的建立通過 <code>word2vec_model.py</code> 實現，基本參數包括：</p>
<ul>
<li><code>-text</code>： 輸入的維基百科文字檔名稱。</li>
<li><code>-vector</code>： 輸出的向量文檔存儲位置和名稱（默認爲 <strong>wiki.en.text.vector</strong>）。</li>
<li><code>-core</code>： 多進程運行使用的cpu數量（默認爲全部）。</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python word2vec_model.py -text wiki.en.text -vector wiki.en.text.vector -core 8</div></pre></td></tr></table></figure>
<h2 id="模型測試"><a href="#模型測試" class="headerlink" title="模型測試"></a>模型測試</h2><p>訓練結束之後就能得到一個gensim原始c版本的word2vec的vector格式的模型，這時候我們就可以利用這些模型進行一些文字的評估測試了：</p>
<ul>
<li><p>導入模型進行操作通過 <code>word2vec_eval.py</code> 實現，基本參數包括：</p>
<ul>
<li><code>-vector</code>： 載入的模型位置和名稱。</li>
<li><code>-mode</code>： 想要執行模型的功能名稱（包括 <em>similar<strong>【預測相關的words】、</strong>similarity*</em>【判斷兩個words的相似度】等）</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python word2vec_eval.py -vector wiki.en.text.vector -mode similarity</div></pre></td></tr></table></figure>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="http://www.52nlp.cn/%E4%B8%AD%E8%8B%B1%E6%96%87%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E8%AF%AD%E6%96%99%E4%B8%8A%E7%9A%84word2vec%E5%AE%9E%E9%AA%8C" target="_blank" rel="external">我愛自然語言處理</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们知道语言在人际交往当中充当了重要的角色，理解语言的编码就能够了解对方所要表达的意思。而机器不同于人，无法从繁杂的文字当中快速提取有用的信息，因此需要借助一个能够代表文字语言的编码单位，也就是我们说的&lt;strong&gt;向量（Vector）&lt;/strong&gt;。因此训练Word
    
    </summary>
    
    
      <category term="Word2Vec" scheme="http://yoursite.com/tags/Word2Vec/"/>
    
      <category term="Embedding" scheme="http://yoursite.com/tags/Embedding/"/>
    
  </entry>
  
  <entry>
    <title>中文情緒字典（Chinese Sentiment Lexicon）</title>
    <link href="http://yoursite.com/2017/08/04/sentiment/"/>
    <id>http://yoursite.com/2017/08/04/sentiment/</id>
    <published>2017-08-04T06:51:16.000Z</published>
    <updated>2017-08-04T07:58:08.125Z</updated>
    
    <content type="html"><![CDATA[<h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p>利用 <code>PMI</code> 和 <code>SOC-PMI</code> 等語言統計分析算法，從現有文章中標記一些seed words，通過半監督式學習找出段落中隱含的其他情緒詞匯，從而建立起完整的情緒字典。</p>
<p>情緒字典的覆蓋範圍包括 <code>名詞</code> 、 <code>動詞</code> 和 <code>形容詞</code> 等部分，每個詞都會有一個正向分數（positive）和一個負向分數（negative）。兩個分數的高低可以判斷這個詞的情緒分布狀況。</p>
<h1 id="必要配置"><a href="#必要配置" class="headerlink" title="必要配置"></a>必要配置</h1><ul>
<li><code>Python2</code></li>
<li><code>JDK</code></li>
<li><code>jieba</code></li>
</ul>
<h1 id="使用流程"><a href="#使用流程" class="headerlink" title="使用流程"></a>使用流程</h1><ul>
<li>下載情緒字典程式：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/EternalFeather/Chinese-Sentiment-Lexicon.git</div></pre></td></tr></table></figure>
<ul>
<li>將預設的Seed Word（也就是自行標記的幾個情緒面向詞匯）放入 <code>SentimentLexicon/data/input/Seedwords.txt</code>  中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3KEOqCF.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>將需要提取情緒詞匯的訓練文章放入 <code>SentimentLexicon/data/input/Corpus.txt</code> 中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/nGJWyIO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>運行 <code>SL.jar</code> 文件即可開始訓練過程：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -jar &apos;SL.jar&apos;</div></pre></td></tr></table></figure>
<h1 id="測試結果"><a href="#測試結果" class="headerlink" title="測試結果"></a>測試結果</h1><ul>
<li>得到的結果會儲存在 <code>SentimentLexicon/data/Propagation/FinalMatrix.csv</code> 文件中。 </li>
</ul>
<p><img src="https://i.imgur.com/Ugyr8cq.png" alt=""></p>
<p>可以看出在比較詞的正負向上能夠取得比較可觀的結果。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;功能&quot;&gt;&lt;a href=&quot;#功能&quot; class=&quot;headerlink&quot; title=&quot;功能&quot;&gt;&lt;/a&gt;功能&lt;/h1&gt;&lt;p&gt;利用 &lt;code&gt;PMI&lt;/code&gt; 和 &lt;code&gt;SOC-PMI&lt;/code&gt; 等語言統計分析算法，從現有文章中標記一些seed wo
    
    </summary>
    
    
      <category term="Sentiment Lexicon" scheme="http://yoursite.com/tags/Sentiment-Lexicon/"/>
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
      <category term="PMI" scheme="http://yoursite.com/tags/PMI/"/>
    
  </entry>
  
  <entry>
    <title>Gal-game-on-Renpy</title>
    <link href="http://yoursite.com/2017/08/02/gal/"/>
    <id>http://yoursite.com/2017/08/02/gal/</id>
    <published>2017-08-02T07:09:53.000Z</published>
    <updated>2017-08-04T06:55:14.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="安裝說明"><a href="#安裝說明" class="headerlink" title="安裝說明"></a>安裝說明</h1><p>Renpy Platform可以用來設計自己專屬的視覺小說遊戲。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/nkF3saW.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p><a href="https://pan.baidu.com/s/1kVeIIoR" target="_blank" rel="external">Demo遊戲鏈接</a><br>提取密碼: <code>m0va</code></p>
<h1 id="素材來源"><a href="#素材來源" class="headerlink" title="素材來源"></a>素材來源</h1><p>遊戲使用的圖片、視頻以及音頻的剪輯原素材來源於 <code>FAVORITE</code> 和 <code>YUZUSOFT</code> 遊戲公司，未經授權不得用以商業目的性傳播和使用。大部分圖片經過PS修圖處理，<strong>如需轉載請注明出處</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7RkEoRe.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="使用說明"><a href="#使用說明" class="headerlink" title="使用說明"></a>使用說明</h1><ul>
<li>將Github上 <code>images.rar</code> 中的三個文件放入下載好的遊戲文件中的 <code>game/images/</code> 目錄中。</li>
<li>運行 <code>.exe</code> 文件即可開始遊戲。</li>
</ul>
<h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><ul>
<li>主界面（會根據劇情不同有所變化）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/kkJKDds.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>CG鑑賞頁面</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/sXbSQeM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/wEylyRQ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zz1W2PG.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>設定頁面</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ZdgAa0M.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>載入頁面</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8MQf1cJ.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>遊戲分支選單</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PzFMnpP.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>遊戲主題內容部分</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ydrcpP9.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>遊戲即時選單</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8Hq7y0e.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>選單 <code>ENCYCLOPEDIA</code> 遊戲介紹和玩法功能簡介</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/oBPr4mH.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/bHGIB3K.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;安裝說明&quot;&gt;&lt;a href=&quot;#安裝說明&quot; class=&quot;headerlink&quot; title=&quot;安裝說明&quot;&gt;&lt;/a&gt;安裝說明&lt;/h1&gt;&lt;p&gt;Renpy Platform可以用來設計自己專屬的視覺小說遊戲。&lt;/p&gt;
&lt;figure class=&quot;image-bubb
    
    </summary>
    
    
      <category term="Renpy" scheme="http://yoursite.com/tags/Renpy/"/>
    
      <category term="Gal-game" scheme="http://yoursite.com/tags/Gal-game/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04配置深度學習開發環境（CUDA+CUDNN）</title>
    <link href="http://yoursite.com/2017/08/01/cuda/"/>
    <id>http://yoursite.com/2017/08/01/cuda/</id>
    <published>2017-08-01T08:18:31.000Z</published>
    <updated>2017-08-04T06:54:57.123Z</updated>
    
    <content type="html"><![CDATA[<h1 id="顯卡規格查詢"><a href="#顯卡規格查詢" class="headerlink" title="顯卡規格查詢"></a>顯卡規格查詢</h1><p>首先需要確定自己顯卡的規格：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">lspci -vnn | grep VGA -A 12</div></pre></td></tr></table></figure></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Hqk5wzt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>其中<code>nvidia_375</code>就是顯卡的規格指數，後面會用到。</p>
<h1 id="安裝CUDA"><a href="#安裝CUDA" class="headerlink" title="安裝CUDA"></a>安裝CUDA</h1><p>前往<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">CUDA下載</a>頁面選擇好系統參數進行下載。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uxl5TQY.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="配置CUDA環境"><a href="#配置CUDA環境" class="headerlink" title="配置CUDA環境"></a>配置CUDA環境</h2><p>Installation Instructions:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb</div><div class="line">sudo apt-get update</div><div class="line">sudo apt-get install cuda</div></pre></td></tr></table></figure></p>
<h1 id="安裝cuDNN"><a href="#安裝cuDNN" class="headerlink" title="安裝cuDNN"></a>安裝cuDNN</h1><p>前往<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="external">cuDNN下載</a>點擊同意並選擇規格後開始下載。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VsYqKL0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="配置cuDNN環境"><a href="#配置cuDNN環境" class="headerlink" title="配置cuDNN環境"></a>配置cuDNN環境</h2><p>Installation Instructions:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar xvzf cudnn-8.0-linux-x64-v5.1-ga.tgz</div><div class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include</div><div class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64</div><div class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*</div></pre></td></tr></table></figure></p>
<h3 id="設定環境變數"><a href="#設定環境變數" class="headerlink" title="設定環境變數"></a>設定環境變數</h3><p>接下來到<code>.bashrc</code>檔案：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vim ~/.bashrc</div></pre></td></tr></table></figure>
<p>將下面的指令復制到配置文件的末尾：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/nvidia-375</div><div class="line">export CUDA_HOME=/usr/local/cuda</div><div class="line">export PATH=$PATH:/usr/local/cuda/bin</div></pre></td></tr></table></figure>
<p><strong>注意</strong>：其中的/usr/lib/nvidia-375就是之前查詢的顯卡規格。</p>
<h2 id="查看配置結果"><a href="#查看配置結果" class="headerlink" title="查看配置結果"></a>查看配置結果</h2><p>配置完成後可以查看是否成功配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nvidia-smi -l</div></pre></td></tr></table></figure>
<p>即可即時查看GPU的運作情況</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/xnyMEH3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="安裝Tensorflow-gpu"><a href="#安裝Tensorflow-gpu" class="headerlink" title="安裝Tensorflow-gpu"></a>安裝Tensorflow-gpu</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo pip install tensorflow-gpu</div></pre></td></tr></table></figure>
<p>安裝之後會加入pip library中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip freeze</div></pre></td></tr></table></figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qHCfJgT.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如此以來就可以用GPU操作深度學習的框架了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;顯卡規格查詢&quot;&gt;&lt;a href=&quot;#顯卡規格查詢&quot; class=&quot;headerlink&quot; title=&quot;顯卡規格查詢&quot;&gt;&lt;/a&gt;顯卡規格查詢&lt;/h1&gt;&lt;p&gt;首先需要確定自己顯卡的規格：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;tab
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="Tensorflow" scheme="http://yoursite.com/tags/Tensorflow/"/>
    
      <category term="CUDA" scheme="http://yoursite.com/tags/CUDA/"/>
    
      <category term="cuDNN" scheme="http://yoursite.com/tags/cuDNN/"/>
    
  </entry>
  
  <entry>
    <title>聊天机器人训练语料整理</title>
    <link href="http://yoursite.com/2017/07/25/Corpus/"/>
    <id>http://yoursite.com/2017/07/25/Corpus/</id>
    <published>2017-07-25T07:15:05.000Z</published>
    <updated>2017-08-04T06:54:46.051Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Dialog-Datasets-for-Training-Chatbot"><a href="#Dialog-Datasets-for-Training-Chatbot" class="headerlink" title="Dialog Datasets for Training Chatbot"></a>Dialog Datasets for Training Chatbot</h1><p>在进行Chatbot的研究过程中，除了要有一个漂亮的模型之外，还需要有大量可供训练的语料来强化我们的聊天机器人。越干净的语料就能训练出越接近人类自然语言回复的Chatbot。</p>
<ul>
<li>目前网上公开的语料大多是一些带有噪音的、数量有限的语料。在这里总结了一些可行的语料以及一些利用爬取工具得到的语料，其中包括：</li>
</ul>
<h1 id="基本公开语料"><a href="#基本公开语料" class="headerlink" title="基本公开语料"></a>基本公开语料</h1><ul>
<li><p><a href="https://github.com/rustch3n/dgk_lost_conv" target="_blank" rel="external">dgk_shooter_min.conv</a><br>中文电影对白语料，噪音大，由于对话未区分说话人，因此对白问答关系难以对应。</p>
</li>
<li><p><a href="https://github.com/gunthercox/chatterbot-corpus/tree/master/chatterbot_corpus/data/" target="_blank" rel="external">ChatBot多语种聊天语料</a><br>ChatterBot聊天引擎所提供的基本语聊，涵盖语种范围广，但是数量不多，但质量较高，适合模型测试。</p>
</li>
<li><p><a href="https://github.com/karthikncode/nlp-datasets#question-answering" target="_blank" rel="external">DataSets for Natural Language Processing</a><br>这个是人为收集总结的自然语言处理研究论文以及对应的数据资料集，主要覆盖方面包括了： <strong>Question Answering, Dialogue Systems</strong> 以及 <strong>Goal-Oriented Dialogue System</strong> 等。文本都由英文构成，可用于机器翻译和对话模型使用。</p>
</li>
<li><p><a href="https://github.com/rustch3n/dgk_lost_conv/tree/master/results" target="_blank" rel="external">小黄鸡对话机器人训练语料</a><br>这就是网络上流行的小黄鸡对话机器人的训练语料，包括了 <strong>xiaohuangji50w_fenciA.conv.zip （已分词）</strong> 和 <strong>xiaohuangji50w_nofenci.conv.zip （未分词）</strong> 两个部分，分词以 <strong>“/”</strong> 区隔开来，并没有语义上的划分。语料中含有较多表情颜文字，总体对话字数较少，杂讯较多。</p>
</li>
<li><p><a href="https://github.com/Samurais/egret-wenda-corpus" target="_blank" rel="external">白鹭时代中文问答语料</a><br>由白鹭时代官方论坛问答版块的问题及回复组成，回复选取了标注 <strong>“最佳答案”</strong> 的记录为目标。人工审核资料，给每一个问题一个可以接受的答案。数量不多，多为问答模式。</p>
</li>
<li><p><a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" target="_blank" rel="external">Cornell_Movie-Dialogs_Corpus</a><br>康奈尔大学影视对话资料集，语料包含对话人名称信息，语料为英文，以多轮对话为主。</p>
</li>
</ul>
<h1 id="个人爬取语聊（初步整理）"><a href="#个人爬取语聊（初步整理）" class="headerlink" title="个人爬取语聊（初步整理）"></a>个人爬取语聊（初步整理）</h1><ul>
<li><p><a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/news%20corpus" target="_blank" rel="external">中文新闻语料</a><br>利用爬虫从各大新闻网站上爬取的新闻头条和简讯。</p>
</li>
<li><p><a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/PTT_charactors" target="_blank" rel="external">PTT八卦版推文</a><br>利用爬虫从社交软体PTT上对于八卦分类板块的内容进行爬取，原始资料为 <a href="">PTT八卦板推文.txt</a> 其中包括一些符号和空格杂讯，过滤杂讯（利用统计方式按比例替换成固定符号，降低资料复杂度）之后，通过 <strong>单字</strong> 或 <a href="https://github.com/EternalFeather/Chatbot-Training-Corpus/tree/master/PTT_words" target="_blank" rel="external">词组</a>（jieba段词） 等不同方式建立问答语料和字典。</p>
</li>
</ul>
<h1 id="License"><a href="#License" class="headerlink" title="License:"></a>License:</h1><p>公开语料的版权归原作者所有，未经允许不得一个人名义投入盈利性活动。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Dialog-Datasets-for-Training-Chatbot&quot;&gt;&lt;a href=&quot;#Dialog-Datasets-for-Training-Chatbot&quot; class=&quot;headerlink&quot; title=&quot;Dialog Datasets for 
    
    </summary>
    
    
      <category term="Chatbot" scheme="http://yoursite.com/tags/Chatbot/"/>
    
      <category term="Corpus" scheme="http://yoursite.com/tags/Corpus/"/>
    
      <category term="Dialogue" scheme="http://yoursite.com/tags/Dialogue/"/>
    
  </entry>
  
  <entry>
    <title>Python简单学</title>
    <link href="http://yoursite.com/2017/07/25/Python/"/>
    <id>http://yoursite.com/2017/07/25/Python/</id>
    <published>2017-07-25T06:10:56.000Z</published>
    <updated>2017-08-04T06:55:33.518Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Foundation-Summary"><a href="#Foundation-Summary" class="headerlink" title="Foundation Summary"></a>Foundation Summary</h1><ul>
<li><strong>Print</strong></li>
<li><strong>Calculation Function</strong></li>
<li><strong>Variable</strong></li>
<li><strong>While loop</strong></li>
<li><strong>For loop</strong></li>
<li><strong>If/Elif/Else Condition</strong></li>
<li><strong>Function Definition[Def] with/without parameters</strong></li>
<li><strong>Global or Local Variable</strong></li>
<li><strong>Read or Write files</strong><ul>
<li><code>readlines()</code> and <code>readline()</code></li>
</ul>
</li>
<li><strong>Class</strong><ul>
<li><code>__init__</code> constructor</li>
</ul>
</li>
<li><strong>input</strong></li>
<li><strong>Tuple &amp; List</strong><ul>
<li>Both are iterative</li>
</ul>
</li>
<li><strong>List</strong><ul>
<li><code>append</code> <code>insert</code> <code>remove</code></li>
</ul>
</li>
<li><strong>Multi-dimention List</strong></li>
<li><strong>Dictionary</strong><ul>
<li><code>del(also can used for list)</code></li>
</ul>
</li>
<li><strong>Import</strong></li>
<li><strong>Continue &amp; Break</strong></li>
<li><strong>Error processing[Try/Except]</strong></li>
<li><p><strong>Zip</strong></p>
<ul>
<li>Output is an object<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">a = [1, 2, 3]</div><div class="line">b = [4, 5]</div><div class="line"># Convert to list</div><div class="line">list(zip(a, b))</div><div class="line"># Also we can use for loop to iterate each elements in object</div><div class="line">for i, j in zip(a,b)</div><div class="line"># Output of list(zip(a, b)) is: [(1, 4), (2, 5)]</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Lambda</strong><br>Example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def fun1(x, y):</div><div class="line">    return(x + y)</div><div class="line">fun2 = lambda x, y : x + y</div><div class="line"># fun1 is the same as fun2</div></pre></td></tr></table></figure>
</li>
<li><p><strong>Map</strong></p>
<ul>
<li>Output is an object<br>Example:<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def fun1(x, y):</div><div class="line">    return(x + y)</div><div class="line">list(map(fun1, [1, 2, 3], [4, 5]))</div><div class="line"># Output is: [5, 7]</div><div class="line"># Note: The output of fun1([1], [2]) is: [1, 2]</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Copy &amp; Deepcopy</strong></p>
<ul>
<li>python object share address(point)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># ********Copy********:</div><div class="line">a = [1, 2, 3]</div><div class="line">b = a</div><div class="line">b[0] = 11</div><div class="line">a = b = [11, 2, 3]</div><div class="line"># id(a) == id(b) is True</div><div class="line"></div><div class="line">import copy</div><div class="line">c = copy.copy(a)</div><div class="line"># id(a) == id(b) is False</div><div class="line"># Note:</div><div class="line">a = [1, 2, [3, 4]]</div><div class="line">d = copy.copy(a)</div><div class="line"># id(a) == id(d) is False</div><div class="line"># id(a[2]) == id(d[2]) is True</div><div class="line"># Because d[2] == a[2] are both object</div><div class="line"># Note2:</div><div class="line">a = 2</div><div class="line">b = a</div><div class="line">a = 3</div><div class="line"># b = 2 auto copy</div><div class="line"># ********Deepcopy ********:</div><div class="line">e = copy.deepcopy(a)</div><div class="line"># id(a[2]) == id(e[2]) is False</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="Multi-Thread"><a href="#Multi-Thread" class="headerlink" title="Multi-Thread"></a>Multi-Thread</h1><h2 id="Lead-to-Improve-Efficiency"><a href="#Lead-to-Improve-Efficiency" class="headerlink" title="Lead to Improve Efficiency"></a>Lead to Improve Efficiency</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">import threading</div><div class="line">import time</div><div class="line"># check the number of threads</div><div class="line">print(threading.active_count())</div><div class="line"># check all the details of threads </div><div class="line">print(threading.enumerate())</div><div class="line"># check which threads are working</div><div class="line">print(threading.current_thread())</div><div class="line"># ********Extend********:</div><div class="line">def thread_job():</div><div class="line">    print(&quot;MSG : This is a new Thread, number = %s\n&quot; % threading.current_thread())</div><div class="line">    for i in range(10):</div><div class="line">        time.sleep(0.1)</div><div class="line">    print(&quot;MSG : T1 Finished.\n&quot;)</div><div class="line">new_thread = threading.Thread(target = thread_job, Name = &apos;T1&apos;)</div><div class="line">def thread_job2():</div><div class="line">    print(&quot;MSG : T2 Start.\n&quot;)</div><div class="line">    print(&quot;MSG : T2 Finished.\n&quot;)</div><div class="line">new2_thread = threading.Thread(target = thread_job2, Name = &apos;T2&apos;)</div><div class="line">new_thread.start()</div><div class="line">new2_thread.start()</div><div class="line"># ********Join********:</div><div class="line"># print(&quot;MSG : Done.\n&quot;)</div><div class="line"># when we run the code &quot;Done&quot; will show before &quot;T2 Finished&quot; </div><div class="line">new2_thread.join()</div><div class="line">print(&quot;MSG : Done.\n&quot;)</div><div class="line"># T1 is slower than T2, so that &quot;Done&quot; will show before &quot;T1 Finished&quot;</div></pre></td></tr></table></figure>
<h2 id="Example-of-queue-using-in-thread"><a href="#Example-of-queue-using-in-thread" class="headerlink" title="Example of queue using in thread:"></a>Example of queue using in thread:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"># ********Queue********:</div><div class="line">import threading</div><div class="line">import time</div><div class="line">from queue import Queue</div><div class="line"></div><div class="line">def job(l, q):</div><div class="line">    for i in range(len(l)):</div><div class="line">        l[i] = l[i] ** 2</div><div class="line">        time.sleep(1)</div><div class="line">    # thread can not return value</div><div class="line">    # return l</div><div class="line">    q.put(l)</div><div class="line"></div><div class="line">def multithreading():</div><div class="line">    q = Queue()</div><div class="line">    threads = []</div><div class="line">    data = [[1,2,3], [4,5,6], [7,8,9]]</div><div class="line">    for i in range(3):</div><div class="line">        t = threading.Thread(target = job, args = (data[i], q))</div><div class="line">        t.start()</div><div class="line">        print(&quot;MSG : Number of thread is %s&quot; % threading.active_count())</div><div class="line">        threads.append(t)</div><div class="line">    [t.join() for t in threads]</div><div class="line">    results = []</div><div class="line">    for _ in range(3):</div><div class="line">        results.append(q.get())</div><div class="line">    print(results)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multithreading()</div></pre></td></tr></table></figure>
<h2 id="Global-Interpreter-lock-GIL"><a href="#Global-Interpreter-lock-GIL" class="headerlink" title="Global Interpreter lock(GIL):"></a>Global Interpreter lock(GIL):</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"># ********GIL********:</div><div class="line"># GIL shows that only one calculation unit can be run at a time</div><div class="line"># Therefore, for example, the efficiency of 4-threading is not equal to normal&apos;s * 4</div><div class="line">import threading</div><div class="line">from queue import Queue</div><div class="line">import copy</div><div class="line">import time</div><div class="line"></div><div class="line">def job(l, q):</div><div class="line">    result = sum(l)</div><div class="line">    q.put(result)</div><div class="line"></div><div class="line">def multi(l):</div><div class="line">    q = Queue()</div><div class="line">    threads = []</div><div class="line">    for i in range(4):</div><div class="line">        t = threading.Thread(target = job, args = (copy.copy(l), q), name = &apos;T%i&apos; % i)</div><div class="line">        t.start()</div><div class="line">        threads.append(t)</div><div class="line">    [t.join() for t in threads]</div><div class="line">    total = 0</div><div class="line">    for _ in range(4):</div><div class="line">        total += q.get()</div><div class="line">    print(total)</div><div class="line">    </div><div class="line">def normal(l):</div><div class="line">    total = sum(l)</div><div class="line">    print(total)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    l = list(range(1000000))</div><div class="line">    current_time = time.time()</div><div class="line">    normal(l*4)</div><div class="line">    print(&apos;MSG : normal time: &apos;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multi(l)</div><div class="line">    print(&apos;MSG : multithreading time: &apos;, time.time() - current_time)</div></pre></td></tr></table></figure>
<h2 id="Lock-example-Squential-operation-multi-thread"><a href="#Lock-example-Squential-operation-multi-thread" class="headerlink" title="Lock example(Squential operation multi-thread)"></a>Lock example(Squential operation multi-thread)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"># ********Lock********:</div><div class="line">imort threading</div><div class="line"></div><div class="line">def job1():</div><div class="line">    global A, lock</div><div class="line">    lock.acquire()</div><div class="line">    for i in range(10):</div><div class="line">        A += 1</div><div class="line">        print(&apos;MSG : job1 &apos;, A)</div><div class="line">    lock.release()</div><div class="line">    </div><div class="line">def job2():</div><div class="line">    global A, lock</div><div class="line">    lock.acquire()</div><div class="line">    for i in range(10):</div><div class="line">        A += 10</div><div class="line">        print(&apos;MSG : job2 &apos;, A)</div><div class="line">    lock.release()</div><div class="line">        </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    lock = threading.Lock()</div><div class="line">    A = 0</div><div class="line">    t1 = threading.Thread(target = job1)</div><div class="line">    t2 = threading.Thread(target = job2)</div><div class="line">    t1.start()</div><div class="line">    t2.start()</div><div class="line">    t1.join()</div><div class="line">    t2.join()</div></pre></td></tr></table></figure>
<h1 id="Multiprocessing"><a href="#Multiprocessing" class="headerlink" title="Multiprocessing"></a>Multiprocessing</h1><h2 id="Create-a-process"><a href="#Create-a-process" class="headerlink" title="Create a process"></a>Create a process</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># ********Extend********:</div><div class="line">import multiprocessing as mp</div><div class="line">import threading as td</div><div class="line"></div><div class="line">def job(a, b):</div><div class="line">    print(a + b)</div><div class="line"></div><div class="line"># processing must run in __main__</div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    new_process = mp.Process(target = job, args = (1, 2))</div><div class="line">    new_process.start()</div><div class="line">    new_process.join()</div></pre></td></tr></table></figure>
<h2 id="Example-of-queue-using-in-processing"><a href="#Example-of-queue-using-in-processing" class="headerlink" title="Example of queue using in processing:"></a>Example of queue using in processing:</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># ********Queue********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">def job(q):</div><div class="line">    result = 0</div><div class="line">    for i in range(1000):</div><div class="line">        result += i + i ** 2 + i ** 3</div><div class="line">    # return (result)</div><div class="line">    q.put(result)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    q = mp.Queue()</div><div class="line">    # Don&apos;t forget the &apos;,&apos; after args while the number of parameter is one</div><div class="line">    p1 = mp.Process(target = job, args = (q, ))</div><div class="line">    p2 = mp.Process(target = job, args = (q, ))</div><div class="line">    p1.start()</div><div class="line">    p2.start()</div><div class="line">    p1.join()</div><div class="line">    p2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(result1 + result2)</div></pre></td></tr></table></figure>
<h2 id="Efficiency-Comparison-normal-multithreading-multiprocessing"><a href="#Efficiency-Comparison-normal-multithreading-multiprocessing" class="headerlink" title="Efficiency Comparison(normal, multithreading, multiprocessing)"></a>Efficiency Comparison(normal, multithreading, multiprocessing)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"># ********Efficiency Comparison********:</div><div class="line">import multiprocessing as mp</div><div class="line">import threading as td</div><div class="line">from queue import Queue</div><div class="line">import time</div><div class="line"></div><div class="line">def job(q):</div><div class="line">    result = 0</div><div class="line">    for i in range(100000):</div><div class="line">        result += i + i ** 2 + i ** 3</div><div class="line">    # return (result)</div><div class="line">    q.put(result)</div><div class="line">    </div><div class="line">def normal():</div><div class="line">    result = 0</div><div class="line">    for _ in range(2):</div><div class="line">        for i in range(100000):</div><div class="line">            result += i + i ** 2 + i ** 3</div><div class="line">    print(&apos;MSG : normal &apos;, result)</div><div class="line">    </div><div class="line">def multiprocess():</div><div class="line">    q = mp.Queue()</div><div class="line">    p1 = mp.Process(target = job, args = (q, ))</div><div class="line">    p2 = mp.Process(target = job, args = (q, ))</div><div class="line">    p1.start()</div><div class="line">    p1.join()</div><div class="line">    p2.start()</div><div class="line">    p2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(&quot;MSG : Processing &quot;, result1 + result2)</div><div class="line">    </div><div class="line">def multithread():</div><div class="line">    q = Queue()</div><div class="line">    t1 = td.Thread(target = job, args = (q, ))</div><div class="line">    t2 = td.Thread(target = job, args = (q, ))</div><div class="line">    t1.start()</div><div class="line">    t2.start()</div><div class="line">    t1.join()</div><div class="line">    t2.join()</div><div class="line">    result1 = q.get()</div><div class="line">    result2 = q.get()</div><div class="line">    print(&quot;MSG : Threading &quot;, result1 + result2)</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    current_time = time.time()</div><div class="line">    normal()</div><div class="line">    print(&quot;MSG : normal time: &quot;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multithread()</div><div class="line">    print(&quot;MSG : multithread time: &quot;, time.time() - current_time)</div><div class="line">    current_time = time.time()</div><div class="line">    multiprocess()</div><div class="line">    print(&quot;MSG : multiprocess time: &quot;, time.time() - current_time )</div></pre></td></tr></table></figure>
<h2 id="Processing-Pool"><a href="#Processing-Pool" class="headerlink" title="Processing Pool"></a>Processing Pool</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"># ********Pool********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">def job(x):</div><div class="line">    return x * x</div><div class="line"></div><div class="line">def multiprocess():</div><div class="line">    pool = mp.Pool(processes = 3)</div><div class="line">    # type = &apos;list&apos;</div><div class="line">    result = pool.map(job, range(10))</div><div class="line">    print(result)</div><div class="line">    # type = &apos;int&apos; </div><div class="line">    result = pool.apply_async(job, (2, ))</div><div class="line">    print(result.get())</div><div class="line">    # Note: pool.apply_async can only input one number for iterating</div><div class="line">    # type = &apos;object&apos;</div><div class="line">    multi_result = [pool.apply_async(job,(i, )) for i in range(10)]</div><div class="line">    print([result.get() for result in multi_result])</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multiprocess()</div></pre></td></tr></table></figure>
<h2 id="Shared-memory"><a href="#Shared-memory" class="headerlink" title="Shared memory"></a>Shared memory</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># ********Shared memory********:</div><div class="line">import multiprocessing as mp</div><div class="line"></div><div class="line">value = mp.Value(&apos;d&apos;, 1)</div><div class="line"># can be only one dimension</div><div class="line">array = mp.Array(&apos;i&apos;, [1,2,3])</div><div class="line"># Value and Array can be share among multiple cores</div></pre></td></tr></table></figure>
<h2 id="Lock-example-avoid-different-cores-processing-out-of-order-with-shared-variable"><a href="#Lock-example-avoid-different-cores-processing-out-of-order-with-shared-variable" class="headerlink" title="Lock example(avoid different cores processing out of order with shared variable)"></a>Lock example(avoid different cores processing out of order with shared variable)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># ********Lock********:</div><div class="line">import multiprocessing as mp</div><div class="line">import time</div><div class="line"></div><div class="line">def job(v, num, l):</div><div class="line">    l.acquire()</div><div class="line">    for _ in range(10):</div><div class="line">        time.sleep(0.1)</div><div class="line">        v.value += num</div><div class="line">        print(v.value)</div><div class="line">    l.release()</div><div class="line"></div><div class="line">def multiprocess():</div><div class="line">    l = mp.Lock()</div><div class="line">    v = mp.Value(&apos;i&apos;, 0)</div><div class="line">    p1 = mp.Process(target = job, args = (v, 1, l))</div><div class="line">    p2 = mp.Process(target = job, args = (v, 3, l))</div><div class="line">    p1.start()</div><div class="line">    p2.start()</div><div class="line">    p1.join()</div><div class="line">    p2.join()</div><div class="line">    </div><div class="line">if __name__ == &apos;__main__&apos;:</div><div class="line">    multiprocess()</div></pre></td></tr></table></figure>
<h1 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h1><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><h3 id="Numpy-Foundation"><a href="#Numpy-Foundation" class="headerlink" title="Numpy Foundation"></a>Numpy Foundation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Foundation********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">array = np.array([[1,2,3],[2,3,4]])</div><div class="line">print(array)</div><div class="line">print(&quot;MSG : number of dims= &quot;, array.ndim)</div><div class="line"># If only have one dimension, shape will be (num, ) which represent it can be iterated</div><div class="line">print(&quot;MSG : shape= &quot;, array.shape)</div><div class="line">print(&quot;MSG : size= &quot;, array.size)</div></pre></td></tr></table></figure>
<h3 id="Numpy-Array"><a href="#Numpy-Array" class="headerlink" title="Numpy Array"></a>Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.array([[2,3,4], [5,6,7]], dtype = np.int)</div><div class="line">print(a.dtype)</div><div class="line"></div><div class="line">b = np.zeros((3, 4), dtype = np.int32)</div><div class="line">print(b)</div><div class="line"></div><div class="line">c = np.ones((3, 4), dtype = np.int32)</div><div class="line">print(c)</div><div class="line"></div><div class="line"># The output is a list of numbers that are approximate to zero </div><div class="line">d = np.empty((3, 4), dtype = np.int32)</div><div class="line">print(d)</div><div class="line"></div><div class="line">e = np.arange(10, 20, 2)</div><div class="line">f = np.arange(12).reshape((3,4))</div><div class="line">print(e)</div><div class="line">print(f)</div><div class="line"></div><div class="line">g = np.linspace(1, 10, 20)</div><div class="line">print(g)</div></pre></td></tr></table></figure>
<h3 id="Some-Useful-Numpy-Calculation-Formula"><a href="#Some-Useful-Numpy-Calculation-Formula" class="headerlink" title="Some Useful Numpy Calculation Formula"></a>Some Useful Numpy Calculation Formula</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Calculation********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.array([10, 20, 30, 40])</div><div class="line">b = np.arange(4)</div><div class="line">c = a - b</div><div class="line"># Output list composed of int numbers</div><div class="line">print(c)</div><div class="line"># Output list composed of boolean elements</div><div class="line">print(b &lt; 3)</div><div class="line">np.dot(a, b)</div><div class="line">rd = np.arange(2, 6)</div><div class="line"># Output has 2 dimensions(0 -&gt; col; 1 -&gt; row)</div><div class="line">np.sum(rd, axis = 1)</div><div class="line">np.min(rd, axis = 0)</div><div class="line">np.max(rd)</div><div class="line">np.argmin(rd)</div><div class="line">np.mean(rd)</div><div class="line">np.average(rd)</div><div class="line">np.median(rd)</div><div class="line"># Output is [2, 5, 9, 14]</div><div class="line">np.cumsum(rd)</div><div class="line"># Output is [1, 1, 1]</div><div class="line">np.diff(rd)</div><div class="line"># Output composed of multi-dimensional array representing  the row and col number of all nonzero elements in rd array respectively</div><div class="line">np.nonzero(rd)</div><div class="line"># sort among each dimensions independent</div><div class="line">np.sort(rd)</div><div class="line">np.sort(rd.reshape((2, 2)))</div><div class="line"># transpose also we can use rd.T to transpose directly</div><div class="line">np.transpose(rd)</div><div class="line"># matrix multiplication</div><div class="line">(rd.T).dot(rd)</div><div class="line">np.clip(rd, 2, 4)</div><div class="line"># Note: we can use axis to choose 0 -&gt; col or 1 -&gt; row as the target for calculation</div></pre></td></tr></table></figure>
<h3 id="Search-From-Numpy-Array"><a href="#Search-From-Numpy-Array" class="headerlink" title="Search From Numpy Array"></a>Search From Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Index Search********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.arange(3, 15).reshape((3, 4))</div><div class="line">A[2] # Output is [11, 12, 13, 14]</div><div class="line">A[2][1] </div><div class="line"># the same as</div><div class="line">A[1, 2]</div><div class="line">A[:, 1]</div><div class="line">A[1, 1:2]</div><div class="line">for row in A:</div><div class="line">    print(row)</div><div class="line"># Trick</div><div class="line">for colume in A.T:</div><div class="line">    print(colume)</div><div class="line"># flat function parse elements from A like a generator</div><div class="line"># Note: A.flat is different from A.flatten()</div><div class="line"># pre-one is an object and the next output a list</div><div class="line">for item in A.flat:</div><div class="line">    print(item)</div></pre></td></tr></table></figure>
<h3 id="Merge-Numpy-Array"><a href="#Merge-Numpy-Array" class="headerlink" title="Merge Numpy Array"></a>Merge Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># ********Merge Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.array([1, 1, 1])</div><div class="line">B = np.array([2, 2, 2])</div><div class="line"># vertical stack with output [[1, 1, 1], [2, 2, 2]]</div><div class="line">C = np.vstack((A, B))</div><div class="line">print(A.shape, C.shape)</div><div class="line"># Horizontal stack with with output [1, 1, 1, 2, 2, 2]</div><div class="line">D = np.hstack((A, B))</div><div class="line"># Note: transpose function can not convert shape(3,) into shape(,3)</div><div class="line">A_ = A[:, np.newaxis]) # newaxis is an extend dimension</div><div class="line"># If we want to get output by merge col-values like [[1, 2], [1, 2], [1, 2]] we can use:</div><div class="line">E = np.hstack((A[:, np.newaxis], B[:, np.newaxis]))</div><div class="line"># the same as:</div><div class="line">F = np.concatenate((A_, A_), axis = 1)</div><div class="line"># Note: np.concatenate((A, B), axis = 1) will shuffle an error because concatenate will reduce dimension when mergement operation happened, and A or B only have one dimension</div></pre></td></tr></table></figure>
<h3 id="Split-Numpy-Array"><a href="#Split-Numpy-Array" class="headerlink" title="Split Numpy Array"></a>Split Numpy Array</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Split Numpy Array********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">A = np.arange(12).reshape((3, 4))</div><div class="line"># every pieces should have the same length</div><div class="line">np.split(A, 2, axis = 1)</div><div class="line"># If you want to split into pieces that in different size</div><div class="line"># Binary split from left to right</div><div class="line">np.array_split(A, 3, axis = 1)</div><div class="line"># Vertical split</div><div class="line">np.vsplit(A, 3)</div><div class="line"># Horizontal split</div><div class="line">np.hsplit(A, 2)</div></pre></td></tr></table></figure>
<h3 id="Numpy-Array-Copy"><a href="#Numpy-Array-Copy" class="headerlink" title="Numpy Array Copy"></a>Numpy Array Copy</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># ********Numpy Array Copy********:</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">a = np.arange(4, dtype = np.float32)</div><div class="line">b = a</div><div class="line">c = a</div><div class="line">d = b</div><div class="line">a[0] = 0.3</div><div class="line"># now a = b = c = d = [0.30000001, 1., 2., 3.]</div><div class="line">b is a # result is True</div><div class="line"># Note: copy object connected with point</div><div class="line">b = a.copy() # deep copy</div><div class="line"># or</div><div class="line">import copy</div><div class="line">b = copy.copy(a)</div><div class="line">a is b # result is False</div></pre></td></tr></table></figure>
<h2 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h2><h3 id="Pandas-Foundation"><a href="#Pandas-Foundation" class="headerlink" title="Pandas Foundation"></a>Pandas Foundation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Data Representation********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">s = pd.Series([1, 3, 6, np.nan, 44, 1])</div><div class="line">dates = pd.date_range(&apos;20170101&apos;, periods = 6)</div><div class="line">df = pd.DataFrame(np.random.randn(6, 4), index = dates, columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df1 = pd.DataFrame(np.arange(12).reshape((3, 4)))</div><div class="line">df2 = pd.DataFrame(&#123;&apos;A&apos;: 1., &apos;B&apos;: pd.Timestamp(&apos;20130102&apos;), &apos;C&apos;: pd.Series(1, index = list(range(4)), dtype = &apos;float32&apos;), &apos;D&apos;: np.array([3] * 4, dtype = &apos;int32&apos;), &apos;E&apos;: pd.Categorical([&apos;test&apos;, &apos;train&apos;, &apos;test&apos;, &apos;train&apos;]), &apos;F&apos;: &apos;foo&apos;&#125;)</div><div class="line">print(df2.dtypes)</div><div class="line">print(df2.index)</div><div class="line">print(df2.columns)</div><div class="line">print(df2.values)</div><div class="line"># Only fit to number elements</div><div class="line">print(df2.describe()) # result index includes count, mean, std, min, 25%, 50%, 75%, max...</div><div class="line">print(df2.T)</div><div class="line"># Sort for columns</div><div class="line">print(df2.sort_index(axis = 1, ascending = False))</div><div class="line"># Sort for column values</div><div class="line">print(df2.sort_values(by = &apos;E&apos;))</div></pre></td></tr></table></figure>
<h3 id="Pandas-Data-Sampling"><a href="#Pandas-Data-Sampling" class="headerlink" title="Pandas Data Sampling"></a>Pandas Data Sampling</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># ********Data Sampling********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">print(df[&apos;A&apos;]) </div><div class="line"># the same as :</div><div class="line">print(df.A)</div><div class="line">print(df[0: 3], &apos;\n&apos;, df[&apos;20130101&apos;: &apos;20130103&apos;])</div><div class="line"># select by label:</div><div class="line">print(df.loc[&apos;20130102&apos;])</div><div class="line">print(df.loc[&apos;20130102&apos;, [&apos;A&apos;, &apos;B&apos;]])</div><div class="line"># select by position:</div><div class="line">print(df.iloc[3, 1])</div><div class="line">print(df.iloc[[1, 3, 5], 1: 3])</div><div class="line"># mixed selection:</div><div class="line">print(df.ix[:3, [&apos;A&apos;, &apos;C&apos;]])</div><div class="line"># Boolean indexing selection:</div><div class="line">print(df[df.A &gt; 8])</div><div class="line"># multi-conditions(Can not use &apos;and&apos;):</div><div class="line">print(df[df[2] &gt; 3][df[1] &lt; 2])</div></pre></td></tr></table></figure>
<h3 id="Pandas-Value-Config"><a href="#Pandas-Value-Config" class="headerlink" title="Pandas Value Config"></a>Pandas Value Config</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># ********Pandas change value********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">df.iloc[2, 2] = 1111</div><div class="line">df.loc[&apos;20130101&apos;, &apos;B&apos;] = 2222</div><div class="line">df[df[&apos;A&apos;] &gt; 0] = 0</div><div class="line"># add a new column</div><div class="line">df[&apos;F&apos;] = np.nan</div><div class="line">df[&apos;E&apos;] = pd.Series(np.arange(6, dtype = np.int32)+1, index = pd.date_range(&apos;20130101&apos;, periods = 6))</div></pre></td></tr></table></figure>
<h3 id="Pandas-Handling-Nan"><a href="#Pandas-Handling-Nan" class="headerlink" title="Pandas Handling Nan"></a>Pandas Handling Nan</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Pandas NaN********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line">df = pd.DataFrame(np.arange(24).reshape((6, 4)), index = pd.date_range(&apos;20130101&apos;, periods = 6), columns = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;])</div><div class="line">df.iloc[0, 1] = np.nan</div><div class="line">df.iloc[1, 2] = np.nan</div><div class="line"># &apos;any&apos; means we drop the row as long as nan exist, &apos;all&apos; means we drop the row if all the elements are nan</div><div class="line">print(df.dropna(axis = 0, how = &apos;any&apos;)) # how = &#123;&apos;any&apos;, &apos;all&apos;&#125;</div><div class="line">print(df.drop(&apos;A&apos;, axis = 1))</div><div class="line"># replace nan</div><div class="line">print(df.fillna(value = 0))</div><div class="line">print(df.isnull()) # result is a dictionary with &apos;True&apos; and &apos;False&apos;</div><div class="line">print(np.any(df.isnull()) == True)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Read-and-Write"><a href="#Pandas-Read-and-Write" class="headerlink" title="Pandas Read and Write"></a>Pandas Read and Write</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Read and Write********:</div><div class="line">import pandas as dp</div><div class="line"></div><div class="line"># Some useful function like: read_csv, read_excel, read_sql, read_json ...</div><div class="line"></div><div class="line">df = pd.read_csv(&apos;Sample.csv&apos;, &apos;r&apos;)</div><div class="line"># Sample.csv</div><div class="line"># A,B,C,D</div><div class="line"># 0,1,2,3</div><div class="line"># 4,5,6,7</div><div class="line"># 8,9,10,11</div><div class="line"></div><div class="line"># Save as pickle file</div><div class="line">df.to_pickle(&apos;Sample.pickle&apos;)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Concatenating"><a href="#Pandas-Concatenating" class="headerlink" title="Pandas Concatenating"></a>Pandas Concatenating</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Concatenating********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">df1 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df2 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df3 = pd.DataFrame(np.ones((3, 4))*2, columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line"># ignore_index will reset the index from top to bottom</div><div class="line">result1 = pd.concat([df1, df2, df3], axis = 0, ignore_index = True)</div><div class="line"></div><div class="line"># concat-join, [&apos;inner&apos;, &apos;outer&apos;]</div><div class="line">df4 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;], index = [1, 2, 3])</div><div class="line">df5 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], index = [2, 3, 4])</div><div class="line"># use NaN as the default value</div><div class="line">result2 = pd.concat([df4, df5], ignore_index = True, join = &apos;inner&apos;) # &apos;inner&apos; only remain the same parts</div><div class="line"></div><div class="line"># concat-join_axes</div><div class="line">result3 = pd.concat([df4, df5], axis = 1, join_axes = [df4.index]) # result&apos;s index is only the index of df4</div><div class="line"></div><div class="line"># append</div><div class="line">df6 = pd.DataFrame(np.zeros((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df7 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">df8 = pd.DataFrame(np.ones((3, 4)), columns = [&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], index = [2, 3, 4])</div><div class="line">result4 = df6.append(df7, ignore_index = True)</div><div class="line">result5 = df6.append([df7, df8])</div><div class="line">s1 = pd.Series([1, 2, 3, 4], index = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])</div><div class="line">result6 = df6.append(s1, ignore_index = True)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Merge-concat-without-the-same-parts"><a href="#Pandas-Merge-concat-without-the-same-parts" class="headerlink" title="Pandas Merge(concat without the same parts)"></a>Pandas Merge(concat without the same parts)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Merge********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line"></div><div class="line"># merge by index named &apos;key&apos;(may be used in database)</div><div class="line">df1 = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;key&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;, &apos;K3&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;key&apos;) # we have to make sure these two frames contain the same index named &apos;key&apos;</div><div class="line"></div><div class="line"># consider two keys</div><div class="line">df1 = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K0&apos;, &apos;K1&apos;], &apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;, &apos;A3&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;, &apos;B3&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;key1&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;key2&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;, &apos;K0&apos;], &apos;C&apos;: [&apos;C0&apos;, &apos;C1&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D1&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;)</div><div class="line"># default join = &apos;inner&apos;</div><div class="line">result = pd.merge(df1, df2, on = [&apos;key1&apos;, &apos;key2&apos;])</div><div class="line">result2 = pd.merge(df1, df2, on = [&apos;key1&apos;, &apos;key2&apos;], how = &apos;outer&apos;) # how = &#123;&apos;left&apos;, &apos;right&apos;, &apos;outer&apos;, &apos;inner&apos;&#125;</div><div class="line"></div><div class="line"># consider indicator(detail of merge)</div><div class="line">df1 = pd.DataFrame(&#123;&apos;col1&apos;: [0, 1], &apos;col_left&apos;: [&apos;a&apos;, &apos;b&apos;]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;col1&apos;: [1, 2, 2], &apos;col_right&apos;: [2, 2, 2]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;col1&apos;, how = &apos;outer&apos;, indicator = True)</div><div class="line">result1 = pd.merge(df1, df2, on = &apos;col1&apos;, how = &apos;outer&apos;, indicator = &apos;indicator_column&apos;) # rename &apos;indicator&apos;</div><div class="line"></div><div class="line"># merged by index</div><div class="line">df1 = pd.DataFrame(&#123;&apos;A&apos;: [&apos;A0&apos;, &apos;A1&apos;, &apos;A2&apos;], &apos;B&apos;: [&apos;B0&apos;, &apos;B1&apos;, &apos;B2&apos;]&#125;, index = [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;])</div><div class="line">df2 = pd.DataFrame(&#123;&apos;C&apos;: [&apos;C0&apos;, &apos;C2&apos;, &apos;C3&apos;], &apos;D&apos;: [&apos;D0&apos;, &apos;D2&apos;, &apos;D3&apos;]&#125;, index = [&apos;K0&apos;, &apos;K2&apos;, &apos;K3&apos;])</div><div class="line">result = pd.merge(df1, df2, left_index = True, right_index = True, how = &apos;outer&apos;)</div><div class="line">result1 = pd.merge(df1, df2, left_index = True, right_index = True, how = &apos;outer&apos;)</div><div class="line"></div><div class="line"># handle overlapping</div><div class="line">df1 = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K1&apos;, &apos;K2&apos;], &apos;age&apos;: [1, 2, 3]&#125;)</div><div class="line">df2 = pd.DataFrame(&#123;&apos;k&apos;: [&apos;K0&apos;, &apos;K0&apos;, &apos;K3&apos;], &apos;age&apos;: [4, 5, 6]&#125;)</div><div class="line">result = pd.merge(df1, df2, on = &apos;k&apos;, suffixes = [&apos;_boy&apos;, &apos;_girl&apos;], how = &apos;inner&apos;)</div></pre></td></tr></table></figure>
<h3 id="Pandas-Plot-View"><a href="#Pandas-Plot-View" class="headerlink" title="Pandas Plot(View)"></a>Pandas Plot(View)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"># ********Pandas Plot********:</div><div class="line">import pandas as dp</div><div class="line">import numpy as np</div><div class="line">import matplotlib.pyplot as plt</div><div class="line"></div><div class="line"># Series</div><div class="line">data = pd.Series(np.random.randn(1000), index = np.arange(1000))</div><div class="line">data = data.cumsum()</div><div class="line"># plt.plot(x = horizontal_value1, y = vertical_value)</div><div class="line">data.plot()</div><div class="line">plt.show()</div><div class="line"></div><div class="line"># DataFrame</div><div class="line">data = pd.DataFrame(np.random.randn(1000).reshape((250, 4)), index = np.arange(250), columns = list((&quot;ABCD&quot;)))</div><div class="line">data = data.cumsum()</div><div class="line">data.plot()</div><div class="line">plt.show()</div><div class="line"></div><div class="line"># scatter -&gt; plt.scatter(x = .., y = ..)</div><div class="line"># plot methods = &#123;&apos;bar&apos;, &apos;hist&apos;, &apos;box&apos;, &apos;kde&apos;, &apos;area&apos;, &apos;scatter&apos;, &apos;hexbin&apos;, &apos;pie&apos;&#125;</div><div class="line">a = data.plot.scatter(x = &apos;A&apos;, y = &apos;B&apos;, color = &apos;DarkBlue&apos;, label = &apos;Class 1&apos;) # only can hold 2 elements</div><div class="line">data.plot.scatter(x = &apos;A&apos;, y = &apos;C&apos;, color = &apos;DarkGreen&apos;, label = &apos;Class 2&apos;, ax = a)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><h2 id="Matplotlib-Foundation"><a href="#Matplotlib-Foundation" class="headerlink" title="Matplotlib Foundation"></a>Matplotlib Foundation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Foundation********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-1, 1, 50)</div><div class="line">y = x * 2 + 1</div><div class="line">plt.plot(x, y)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Figure"><a href="#Matplotlib-Figure" class="headerlink" title="Matplotlib Figure"></a>Matplotlib Figure</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Figure********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.plot(x, y1)</div><div class="line">plt.figure(num = 3, figsize = (8, 5))</div><div class="line">plt.plot(x, y1)</div><div class="line">plt.plot(x, y2, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Setting"><a href="#Matplotlib-Setting" class="headerlink" title="Matplotlib Setting"></a>Matplotlib Setting</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Setting********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.plot(x, y2)</div><div class="line">plt.plot(x, y1, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;)</div><div class="line">plt.xlim((-1, 2))</div><div class="line">plt.ylim((-2, 3))</div><div class="line">plt.xlabel(&apos;I am X&apos;)</div><div class="line">plt.ylabel(&apos;I am Y&apos;)</div><div class="line">new_ticks = np.linspace(-1, 2, 5) # steps</div><div class="line">plt.xticks(new_ticks)</div><div class="line">plt.yticks([-2, -1.8, 0, 1.22, 3], [r&apos;$really\ bad$&apos;, r&apos;$bad$&apos;, r&apos;$normal$&apos;, r&apos;$good$&apos;, r&apos;$really\ good$&apos;]) # alpha need write as &apos;\alpha&apos;</div><div class="line"></div><div class="line"># gca = &apos;get current axis&apos;</div><div class="line">ax = plt.gca()</div><div class="line">ax.spines[&apos;right&apos;].set_color(&apos;none&apos;) # right side of boundarys</div><div class="line">ax.spines[&apos;top&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.xaxis.set_ticks_position(&apos;bottom&apos;)</div><div class="line">ax.yaxis.set_ticks_position(&apos;left&apos;)</div><div class="line">ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;, 0)) # &apos;data&apos; can set to &apos;outward&apos; , &apos;axes&apos;... </div><div class="line">ax.spines[&apos;left&apos;].set_position((&apos;data&apos;, 0))</div><div class="line"></div><div class="line"># Legend</div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y1 = 2 * x + 1</div><div class="line">y2 = x ** 2</div><div class="line">plt.figure()</div><div class="line">plt.xlim((-1, 2))</div><div class="line">plt.ylim((-2, 3))</div><div class="line">plt.xlabel(&apos;I am X&apos;)</div><div class="line">plt.ylabel(&apos;I am Y&apos;)</div><div class="line">new_ticks = np.linspace(-1, 2, 5) # steps</div><div class="line">plt.xticks(new_ticks)</div><div class="line">plt.yticks([-2, -1.8, 0, 1.22, 3], [r&apos;$really\ bad$&apos;, r&apos;$bad$&apos;, r&apos;$normal$&apos;, r&apos;$good$&apos;, r&apos;$really\ good$&apos;]) # alpha need write as &apos;\alpha&apos;</div><div class="line">l1, = plt.plot(x, y2, label = &apos;up&apos;) # Don&apos;t forget &apos;,&apos;</div><div class="line">l2, = plt.plot(x, y1, color = &apos;red&apos;, linewidth = 1.0, linestyle = &apos;--&apos;, label = &apos;down&apos;)</div><div class="line">plt.legend(handles = [l1, l2], labels = [&apos;line 1&apos;, &apos;line 2&apos;], loc = &apos;best&apos;) # loc = &#123;&apos;best&apos;, &apos;upper&apos;, &apos;lower right&apos;, &apos;center&apos;...&#125;</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<h2 id="Matplotlib-Annotation"><a href="#Matplotlib-Annotation" class="headerlink" title="Matplotlib Annotation"></a>Matplotlib Annotation</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># ********Matplotlib Annotation********:</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">x = np.linspace(-3, 3, 50)</div><div class="line">y = 2 * x + 1</div><div class="line">plt.figure(num = 1, figsize = (8, 5))</div><div class="line">plt.plot(x, y)</div><div class="line">ax = plt.gca()</div><div class="line">ax.spines[&apos;right&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.spines[&apos;top&apos;].set_color(&apos;none&apos;)</div><div class="line">ax.xaxis.set_ticks_position(&apos;bottom&apos;)</div><div class="line">ax.spines[&apos;bottom&apos;].set_position((&apos;data&apos;, 0))</div><div class="line">ax.yaxis.set_ticks_position(&apos;left&apos;)</div><div class="line">ax.spines[&apos;left&apos;].set_position((&apos;data&apos;, 0))</div><div class="line"></div><div class="line">X0 = 1</div><div class="line">Y0 = 2 * X0 + 1</div><div class="line"># Point</div><div class="line">plt.scatter(X0, Y0, s = 50, color = &apos;b&apos;)</div><div class="line"># Line</div><div class="line">plt.plot([X0, X0], [Y0, 0], &apos;k--&apos;, lw = 2.5)</div><div class="line"># Choice one</div><div class="line">plt.annotate(r&apos;$2x+1=%s$&apos; % Y0, xy = (X0, Y0), xycoords = &apos;data&apos;, xytext = (+30, -30), textcoords = &apos;offset points&apos;, fontsize = 16, arrowprops = dict(arrowstyle = &apos;-&gt;&apos;, connectionstyle = &apos;arc3, rad = .2&apos;))</div><div class="line"># Choice two</div><div class="line">plt.text(-3.7, 3, r&apos;$This\ is\ some\ text.\ \mu\ \sigma_i\ \alpha_t$&apos;, fontdict = &#123;&apos;size&apos;: 16, &apos;color&apos;: &apos;r&apos;&#125;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Foundation-Summary&quot;&gt;&lt;a href=&quot;#Foundation-Summary&quot; class=&quot;headerlink&quot; title=&quot;Foundation Summary&quot;&gt;&lt;/a&gt;Foundation Summary&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Numpy" scheme="http://yoursite.com/tags/Numpy/"/>
    
      <category term="Pandas" scheme="http://yoursite.com/tags/Pandas/"/>
    
      <category term="Matplotlib" scheme="http://yoursite.com/tags/Matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>利用LSTM模型进行手写识别</title>
    <link href="http://yoursite.com/2017/07/25/RNN/"/>
    <id>http://yoursite.com/2017/07/25/RNN/</id>
    <published>2017-07-25T04:03:41.000Z</published>
    <updated>2017-08-04T06:55:59.054Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Recurrent-Neural-Netword-RNN-Using-Tensorflow"><a href="#Recurrent-Neural-Netword-RNN-Using-Tensorflow" class="headerlink" title="Recurrent Neural Netword(RNN) Using Tensorflow"></a>Recurrent Neural Netword(RNN) Using Tensorflow</h1><h1 id="Pre-processing"><a href="#Pre-processing" class="headerlink" title="Pre-processing"></a>Pre-processing</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>MNIST database of handwritten digits. <a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">Click here</a><br>Input data: Image shape(28*28)<br>Output label: 0~9 </p>
<h2 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h2><ul>
<li>Data_Size<ul>
<li><code>Input_dimension</code>: Dimension of each image</li>
<li><code>Output_dimension</code>: Dimension of predicted label</li>
<li><code>Classes</code>: The number of different outputs</li>
</ul>
</li>
<li>Model_Parameter<ul>
<li><code>Training_iter</code>: The number of iterations for training</li>
<li><code>Batch_size</code>: The length of inputeach epoch</li>
</ul>
</li>
</ul>
<h2 id="Requirement"><a href="#Requirement" class="headerlink" title="Requirement"></a>Requirement</h2><ul>
<li><code>Python 2.7</code></li>
<li><code>Tensorflow 0.12.1</code></li>
</ul>
<h1 id="Model-RNN-LSTM"><a href="#Model-RNN-LSTM" class="headerlink" title="Model(RNN + LSTM)"></a>Model(RNN + LSTM)</h1><p>We use a Recurrent Neural Network with <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">LSTM</a> Cell to implement this model.</p>
<ul>
<li>LSTM (Long Short Term Memory):</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="http://upload-images.jianshu.io/upload_images/42741-b9a16a53d58ca2b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="LSTM_MODEL" title="">
                </div>
                <div class="image-caption">LSTM_MODEL</div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://json0071.gitbooks.io/deeplearning/content/LSTM.png" alt="LSTM" title="">
                </div>
                <div class="image-caption">LSTM</div>
            </figure>
<p>LSTM Composed of three gates which called INPUT_GATE, FORGET_GATE and OUTPUT_GATE.</p>
<p>More information about how to implement LSTM Model is <a href="https://www.tensorflow.org/tutorials/recurrent" target="_blank" rel="external">here</a>.</p>
<ul>
<li><strong>Initialize Step</strong></li>
</ul>
<p>First we should initialize the placeholder and weights of our neural network.<br><code>placeholder</code>: just like the <strong>x</strong> of the function:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large f(x) = x^2" style="border:none;"></p>
<p><code>weights</code>: the weight for converting input data to output label.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(&quot;float&quot;, [None, n_steps, n_input])</div><div class="line">y = tf.placeholder(&quot;float&quot;, [None, n_classes])</div><div class="line"></div><div class="line">weights = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_hidden, n_classes]))</div><div class="line">&#125;</div><div class="line">biases = &#123;</div><div class="line">    &apos;out&apos;: tf.Variable(tf.random_normal([n_classes]))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><strong>Training Step</strong></li>
</ul>
<p><strong>First</strong> we define a RNN_Model function.<br>Using linear relationship to combine the output parameters.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def RNN_Model(x, weights, biases):</div><div class="line">    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias = 1.0)</div><div class="line">    output, states = tf.nn.rnn(lstm_cell, x, dtype = tf.float32)</div><div class="line">    return tf.matmul(output[-1], weights[&apos;out&apos;]) + biases[&apos;out&apos;]</div></pre></td></tr></table></figure>
<p><strong>Second</strong> we have to define the loss function and optmizer of our model.<br><code>loss fuction</code>: softmax_cross_entropy<br><code>optimizer</code>: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">prediction = RNN_Model(x, weights, biases)</div><div class="line">result = tf.nn.softmax(prediction)</div><div class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))</div><div class="line">optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)</div></pre></td></tr></table></figure>
<p><strong>Third</strong> in order to evaluate the efficiency of this model, we define the function to calculate accuracy.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> we can start training after all the initialization.</p>
<ul>
<li>We can use session to run our tensorflow function.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    sess.run(init)</div><div class="line">    while &quot;./epoch&quot; &lt; training_iters</div><div class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</div><div class="line">        batch_x = batch_x.reshape((batch_size, n_steps, n_input))</div><div class="line">        sess.run(optimizer, feed_dict = &#123;x: batch_x, y: batch_y&#125;</div><div class="line">        if &quot;./batch_size&quot;:</div><div class="line">            acc = sess.run(accuracy, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div><div class="line">            los = sess.run(loss, feed_dict = &#123;x: batch_x, y: batch_y&#125;)</div></pre></td></tr></table></figure>
<p><strong>Tips</strong>: “./“ represent the parameters defined by user own.</p>
<ul>
<li><strong>Testing Step</strong></li>
</ul>
<p>After training we get a weights in the tensorflow session which can be used to predict our test data.</p>
<p><strong>First</strong> generate the testing dataset from mnist generator.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">test_data = mnist.test.images[:&quot;./test_length&quot;].reshape(-1, n_steps, n_input)</div><div class="line">res = sess.run(result, feed_dict = &#123;x: test_data&#125;)</div><div class="line">predict_label = sess.run(tf.argmax(res, 1))</div></pre></td></tr></table></figure>
<p><strong>Finally</strong> because tensorflow mnist test dataset have its own ground-truth. So we can estimate if our “predict_label” is correct. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">test_label = mnist.test.labels[:&quot;./test_lenght&quot;]</div><div class="line">sess.run(accuracy, feed_dict = &#123;x: predict_label, y: test_label&#125;)</div></pre></td></tr></table></figure>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><ol>
<li><p>Install tensorflow.</p>
<ul>
<li>If we will run our model on GPU we have to install cuda and cuDNN.<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install tensorflow(-gpu)==0.12.1</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Import tensorflow package.</p>
</li>
<li>Import tensorflow mnist dataset and read the dataset as a generator.</li>
<li>Run our model<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python &quot;./model_name&quot;.py</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://github.com/aymericdamien/TensorFlow-Examples/" target="_blank" rel="external">Googel Tensorflow Example</a></li>
</ul>
<h1 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h1><p>In this experiment we use a simple RNN(LSTM) model to predict the handwritten digits which also catch a good consequence in CNN.<br>RNN model is good for using in NLP processing. But how to explore the most useful <strong>determines</strong> whether our model can get an excellent result or not.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot;&gt;&lt;a href=&quot;#Recurrent-Neural-Netword-RNN-Using-Tensorflow&quot; class=&quot;headerlink&quot; title=&quot;Re
    
    </summary>
    
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="LSTM" scheme="http://yoursite.com/tags/LSTM/"/>
    
      <category term="Tensorflow" scheme="http://yoursite.com/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04遠端桌面（remote desktop）設置</title>
    <link href="http://yoursite.com/2017/07/25/Remote/"/>
    <id>http://yoursite.com/2017/07/25/Remote/</id>
    <published>2017-07-25T04:00:24.000Z</published>
    <updated>2017-09-07T12:32:45.776Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Ubuntu上的遠端鏈接比起windows系統自帶的Remote Desktop需要配置的條件更多。網上也有許多不同的版本，本人嘗試之後發現了一些常見的問題，特在此總結可行的一般流程與常見問題的解決方式。</p>
<h1 id="System-Config"><a href="#System-Config" class="headerlink" title="System Config"></a>System Config</h1><p><code>Ubuntu16.04</code> <code>Windows 10</code></p>
<h1 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h1><p>1、如果需要從Ubuntu連接到Windows系統，則可以安裝Desktop</p>
<ul>
<li>sudo apt-get install ubuntu-desktop</li>
</ul>
<p>2、若只是從Windows鏈接到Ubuntu則跳過第一步，直接安裝遠端桌面軟體xrdp</p>
<ul>
<li><p>sudo apt-get install xrdp</p>
<ul>
<li>此時若打開xrdp的配置文件，可以看到默認的xrdp協定，遠 端桌面則是根據這個來請求遠端服務的。</li>
</ul>
</li>
<li>sudo vim /etc/xrdp/xrdp.ini</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1tOoyic.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>其中port = -1表示默認port(5910)作為登錄的接口，之後的連接可通過這個port連入相同的session（因為遠端連接的port一般可以兼容port5900到5910）如果需要更改連接的port可以在xrdp.ini文檔中修改port為port = ask59XX來請求連接。</li>
</ul>
<p>修改完畢後記得重啟xrdp：</p>
<ul>
<li>sudo service xrdp restart</li>
</ul>
<p>3、此時可以查看service port看是否處於LISTEN的狀態。</p>
<ul>
<li>netstat -utl</li>
</ul>
<p><strong>Important : 必須確保三個port處於監聽狀態</strong></p>
<ul>
<li>port 3389</li>
<li>port 3350</li>
<li>port 59XX</li>
</ul>
<p><img src="https://i.imgur.com/0BgAP4w.png" alt=""></p>
<p>4、確保Ubuntu系統安裝了vnc服務，大部分系統會自行安裝，可以通過重複安裝確認。</p>
<ul>
<li>sudo apt-get install vnc4server<br>或</li>
<li>sudo apt-get install tightvncserver</li>
</ul>
<p>5、由於xrdp會開放3389的port作為遠端圖形化界面的窗口，因此還需要有相應的圖形化桌面套件。<br><strong>Ubuntu常用的桌面套件有三種，選擇一種安裝即可</strong></p>
<ul>
<li>安裝與設定Xfce<ul>
<li>sudo apt install xfce4</li>
<li>echo “xfce4-session” &gt; ~/.xsession </li>
</ul>
</li>
<li>安裝與設定Lxde<ul>
<li>sudo apt install lxde</li>
<li>echo “lxsession -s LXDE -e LXDE” &gt; ~/.xession </li>
</ul>
</li>
<li>安裝與設定Mate<ul>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/ppa</li>
<li>sudo apt-add-repository ppa:ubuntu-mate-dev/trusty-mate</li>
<li>sudo apt update</li>
<li>sudo apt install –no-install-recommends ubuntu-mate-core ubuntu-mate-desktop</li>
<li>echo “mate-session” &gt; ~/.xsession</li>
</ul>
</li>
</ul>
<p>6、之後就可以使用遠端桌面連接Windows和Ubuntu了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PBsp6Sc.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>结果如下（Mate）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a1PmzMs.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="Common-Problem"><a href="#Common-Problem" class="headerlink" title="Common Problem"></a>Common Problem</h2><ul>
<li>遠端連接出現error-problem connecting：<ul>
<li>通常是因為vnc服務沒有架好，查看port的監聽狀態（詳見步驟3），如果只有3389和3350沒有5910的情況，則需要手動開啟相應的port進行連接。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>vncserver : 1~9 (冒号兩邊都需要空格)</li>
<li>在xrdp設定檔中將prot從-1改為ask剛才開啟的port（vncserver設1則開啟5901以此類推）</li>
</ul>
</li>
<li>遠端桌面連接進入出現灰色網格，無圖像，滑鼠變成X：<ul>
<li>出現這種狀況通常是沒有安裝遠端桌面套件，導致圖形化界面無法呈現。</li>
</ul>
</li>
<li><strong>解決方法：</strong><ul>
<li>安裝三種遠端桌面套件的一種（詳見步驟5）</li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;Ubuntu上的遠端鏈接比起windows系統自帶的Remo
    
    </summary>
    
    
      <category term="Ubuntu" scheme="http://yoursite.com/tags/Ubuntu/"/>
    
      <category term="Remote Desktop" scheme="http://yoursite.com/tags/Remote-Desktop/"/>
    
      <category term="xrdp" scheme="http://yoursite.com/tags/xrdp/"/>
    
  </entry>
  
  <entry>
    <title>Python字符編碼問題</title>
    <link href="http://yoursite.com/2017/07/25/Unicode/"/>
    <id>http://yoursite.com/2017/07/25/Unicode/</id>
    <published>2017-07-25T03:52:58.000Z</published>
    <updated>2017-08-04T07:04:41.769Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是编码"><a href="#什么是编码" class="headerlink" title="什么是编码"></a>什么是编码</h1><p>字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編程語言中，我們經常會處理文本編碼之間的轉化問題，因為文本可能存在不同的編碼格式，例如 ASCII、GBK、UTF-8等等。最近在做NN的過程中面臨Corpus的unicode編碼問題，因此需要弄清楚python不同版本對編碼問題的處理策略。</p>
<h2 id="字符的抽象概念"><a href="#字符的抽象概念" class="headerlink" title="字符的抽象概念"></a>字符的抽象概念</h2><p>看了一些網絡上的介紹，發現我們所謂的字符表示文本中單一的一個符號。然而一個字符不是一個字節，例如 “中” 這個字在文本中是一個基礎字符，但是在計算機中卻不是一個字節。一個字符有許多表示方法，不同的表示方法會使用不同的字節數，這就是所謂的編碼。<strong>字符就是文本中的最小單元</strong>。</p>
<h2 id="編碼的方式"><a href="#編碼的方式" class="headerlink" title="編碼的方式"></a>編碼的方式</h2><p>Unicode是一種編碼規範，用來統一表示世界上的各種語言。其作為Python語言中的一種中間轉換碼，如果要對不同編碼格式的文本進行轉換，就必須對字符串解碼（decode）成Unicode，再從Unicode編碼（encode）成另一種編碼格式：</p>
<p><code>decode</code> : 作用是將編碼的字符串轉換成Unicode。<br><code>encode</code> : 作用是將Unicode傳換成其他編碼格式。</p>
<h1 id="Python2-vs-Python3"><a href="#Python2-vs-Python3" class="headerlink" title="Python2 vs Python3"></a>Python2 vs Python3</h1><p>Python3的編碼形式默認為Unicode</p>
<ul>
<li>那麼Python3的文本可以通過encode傳換成bytes嗎？bytes和str一樣嗎？</li>
</ul>
<p>首先bytes不是字符串，那么b ‘a’ 和 ‘a’ 的区别是什么呢？在Python3运行输入出bytes的时候，它采取的原则是这样的：没读一个字节就和ascii码比对一下，如果符合ascii码的字符（特殊字符，字母和数字等除外），那这个字节就按照ascii码来表示，否则就按照十六进制‘\x’的形式来表示。</p>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ctGhV9P.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
<p>因此bytes对象不能由超过0到127的ascii码范围的unicode字<br>符串表示。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8ou3vVE.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>bytes的表示方式为b + (字符串)，如果不用bytes表示，则直接用 ‘\x’ + 两位十六进制数表示一个字节。</p>
<ul>
<li>那么在Python2表示unicode的时候我们使用u + (字符串)的形式表示unicode编码，而Python3中则无需这么做。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2ji3C8E.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y2rtdQM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>注意在Python3中u‘字符串’和‘\u四位十六进制数’是等价的，而且都为str对象。而‘\u四位十六进制数’和‘\u四位十六进制数’却不相同。</li>
</ul>
<p>结果就如同图中所示 ： <figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RZD8Ptn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是编码&quot;&gt;&lt;a href=&quot;#什么是编码&quot; class=&quot;headerlink&quot; title=&quot;什么是编码&quot;&gt;&lt;/a&gt;什么是编码&lt;/h1&gt;&lt;p&gt;字符串也是一種數據形態，但是比較特殊的是字符串本身也存在一個編碼的問題，就是如何讓計算機來表示相應的字符並存儲。在編
    
    </summary>
    
    
      <category term="Unicode" scheme="http://yoursite.com/tags/Unicode/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu16.04如何安裝搜狗（Sogou）輸入法</title>
    <link href="http://yoursite.com/2017/07/25/Ubuntu-sogo/"/>
    <id>http://yoursite.com/2017/07/25/Ubuntu-sogo/</id>
    <published>2017-07-25T03:48:07.000Z</published>
    <updated>2017-08-04T07:04:32.461Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>目前Ubuntu常用的中文输入法有：</p>
<ul>
<li>搜狗拼音： 搜狗出品的面向Linux的输入法。</li>
<li>Fcitx： 这个是Ubuntu系统自带的Linux开源的输入法框架，提供了包括Google PinYin、ShuangPin、SunPinYin、Hong Kong和TaiWan繁体等一系列输入法。</li>
</ul>
<p>下面主要讲下如何在Ubuntu 16.04上安装搜狗输入法。</p>
<h2 id="安裝過程"><a href="#安裝過程" class="headerlink" title="安裝過程"></a>安裝過程</h2><p>下載安裝檔之前首先需要確認本機的Ubuntu系統是什麼樣的編碼位元。利用“uname -a”指令查詢系統資訊。</p>
<p>下載安裝包，sogou提供了32位和64位版本:<a href="http://pinyin.sogou.com/linux/?r=pinyin" target="_blank" rel="external">http://pinyin.sogou.com/linux/?r=pinyin</a></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/G7PoJFF.png" alt="Sogou" title="">
                </div>
                <div class="image-caption">Sogou</div>
            </figure>
<p>下載完成后可以直接雙擊下載的deb包裝或執行指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo dpkg -i sogoupinyin*.deb</div><div class="line">$ sudo apt -f install</div></pre></td></tr></table></figure></p>
<ul>
<li><strong>第一行指令會提示sogou的一些鏈接錯誤，需用第二條指令解決。</strong></li>
</ul>
<p>安裝完成之後重啟系統。</p>
<p>再次開啟系統后就能夠在輸入法設置菜單看到Sogou的選項了。</p>
<ul>
<li><strong>Tips</strong>：有些版本會出現搜狗與Fcitx的衝突問題，但是本人沒有遇到這個問題，但是仍然提供一個評價最佳的解決策略：(移除其中一種輸入法架構)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo apt remove fcitx*</div><div class="line">$ sudo apt autoremove</div></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;目前Ubuntu常用的中文输入法有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;搜狗拼音： 搜狗出品的面向Linux的输入法。&lt;/li&gt;
&lt;li&gt;Fcitx
    
    </summary>
    
    
      <category term="Linux" scheme="http://yoursite.com/tags/Linux/"/>
    
      <category term="Ubuntu 16.04" scheme="http://yoursite.com/tags/Ubuntu-16-04/"/>
    
      <category term="sogou输入法" scheme="http://yoursite.com/tags/sogou%E8%BE%93%E5%85%A5%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>机器学习（Machine Learning）简单学</title>
    <link href="http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/"/>
    <id>http://yoursite.com/2017/07/24/Machine-Learning-Tutorial/</id>
    <published>2017-07-24T05:48:31.000Z</published>
    <updated>2017-09-19T02:41:21.632Z</updated>
    
    <content type="html"><![CDATA[<p>本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了<a href="https://morvanzhou.github.io/tutorials/machine-learning/" target="_blank" rel="external">莫烦Python</a>的教学视频，发现其中的内容丰富有趣并且具有很好的阶层学习框架。于是总结了一些精髓并加入了自己从事机器学习研究所工作的一些见解，总结了一些精华的部分以供大家快速入门和学习。</p>
<h1 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h1><p>机器学习（Machine Learning）是由一帮计算机科学家们希望让计算机像人类一样思考而延伸出来的一门计算机理论。机器学习最早来自心理和生物科学，科学家们认为人和计算机其实没有什么差别，都是一大批相互连接的信息传递和存储元素所组成的系统。机器学习是一门典型的跨领域科学，其中包含了概率学、统计学等等方面。随着计算机性能的提升和计算机运算速度的升级，机器学习的应用才真正开始融入我们日常的生活当中。而不久的将来，机器学习必将成为人类探索机器世界的关键钥匙。<strong>总的来说</strong>，机器学习就是一个寻找方法的过程（Looking for a function）。我们所要做的就是构建一个function set（也就是model），其中的function结合起来<strong>能够真正将输入和输出拟合起来的function</strong>。</p>
<p><strong>以下的内容出自自己的理解，如有疑问欢迎留言探讨。</strong></p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>图像识别， AI对话式智慧型家居, 聊天机器人， 股市风险预测…</p>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>机器学习可以按照目的不同划分成几个不同功能的种类：</p>
<ul>
<li><code>Regression</code>: Output a scalar</li>
<li><code>Classification</code>: Output a class(one_hot vevtor)</li>
<li><code>Structured Learning/Prediction</code>: Output a sequence, a matrix, a graph, a tree…(Output is composed of <strong>components with dependency</strong>)</li>
</ul>
<p>在<strong>Structured Learning</strong>领域中，而这种机器学习方式的可靠指出在于它能够适应更加复杂的环境。对于<strong>One-shot、Zero-shot Learning</strong>的问题上，传统的机器学习分类模式讲究的是利用监督式学习的方法用大量例子来拟合网络结构。而Structured Learning除了能够拟合那些带有Label的数据外，还能够在输出范围较大的时候<strong>主动去尝试拟合</strong>那些模型从未处理过的数据类别。从而<strong>创造出全新的类别成员</strong>，因此该学习方式也要求模型的结构更加智能。</p>
<p>Structured Learning还有一个重要的问题需要克服，那就是要让模型自己学会如何<strong>安排数据流的模型</strong>（Learn how to planning）。机器学习模型能够自我生成一些新的数据样本，但是这些数据通常是依靠已知的记忆进行组合而成的。这就需要我们的模型能够<strong>考虑全局再做决定</strong>，避免因为 <strong>“盲人摸象”</strong> 的认知而做出错误的决定：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/kddTCBI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>图中就是一些模型因为只认知到局部而产生的错误理解所导致的结果。</li>
</ul>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>机器学习的实现方式多种多样，在程式语言中我们称之为算法。<br>Machine Learning的学习方式主要包括：</p>
<ul>
<li><strong>监督式学习（Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and Labels</li>
<li><strong>Principle</strong>: 通过让计算机学习这些label来标记相应的value，从中找出它认为重要的部分作为判断依据。（<strong>既定规律</strong>）</li>
<li><strong>Example</strong>: Logistic Regression、Back Propogation Neural Network</li>
</ul>
</li>
<li><strong>非监督式学习（Un-Supervised Learning）</strong><ul>
<li><strong>Input: Values</strong></li>
<li><strong>Principle</strong>: 只提供value的情况下，计算机事先无法得知value所代表的含义以及需要学习的正确结果，这时候就需要让计算机自己学会分类不同的value，从而总结出不同value背后所隐藏的重要规律作为判断依据。（<strong>生成规律</strong>）</li>
<li><strong>Example</strong>: Apriori、K-Means</li>
</ul>
</li>
<li><strong>半监督式学习（Semi-Supervised Learning）</strong><ul>
<li><strong>Input</strong>: Values and A few Labels</li>
<li><strong>Principle</strong>: 这种学习方式主要让计算机考虑如何利用少量的label总结出最适合value的判断规则，从而引申到更大范围的value中。</li>
<li><strong>Example</strong>: Laplacisn SVM、Graph Inference</li>
</ul>
</li>
<li><strong>强化学习（Reinforcement Learning）</strong><ul>
<li><strong>Input</strong>: Environment and Set of Operations</li>
<li><strong>Principle</strong>: 通过将计算机设定在一个复杂的环境中，让机器去随机尝试各种可能的操作，并通过环境的回馈（正确加分，不正确扣分）的方式让机器的行为向加分的方面靠近，最终适应环境。</li>
<li><strong>Example</strong>: Alpha GO、Robot Control</li>
</ul>
</li>
</ul>
<p>Machine Leaning的算法主要分为这几类：</p>
<ul>
<li><strong>回归算法（Regression）</strong><ul>
<li>该算法主要是试图通过对误差的衡量来探索变量之间的关系问题。常见的回归算法包括：<strong>最小二乘法（Ordinary Least Square）</strong>、<strong>逻辑回归（Logistic Regression）</strong>、<strong>逐步回归（Stepwise Regression）</strong>、<strong>多元自适应回归样条（Multivariate Adaptive Regression Splines）</strong> 和 <strong>本地散点平滑估计（Locally Estimated Scatterplot Smoothing）</strong> 等。</li>
<li>常用的<strong>情形</strong>有：信用评估、度量成功率、预测收入水平、预测地震发生几率等等。</li>
</ul>
</li>
<li><strong>基于实例的算法（Instance-Based Algorithm）</strong><ul>
<li>该算法常常用来对决策性问题建模，通常会选取一批样本数据，然后根据某些特性和新数据样本的比较，通过匹配度来找到最佳的匹配相性。因此可以理解为 <strong>“赢家通吃”</strong> 的贪婪（Greedy）学习方式。</li>
<li>常见的算法包括：<strong>K-Nearest Neighbor（KNN）</strong>、<strong>学习矢量量化（Learning Vector Quantization，LVQ）</strong> 以及 <strong>自组织映射算法（Self-Organizing Map，SOM）</strong>。</li>
</ul>
</li>
<li><strong>正则化方式（Regular Expression）</strong><ul>
<li>该算法是基于回归算法的延伸，根据算法的复杂度对其进行的调整。正则化方法会对简单模型基于奖励而对复杂模型算法基于惩罚（一个类似强化学习的概念）。</li>
<li>常见的算法包括：<strong>Ridge Regression</strong>、<strong>Least Absolute Shrinkage and Selection Operator（LASSO）</strong> 和 <strong>弹性网络（Elastic Net）</strong>。</li>
</ul>
</li>
<li><strong>决策树（Decision Tree）</strong><ul>
<li>该算法根据数据的属性采用树状的结构建立决策模型，常常被用来解决<strong>分类</strong>和<strong>回归</strong>问题。</li>
<li>常见的算法包括：<strong>分类及回归树（Classification And Regression Tree，CART）</strong>、<strong>Iterative Dichotomiser 3（ID3）</strong>、<strong>随机森林（Random Forest）</strong> 以及 <strong>梯度推进（Gradient Boosting Machine，GBM）</strong>。</li>
</ul>
</li>
<li><strong>贝叶斯（Bayesian）</strong><ul>
<li>该算法是基于贝叶斯定理的一类演算法，主要也是来解决<strong>分类</strong>和<strong>回归</strong>的问题。</li>
<li>常见的算法包括: <strong>朴素贝叶斯（Naive Bayesian）</strong>、<strong>平均单依赖评估（Averaged One-Dependence Estimators，AODE）</strong> 以及 <strong>Bayesian Belief Network（BBN）</strong>。</li>
<li>常用范例：垃圾邮件分类、文章分类、情绪分类、人脸识别等。</li>
</ul>
</li>
<li><strong>基于核的算法（Kernel-Based Algorithm）</strong><ul>
<li>该算法最著名的应该是支持向量机（SVM）了，其将输入数据映射到一个高阶的向量空间中，在这些高阶空间里，有些分类或者回归问题就能得到解决。</li>
<li>常见的算法包括：<strong>支持向量机（Support Vector Machine，SVM）</strong>、<strong>径向基函数（Radial Basis Function，RBF）</strong> 和 <strong>线性判别分析（Linear Discriminate Analysis）</strong>。</li>
</ul>
</li>
<li><strong>聚类算法（Clustering）</strong><ul>
<li>该算法和回归类似，就是在处理分类问题的时候，通常以中心点或者分层的方式输入数据进行归并。所以聚类算法目的是找到数据的内部结构，以便按照最大的共同特征进行归类。</li>
<li>常见的聚类算法包括：<strong>K-Means算法</strong> 以及 <strong>期望最大化算法（Expectation Maximization，EM）</strong>。</li>
<li>聚类的关注特征也分为好多种，包括：质心、连通性、密度、概率、维度以及神经网络结构等。</li>
</ul>
</li>
<li><strong>关联法则（Association Rule）</strong><ul>
<li>该算法通过寻找最能解释数据变量之间关系的规则，从而找出大量多元数据集中的有用关联法则。</li>
<li>常见的算法包括：<strong>Apriori算法</strong> 和 <strong>Eclat算法</strong>。</li>
</ul>
</li>
<li><strong>遗传算法（Genetic Algorithm）</strong><ul>
<li>源自进化理论，淘汰弱者，适者生存。通过不断更新和淘汰的机制去选择最优的设计模型。后诞生的模型会继承先带模型的参数，并能够根据环境自我优化或消失。</li>
</ul>
</li>
<li><strong>人工神经网络（Neural Network）</strong><ul>
<li>该算法主要是模拟生物神经网络，属于模型匹配算法的一种。通常用于解决<strong>分类</strong> 和 <strong>回归</strong>的问题。人工神经网络是机器学习的一个庞大分支，有几百种不同的算法结构（包括深度学习）。</li>
<li>重要的神经网络算法包括：<strong>感知神经网络（Perceptron Neural Network）</strong>、<strong>反向传递（Back Propagation）</strong>、<strong>自组织映射（Self-Organizing Map，SOM）</strong>等。</li>
</ul>
</li>
<li><strong>深度学习（Deep Learning）</strong><ul>
<li>深度学习算法是基于人工神经网络的延伸，通过建立更复杂的神经网络结构来提升神经网络的效果。很多深度学习的算法是半监督式学习算法，用来处理少量未label的数据集。</li>
<li>常见的深度学习算法包括：<strong>受限波尔兹曼机（Restricted Boltzmann Machine，RBN）</strong>、<strong>Deep Belief Networks（DBN）</strong>、<strong>卷积网络（Convolutional Network）</strong> 和 <strong>堆栈式自动编码器（Stacked Auto-encoders）</strong>。</li>
</ul>
</li>
<li><strong>降低维度算法（Reduce Dimension）</strong><ul>
<li>与聚类相似，降低纬度算法也是试图分析数据内部的结构，不过该算法属于非监督学习的方式，在缺乏信息的情况下归纳或解释数据。这类算法利用高维度的数据作为监督的label使用，从而完成迁移的降维动作。</li>
<li>常见的算法包括：<strong>主成分分析（Principle Component Analysis，PCA）</strong>、<strong>偏最小二乘回归（Partial Least Square Regression，PLS）</strong> 和 <strong>投影追踪（Projection Pursuit）</strong>等。</li>
</ul>
</li>
</ul>
<h1 id="十大常见机器学习算法"><a href="#十大常见机器学习算法" class="headerlink" title="十大常见机器学习算法"></a>十大常见机器学习算法</h1><p>常用的机器学习算法，几乎可以用在所有的数据问题上：</p>
<h2 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h2><p>线性回归通常用于根据<strong>连续变量</strong>估计实际数值等问题上。通过拟合最佳的<strong>直线</strong>来建立<strong>自变量（X，features）</strong> 和 <strong>因变量（Y，labels）</strong> 的关系。这条直线也叫做回归线，并用<strong>Y = a* X + b</strong>来表示。</p>
<p>在这个等式中：</p>
<ul>
<li><code>Y</code> : 因变量（也就是Labels）</li>
<li><code>a</code> : 斜率（也就是Weights）</li>
<li><code>X</code> : 自变量（也就是Features）</li>
<li><code>b</code> : 截距（也就是Bias）</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PSM7e7e.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>系数 <code>a</code> 和 <code>b</code> 可以通过<strong>最小二乘法</strong>（即让所有pairs带入线性表达式等号两边的方差和最小）获得。</p>
<h3 id="最小二乘法（Least-Squares）"><a href="#最小二乘法（Least-Squares）" class="headerlink" title="最小二乘法（Least Squares）"></a>最小二乘法（Least Squares）</h3><p>最小二乘法最重要的应用是在曲线拟合上。最小平方所包含的最佳拟合，即残差（观测值与模型提供的拟合值之间的差距）平方总和的最小化。当问题在自变量（x变量）有重大不确定性时，那么使用简易回归和最小二乘法会发生问题；在这种情况下，须另外考虑变量-误差-拟合模型所需的方法，而不是最小二乘法。</p>
<p><strong>Example:</strong><br>某次实验得到了四个数据点:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {\displaystyle (x,y)} includes {\displaystyle (1,6)} {\displaystyle (2,5)} {\displaystyle (3,7)} {\displaystyle (4,10)}" style="border:none;"></p>
<p>我们希望找出一条和这四个点最匹配的直线:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y=\beta _{1}+\beta _{2}x" style="border:none;"></p>
<p>即找出在某种 <strong>“最佳情况”</strong> 下能够大致符合如下超定线性方程组的参数：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large \beta _{1}+1\beta _{2} = 6 \\
\beta _{1}+2\beta _{2} = 5 \\
\beta _{1}+3\beta _{2} = 7 \\
\beta _{1}+4\beta _{2} = 10" style="border:none;"></p>
<p>最小二乘法的思路是让等号的两边方差最小。也就是说此时能够算出下面这个函数的最小值：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large S(\beta _{1}, \beta _{2})=[6-(\beta _{1}+1\beta _{2})]^2+[5-(\beta _{1}+2\beta _{2})]^2+[7-(\beta _{1}+3\beta _{2})]^2+[10-(\beta _{1}+4\beta _{2})]^2" style="border:none;"></p>
<p>求解的过程可以通过对S分别对两个参数做偏导数，然后让他们等于0:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {\frac  {\partial S}{\partial \beta _{1}}}=0=8\beta _{1}+20\beta _{2}-56 \\
{\frac  {\partial S}{\partial \beta _{2}}}=0=20\beta _{1}+60\beta _{2}-154." style="border:none;"></p>
<p>此时可以求解出：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large \beta _{1}=3.5 \\
\beta _{2}=1.4" style="border:none;"></p>
<p>也就是说直线方程：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y = 3.5+1.4x" style="border:none;"></p>
<p>为最佳解。</p>
<h2 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h2><p>逻辑回归虽然名字中带有<strong>回归</strong>字样，但其实是一个<strong>分类</strong>算法而不是回归算法。该算法根据已知的一系列因变量估计<strong>离散的数值</strong>（0或1，代表假和真）。该算法通过将数据拟合进一个逻辑函数来预估一个事件发生的<strong>概率</strong>。由于其估计的对象是概率，所以输出的值大都在0和1之间。</p>
<p>逻辑回归通常用于解决二分类的问题，例如判断人是男是女等。逻辑回归就是通过人的一些基本性状特征来判断属于男女的概率。</p>
<p>从数学角度看，几率的对数使用的是<strong>预测变量的线性组合</strong>模型。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Probability of event occurence / not occurence</span></div><div class="line">odds = p / (<span class="number">1</span> - p)</div><div class="line">ln(odds) = ln(p / (<span class="number">1</span> - p))</div><div class="line">logit(p) = ln(p / (<span class="number">1</span> - p)) = b0 + b1X1 + b2X2 + ... + bnXn</div></pre></td></tr></table></figure></p>
<p>式子中 <code>p</code> 指的是特征出现的概率，它选用使观察样本可能性最大的值（<strong>极大似然估计</strong>）作为参数，而不是通过最小二乘法得到。</p>
<ul>
<li><p>那么为什么要取对数log呢？</p>
<ul>
<li>简而言之就是对数这种方式是复制阶梯函数最好的方法之一。</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hq1q9Z5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>关于改进模型的方法：<ul>
<li>加入交互项（<strong>X1 * X2</strong>等）</li>
<li>对输入输出进行正规化</li>
<li>使用非线性模型</li>
</ul>
</li>
</ul>
<h2 id="决策树（Decision-Tree）"><a href="#决策树（Decision-Tree）" class="headerlink" title="决策树（Decision Tree）"></a>决策树（Decision Tree）</h2><p>该算法属于监督式学习的一部分，主要用来处理分类的问题，它能够适用于分类连续因变量。我们将主体分成两个或者更多的类群，根据重要的属性或者自变量来尽可能多地区分开来。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8Nj3E0r.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>根据不同的决策属性，我们可以依次将输入进行分类，最终会得到一个标签（Label）。为了把总体分成不同组别，需要用到许多技术，比如<strong>Gini、Information Gain</strong> 和 <strong>Entropy</strong> 等。</li>
</ul>
<h3 id="Gini"><a href="#Gini" class="headerlink" title="Gini"></a>Gini</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ltVHIxt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中的实际分配曲线（红线）和绝对平衡线（绿线）之间的<strong>面积</strong>为A，和绝对不平衡线（蓝线）之间的面积为B，则横纵坐标之间的比例的<strong>Gini系数</strong>为：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {A \over A + B}" style="border:none;"></p>
<ul>
<li>A为零时，Gini系数为0，表示完全平衡。B为零时，Gini系数为1，表示完全不平衡。</li>
</ul>
<h3 id="Information-Gain-amp-Entropy"><a href="#Information-Gain-amp-Entropy" class="headerlink" title="Information Gain &amp; Entropy"></a>Information Gain &amp; Entropy</h3><p>在我们建立决策树的时候，常常会有许多属性，那么用哪一个属性作为数的根节点呢？这个时候就需要用到 <strong>信息增益（Information Gain）</strong> 来衡量一个属性区分以上数据样本的能力强弱。信息增益越大的属性作为数的根节点，就能使得这棵树更加简洁。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/9vwwsJt.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>以图中数据为例，要想知道信息增益，就必须先算出分类系的<strong>熵值（Entropy）</strong>。最终结果的label是yes或者no，所以统计数量之后共有9个yes和5个no。这时候<strong>P（“yes”） = 9 / 14，P（“no”） = 5 / 14</strong>。这里的熵值计算公式为：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(S) = {-(9 / 14) * log2(9 / 14) - (5 / 14) * log2(5 / 14)}" style="border:none;"></p>
<ul>
<li>之后就可以计算每一个属性特征的信息增益（Gain）了。以wind属性为例，Wind为Weak的共有8条，其中yes的有6条，no的有2条；为Strong的共有6条，其中yes的有3条，no的也有3条。因此相应的熵值为：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(Weak) = {-(6 / 8) * log2(6 / 8) - (2 / 8) * log2(2 / 8)}" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Entropy(Strong) = {-(3 / 6) * log2(3 / 6) - (3 / 6) * log2(3 / 6)}" style="border:none;"></p>
<ul>
<li>现在就可以计算Wind属性的<strong>信息增益</strong>了：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Gain(Wind) = {Entropy(S) -(8 / 14) * Entropy(Weak) - (6 / 14) * Entropy(Strong)}" style="border:none;"></p>
<h2 id="支持向量机（Support-vector-machine-SVM）"><a href="#支持向量机（Support-vector-machine-SVM）" class="headerlink" title="支持向量机（Support vector machine,SVM）"></a>支持向量机（Support vector machine,SVM）</h2><p>SVM是一种常用的机器学习分类方式。在这个算法过程中，我们将每一笔数据在<strong>N维度的空间中用点表示（N为特征总数，Features）</strong>，每个特征的值是一个坐标的值。</p>
<p>如果以二维空间为例，此时有两个特征变量，我们会在空间中画出这两个变量的分布情况，每个点都有两个坐标（分别为tuples所具有的特征值组合）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ea3Jb95.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>现在我们找一条直线将两组不同的数据在维度空间中分开。分割的曲线满足让两个分组中的距离最近的两个点到直线的距离<strong>动态最优化</strong>（都尽可能最近）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/NGsSXtM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>那么看到这里一定很多人和我一样有一个疑问，那就是这种线性分类的SVM和之前提到的逻辑回归（Logistic Regression）有什么<strong>区别</strong>呢？</li>
</ul>
<p>其实他们在二维空间的<strong>线性分类</strong>中都扮演了重要的角色，其主要区别大致可分为两类：</p>
<ul>
<li><p>寻找最优超平面的方式不同。</p>
<ul>
<li>形象来说就是Logistic模型找的超平面（二维中就是线）是尽可能让所有点都远离它。而SVM寻找的超平面，是只让最靠近的那些点远离，这些点也因此被称为<strong>支持向量样本</strong>，因此模型才叫<strong>支持向量机</strong>。</li>
</ul>
</li>
<li><p>SVM可以处理非线性的情况。</p>
<ul>
<li>比Logistic更强大的是，SVM还可以处理<strong>非线性</strong>的情况（经过优化之后的Logistic也可以，但是却更为复杂）。</li>
</ul>
</li>
<li><p><strong>本质区别</strong>为不同的目标函数。</p>
<ul>
<li>SVM采用的loss function为Hinge loss,而Logistic Regression采用的是Cross entropy loss。两者均为discriminative model。前者为了找到一个超平面区分支持向量，所以为Maximum margin classifier。后者为了表示一个数据的分布，所以为Log loss classifier。</li>
<li>举个例子：如果有一万个数据分布在点（1， 1）；而只有10个数据分布在点（-1， -1），那么SVM得到的分类超平面会是原点，而Logistic Regression得到的超平面会是接近点（-1， -1）的范围上。</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/5seIoZJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="朴素贝叶斯（Naive-Bayesian）"><a href="#朴素贝叶斯（Naive-Bayesian）" class="headerlink" title="朴素贝叶斯（Naive Bayesian）"></a>朴素贝叶斯（Naive Bayesian）</h2><p>在假设变量间<strong>相互独立</strong>的前提下，根据贝叶斯定理（Bayesian Theorem）可以推得朴素贝叶斯这个分类方法。通俗来说，一个朴素贝叶斯分类器假设分类的特性和其他特性不相关。朴素贝叶斯模型容易创建，而且在非监督式学习的大型数据样本集中非常有用，虽然简单，却能超越复杂的分类方法。其基本思想就是：对于给出的待分类项，求解<strong>在此项出现的条件下各个目标类别出现的概率</strong>，哪个最大，就认为此待分类项属于哪个类别。</p>
<p>贝叶斯定理提供了从P（c）、P（x）和P（x | c）计算后验概率P（c | x）的方法:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(c | x) = {P(x | c) P(c) \over P(x)}" style="border:none;"></p>
<p>式子中的变量表示如下：</p>
<ul>
<li>P（c | x）是已知预测变量（属性特征）的前提下，目标发生的后验概率。</li>
<li>P（c）是目标发生的先验概率。</li>
<li>P（x | c）是已知目标发生的前提下，预测变量发生的概率。</li>
<li>P（x）是预测变量的先验概率。</li>
</ul>
<p>举一个例子：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gBuFCBd.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这是一个训练资料集，提供一些身体特征，用来预测人的性别。此时假设特征之间独立且满足高斯分布，则得到下表：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eSwuOJV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通过计算方差、均值等参数，同时确认Label出现的频率来判断训练集的样本分布概率，P（male） = P（female） = 0.5。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qZPw7xC.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>此时给出测试资料，我们希望通过计算得到性别的后验概率从而判断样本的类型：</li>
</ul>
<p><strong>男子的后验概率</strong>:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior(male) = {P(male) P(height | male) P(weight | male) P(footsize | male) \over evidence}" style="border:none;"></p>
<p><strong>女子的后验概率</strong>:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior(female) = {P(female) P(height | female) P(weight | female) P(footsize | female) \over evidence}" style="border:none;"></p>
<p>证据因子（evidence）通常为常数，是用来对结果进行归一化的参数。</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Evidence = {(Posterior(female) + Posterior(male)) * evidence}" style="border:none;"></p>
<ul>
<li>因此我们可以计算出相应结果：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(height | male) = {1 \over \sqrt{2\pi\sigma^2}}exp({-(6 - \mu^2) \over 2\sigma^2})" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P(weight | male) = ..." style="border:none;"></p>
<ul>
<li>最后可以得出后验概率:</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior Numerator(male) = {6.1984e^{-09}}" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Posterior Numerator(female) = {5.3778e^{-04}}" style="border:none;"></p>
<ul>
<li>因此女性的概率较大，我们估计结果为女性。</li>
</ul>
<h2 id="K近邻（K-Nearest-Neighbors）"><a href="#K近邻（K-Nearest-Neighbors）" class="headerlink" title="K近邻（K Nearest Neighbors）"></a>K近邻（K Nearest Neighbors）</h2><p>该算法可以用于分类和回归问题，然而我们更常将其被用于解决分类问题上。KNN能够存储所有的案例，通过对比周围K个样本中的大概率情况，从而决定新的对象应该分配在哪一个类别。新的样本会被分配到它的K个最近最普遍的类别中去，因此KNN算法也是一个基于距离函数的算法。</p>
<p>这些<strong>距离函数</strong>可以是欧氏距离、曼哈顿距离、明氏距离或是汉明距离。前三个距离函数用于<strong>连续函数</strong>，最后一个用于<strong>分类变量</strong>。如果K = 1，新的样本就会被直接分到距离最近的那个样本所属的类别中。因此选择K是一个关系到模型精确度的问题。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7sGrxz0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如图所示，如果我们取K = 3，即为中间的圆圈内，我们可以直观地看出此时绿点应该被归为红三角的一类。而如果K = 5，此时延伸到虚线表示的圆，则此时绿点应该被归为蓝色的类。</li>
</ul>
<p>在选择KNN之前，我们需要考虑的事情有：</p>
<ul>
<li>KNN在K数量大的时候的计算成本很高。</li>
<li>变量（Features）应该先标准化（normalized），不然会被更高数量单位级别的范围带偏。</li>
<li>越是<strong>干净</strong>的资料效果越好，如果存在偏离度较高的杂讯噪声，那么在类别判断时就会收到干扰。</li>
</ul>
<h3 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h3><p>空间中点X = （X1，X2，X3，…，Xn）与点Y = （Y1，Y2，Y3，…，Yn）的欧氏距离为：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large d(x, y) := {\sqrt{(X1 - Y1)^2 + (X2 - Y2)^2 + ... + (Xn - Yn)^2}}" style="border:none;"></p>
<h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h3><p>在平面上，坐标（X1，X2，…，Xn）的点和坐标（Y1，Y2，…，Yn）的点之间的曼哈顿距离为:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {|X1 - Y1| + |X2 - Y2| + ... + |Xn - Yn|}" style="border:none;"></p>
<h3 id="明氏距离"><a href="#明氏距离" class="headerlink" title="明氏距离"></a>明氏距离</h3><p>两点 P = (X1，X2，…，Xn) 和 Q = （Y1，Y2，…，Yn）之间的明氏距离为:</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large {(|X1 - Y1|^p + |X2 - Y2|^p + ... + |Xn - Yn|^p)^{1 \over p}}" style="border:none;"></p>
<ul>
<li>其中p取1时为曼哈顿距离，p取2时为欧氏距离。</li>
</ul>
<h3 id="汉明距离"><a href="#汉明距离" class="headerlink" title="汉明距离"></a>汉明距离</h3><p>对于固定长度n，汉明距离是该长度字符串向量空间上的度量，即表示长度n中不同字符串的个数。</p>
<p>例子：</p>
<ul>
<li><strong>“toned”</strong> 和 <strong>“roses”</strong> 之间的汉明距离就是3。因为其中 <strong>t - &gt; r，n -&gt; s，d -&gt; s</strong> 三个字符不相同。</li>
</ul>
<h2 id="K均值（K-means）"><a href="#K均值（K-means）" class="headerlink" title="K均值（K-means）"></a>K均值（K-means）</h2><p>K-means方法是一种<strong>非监督式学习</strong>的算法，能够解决<strong>聚类</strong>问题。使用K-means算法将一个数据样本归入一定数量的集群中（假设有K个）中，每一个集群的数据点都是均匀齐次的，并且异于其它集群。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/WQlIGo4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>K-means算法如何形成<strong>集群</strong>？</p>
<ul>
<li>给一个集群选择K个点，这些点称为质心。</li>
<li>给每一个数据点与距离最接近的质心形成一个集群，也就是K个集群。</li>
<li>根据现有的类别成员，找出每个类别的质心。</li>
<li>当有新的样本输入后，找到距离每个数据点最近的质心，并与质心对应的集群归为一类，计算新的质心位置，重复这个过程直到数据收敛，即质心位置不再改变。</li>
<li>如果新的数据点到多个质心的距离相同，则将这个数据点作为<strong>新的质心</strong>。</li>
</ul>
<p>如何决定K值？</p>
<ul>
<li>K-means算法涉及到集群问题，每个集群都有自己的质心。一个集群的内的质心和个数据点之间的距离的平方和形成了这个集群的平方值之和。我们能够直观地想象出当集群的内部的数据点增加时，K值会跟着下降（数据点越多，分散开来每个质心能够包揽的范围就变大了，这时候其他的集群就会被吞并或者分解）。<strong>集群元素数量的最优值</strong>也就是在集群的平方值之和最小的时候取得（每个点到质心的距离和最小，分类最精确）。</li>
</ul>
<h2 id="随机森林（Random-Forest）"><a href="#随机森林（Random-Forest）" class="headerlink" title="随机森林（Random Forest）"></a>随机森林（Random Forest）</h2><p>Random Forest是表示<strong>决策树总体</strong>的一个专有名词。在算法中我们有一系列的决策树（因此为<strong>森林</strong>）。为了根据一个新的对象特征将其分类，每一个决策树都有一个分类结果，称之为这个决策树<strong>投票</strong>给某一个分类群。这个森林选择获得其中（所有决策树）<strong>投票数最多</strong>的分类。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/xViexYM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>Random Forest中的Decision Tree是如何形成的？</p>
<ul>
<li>如果训练集的样本数量为N，则从N个样本中用重置抽样的方式随机抽取样本。这个样本将作为决策树的训练资料。</li>
<li>假如有N个输入特征变量，则定义一个数字<strong>m &lt;&lt; M</strong>。m表示从M中随机选中的变量，这m个变量中最好的切分特征会被用来当成节点的决策特征（利用Information Gain等方式）。在构建其他决策树的时候，m的值<strong>保持不变</strong>。</li>
<li>尽可能大地建立每一个数的节点分支。</li>
</ul>
<h3 id="随机森林的优点"><a href="#随机森林的优点" class="headerlink" title="随机森林的优点"></a>随机森林的优点</h3><p>随机森林的优点有：</p>
<ul>
<li>对于很多种资料，它可以产生高准确度的分类器。</li>
<li>它可以处理大量的输入特征，并且不用做特征选择。</li>
<li>它可以在决定类别时，评估变数的重要性。</li>
<li>在建造森林时，它可以在内部对于一般化后的误差产生不偏差的估计。</li>
<li>它包含一个好方法可以<strong>估计遗失的资料</strong>，并且，如果有很大一部分的资料遗失，仍可以<strong>维持准确度</strong>。</li>
<li>它提供一个实验方法，可以去侦测variable interactions。</li>
<li>对于<strong>不平衡的分类资料集</strong>来说，它可以平衡误差。</li>
<li>它计算各例中的亲近度，对于数据挖掘、侦测离群点（outlier）和将资料视觉化非常有用。</li>
<li>使用上述。它可被延伸应用在未标记的资料上，这类资料通常是使用非监督式聚类。也可侦测偏离者和观看资料。</li>
<li>学习过程是<strong>很快速</strong>的。</li>
<li>抽样独立，容易实现<strong>并行化</strong>。</li>
</ul>
<h3 id="梯度提升决策树（GBDT）"><a href="#梯度提升决策树（GBDT）" class="headerlink" title="梯度提升决策树（GBDT）"></a>梯度提升决策树（GBDT）</h3><p>梯度提升决策树（Gradient Boosting Decision Tree）又叫做MART（Multiple Additive Regression Tree）, GBRT， Tree Net等，是一种迭代的决策树算法，同样由多棵树组成，所有树的结果<strong>累加</strong>起来就是最终结果。它和SVM一样都是泛化能力比较强的算法。</p>
<p>GBDT中的树是回归树不是分类树，但是经过调试后也能够用于分类。<strong>GBDT具有天然优势能够发现多种具有区分性的特征以及特征组合</strong>。</p>
<p>GBDT通过迭代多棵回归树来共同决策。当采用平方误差损失函数（Squared Loss function）时，每一棵回归树学习的是<strong>之前所有树的结论和残差</strong>，拟合得到一个当前的残差回归树（残差 = 真实值 - 预测值）。</p>
<p><strong>Example:</strong><br>利用GBDT模型预测年龄：训练集4人，年龄分别为14， 16， 24， 26。样本中有购物金额，经常到百度知道提问解答等特性。GBDT建立过程如下：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/quaDbzd.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>预测结果由所有树累加得到：</p>
<ul>
<li>A : 14岁购物少，经常在百度知道上提问，预测年龄A = 15 - 1 = 14</li>
<li>B : 16岁购物少，经常在百度知道上回答，预测年龄B = 15 + 1 = 16</li>
<li>C : 24岁购物多，经常在百度知道上提问，预测年龄C = 25 - 1 = 24</li>
<li>D : 26岁购物多，经常在百度知道上回答，预测年龄D = 25 + 1 = 26</li>
</ul>
<h3 id="Random-Forest-amp-GBDT差别"><a href="#Random-Forest-amp-GBDT差别" class="headerlink" title="Random Forest &amp; GBDT差别"></a>Random Forest &amp; GBDT差别</h3><p>随机森林(random forest)和GBDT都是属于集成学习（ensemble learning)的范畴。集成学习下有两个重要的策略<strong>Bagging和Boosting</strong>。Boosting主要关注降低偏差（bias），因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成；Bagging主要关注降低方差（Variance），因此它在不剪枝的决策树、神经网络等学习器上效用更为明显。</p>
<ul>
<li>如下图所示，当模型越复杂时，拟合的程度就越高，模型的训练偏差就越小。但此时如果<strong>换一组数据</strong>可能模型的变化就会很大，即模型的方差很大。所以模型过于复杂的时候会导致过拟合。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Zs3tAfG.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>对于Bagging算法来说，由于我们会并行地训练很多不同的分类器的目的就是降低这个方差(variance) ,因为采用了相互独立的基分类器多了以后，h的值自然就会靠近。所以对于每个基分类器来说，目标就是如何降低这个偏差（bias)，所以我们会采用深度很深甚至不剪枝的决策树。 </li>
<li>对于Boosting来说，每一步我们都会在上一轮的基础上更加拟合原数据，所以可以保证偏差（bias）,所以对于每个基分类器来说，问题就在于如何选择variance更小的分类器，即更简单的分类器，所以我们选择了深度很浅的决策树。</li>
</ul>
<h2 id="降维（Dimensionality-reduction）"><a href="#降维（Dimensionality-reduction）" class="headerlink" title="降维（Dimensionality reduction）"></a>降维（Dimensionality reduction）</h2><p>当今的社会中信息的捕捉量都是呈上升的趋势。各种研究信息数据都在尽可能地捕捉完善，生怕遗漏一些关键的特征值。对于这些数据中包含许多特征变量的数据而言，看似为我们的模型建立提供了充足的<strong>训练材料</strong>。但是这里却存在一个问题，那就是<strong>如何从上百甚至是上千种特征中区分出样本的类别呢？</strong>样本特征的<strong>重要程度</strong>又该如何评估呢？</p>
<ul>
<li>其实随着输入数据特征变量的增多，模型很难拟合众多样本变量（高维度）的数据分类规则。这样训练出来的模型不但<strong>效果差</strong>，而且<strong>消耗大量的时间</strong>。</li>
<li>这个时候，降维算法和别的一些算法（比如<strong>Decision Tree</strong>、<strong>Random Forest</strong>、<strong>主成分分析（PCA）</strong> 和 <strong>因子分析</strong>）就能帮助我们实现根据相关矩阵，压缩维度空间之后总结特征规律，最终再逐步还原到高维度空间的训练模式。</li>
</ul>
<h3 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h3><p>在多元统计分析中，PCA是一种分析、简化数据集的技术，经常用于减少数据集的维数，同时保留数据集中的<strong>对方差贡献最大</strong>的那些特征变量。</p>
<ul>
<li>该算法会根据不同维度的压缩（在这个维度上的<strong>投影</strong>）来测试<strong>各个维度对方差的影响</strong>，从而对每一个维度进行重新排序（影响最大的放在第一维度）。之后只需要取有限个数的维度进行训练，就能够保证模型拟合最佳的数据特征了。</li>
</ul>
<h3 id="因子分析"><a href="#因子分析" class="headerlink" title="因子分析"></a>因子分析</h3><p>该算法主要是从关联矩阵内部的依赖关系出发，把一些重要信息重叠，将错综复杂的变量归结为少数几个不相关的综合因子的多元统计方法。基本思想是：根据<strong>相关性大小</strong>把变量分租，使得同组内的变量之间相关性高，但不同组的变量不相关或者相关性低。每组变量代表一个基本结构，即公共因子。</p>
<h2 id="Gradient-Boost-amp-Adaboost"><a href="#Gradient-Boost-amp-Adaboost" class="headerlink" title="Gradient Boost &amp; Adaboost"></a>Gradient Boost &amp; Adaboost</h2><p>当我们想要处理很多数据来做一个具有高度预测能力的预测模型时，我们会用到Gradient Boost和AdaBoost这两种Boosting算法。<strong>Boosting算法</strong>是一种集成学习算法，它结合了建立在多个基础估计值上的预测结果，来增强单个估计值的准确度。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/eOKOw6J.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h3><p>Bossting能够对一份数据建立多个模型（如分类模型），通常这些模型都比较简单，称为<strong>弱分类器（Weak Learner）</strong>。每次分类都将上一次分错的数据权重值调大（放大的圆圈），然后再次进行分类，最终得到更好的结果。最终所有学习器（在这里值分类器）共同组成完整的模型。</p>
<h3 id="Gradient-Boost"><a href="#Gradient-Boost" class="headerlink" title="Gradient Boost"></a>Gradient Boost</h3><p>与Adaboost不同的是，Gradient Boost在迭代的时候选择梯度下降的方向来保证最后的结果最好。损失函数（Loss function）用来描述模型的误差程度，如果模型没有Over fitting，那么loss的值越大则误差越高。如果我们的模型能够让损失函数值下降，说明它在不断改进，而最好的方式就是让函数在<strong>梯度的方向</strong>上改变。（类似神经网络的<strong>Gradient Descend</strong>）</p>
<h1 id="什么是神经网络（Neural-Network）"><a href="#什么是神经网络（Neural-Network）" class="headerlink" title="什么是神经网络（Neural Network）"></a>什么是神经网络（Neural Network）</h1><p>基于生物学的神经结构，将神经细胞的电信号传播机制应用到计算机结构中来，通过对信号传导和演变来组成网络架构。人工神经网络中的每一个“神经元”就是一个Neuron，用来以一定的算法改变输入的信号，从而改变传输的信息，达到对环境做出反应的目的。另一方面，通过神经网络产生的反应收到环境的反馈（做的好或不好），这些反馈和目标行为的误差会通过神经网络的反向传递从原先的路径传送回去，沿途中这些反馈信号会反过来刺激Neuron调整相应的参数从而使得下一次正向传递的结果能够更加贴近目标。如此往复便是整个神经网络训练的过程。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/umtL8L5.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>人类通过学习，能够掌握和判别事物的特征从而对事物的本质做出判断，而机器同样是利用这种机制建立起相应的“识别”模型，这些模型对不同的事物具有不同的反应强度，利用强度的不同来区别事物的本质。</p>
<h2 id="神经网络的基本结构"><a href="#神经网络的基本结构" class="headerlink" title="神经网络的基本结构"></a>神经网络的基本结构</h2><p>一个简单的神经网络由3个部分组成：</p>
<ul>
<li><strong>Input Layer</strong><ul>
<li>输入层，用来将资料喂给神经网络</li>
</ul>
</li>
<li><strong>Hidden Layer</strong><ul>
<li>隐藏层，用来尝试改变和调整神经网络的模型和数据的转化</li>
</ul>
</li>
<li><strong>Output Layer</strong><ul>
<li>输出层，用来将神经网络处理后的信号输出成最终的结果</li>
</ul>
</li>
</ul>
<h2 id="神经元（Neuron）的激活函数（Activation-Function）"><a href="#神经元（Neuron）的激活函数（Activation-Function）" class="headerlink" title="神经元（Neuron）的激活函数（Activation Function）"></a>神经元（Neuron）的激活函数（Activation Function）</h2><p>在神经网络学习的过程中，需要对输入的信号做出某种调整，才能真正得到最终的结果。<br>传统的激活函数包括：<br><strong>Sigmoid</strong>、<strong>TanHyperbolic(tanh)</strong>、<strong>ReLu</strong>、 <strong>softplus</strong>以及<strong>softmax</strong>函数</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LT2BXvM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>例如当我们输入一只猫，输入层神经网络会把信号传递给隐藏层的神经元。每一个接收到信息的神经元会通过自己现有的经验对信号做出判断，利用激活函数（activation function）来判断此时的神经元是否需要被激活。激活后的神经元就会对输入信号进行处理并传递给下一层的神经网络层，如此往复当信号传递到输出层时则会经由最终的刺激函数（一般为softmax）产生相应的结果确定输出的信号是属于哪一个标签（label）。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vYgqqHJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果此时计算机得到了错误的结果，我们就会通过反向的传递将误差传导回去，改变<strong>所有</strong>的神经元参数，继而那些原本活跃的神经元就会被弱化，在下一次的神经传导过程中就会逐渐被激活函数淘汰。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/UHIK2YN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>经过更新的神经网络能够在下一次迭代过程（epoch）中就会改变思路，转而尝试其他的判断方法。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/so90M0c.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>直到得到正确的结果，误差就会小到可以忽略，如此神经网络得以生成。</p>
<h2 id="卷及神经网络（CNN）"><a href="#卷及神经网络（CNN）" class="headerlink" title="卷及神经网络（CNN）"></a>卷及神经网络（CNN）</h2><p>卷积神经网络（Convolution Neural Network）在图片识别方面能够给出不错的结果。而卷积的作用实际上是对Fully connected的控制：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Tvko00g.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用卷积的方式来选取进入下一个hidden layer中每一个neuron的链接数量，这样可以有效控制每个neuron处理信息的<strong>针对性</strong>。（Different neurons have different, but overlapping, receptive fields）</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Y65bdvJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TZ1jOeO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用<strong>图片</strong>作为例子，任何输入的信号都会被转化成计算机能够识别的数字信号集合，例如矩阵（matrix）。<strong>文字</strong>也是一样的，我们把文字抽象成一个固定维度的向量，在这个维度空间中，每个字都是独立区别开来的，文字的多样性就有这些数字的排列组合来定义。这些信号集会通过输入层读取信息并进入神经网络中。<br>卷积神经网络就是其中的一种网络模式，我们可以把它分成<strong>卷积</strong>和<strong>神经网络</strong>两个部分来理解。</p>
<ul>
<li><strong>卷积</strong>：可以理解为对一个区域信号强弱的总体分析。通过卷积运算可以在一定的区域内总结有用信号的强弱分布，从而对一定区域内信号的变化情况能够有一个较好的认知。卷积能够增强信号的连续性，用区域单位代替点电位。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uOav6gV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><strong>神经网络</strong>：卷积神经网络利用批量过滤的方式，在大范围的信号中不断收集信息，每一次得到的区域信息都是区域中的一小块，之后从这些信息中总结出一些所谓的边缘信号（edges，例如：竖线，横线，斜线，圆圈等基本边缘，其可能分别代表人脸眼睛的左上角，中间，右上角等等部位的区域信息）。同样，用相同的方式从边缘信息组合的图像中总结出更大范围的边缘信息（例如：利用竖线，横线，圆圈等结构组合出整个眼睛）。最后将得到的结果传入全连接层的分类神经网络中就能得到相应的label了。</li>
</ul>
<p><strong>Example：</strong> </p>
<p>如果以灰阶图像为例，其高度为1，fsize = 5。此时ksize = 3, strides = 1。那么结果为一个reshape_size = 3的图像。</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large rsize = {fsize - ksize + 2* padding \over strides} + 1" style="border:none;"></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/HbnsG7v.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>卷积的过程就是将物件的特征值（图像多为基本颜色）拆分成小块区域，然后计算其中<strong>各个特征值</strong>的和。最后输出为一个压缩后的图像。如上图，以0为黑色，1为白色，那么求得的最后图像中每一个方格的值就是kernel中所有格子数的加权和。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/fScPOCU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/fScPOCU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图片的维度信息有长、宽和高，长和宽用来表示图片的信号集，高度则是表示颜色的信号分布。被白颜色只有1个高度单位，而彩色的图片则有R、G、B三种基本颜色的信息单位。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VmMQcSI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>利用批量过滤从图片中收集一定区域中的像素块，而输出的值就是一个高度更高，长和宽都更小的图片。这些图片存储的就是边缘（edges）信息。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/twaqQCR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>反复进行同样的过滤步骤，就可以对图片的信息有更好的理解。之后再对结果进行分类就行了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ikChVno.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在卷积的过程中，神经元可能无意中会丢失一些信息。池化（pooling）就是为了解决这样的问题而被设计出来的。既然我们的信息是在卷积过程中压缩的时候丢失的，那么我们就舍弃这个步骤，直接保留原本的长宽，最后在由池化层统一进行压缩长宽的动作。</p>
<p>跟踪细节如下：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RnGaqvA.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h3 id="CNN常用结构"><a href="#CNN常用结构" class="headerlink" title="CNN常用结构"></a>CNN常用结构</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zugYmYR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>比较流行的<strong>CNN结构</strong>先是输入信号，经过卷积层进行卷积运算，然后经过池化压缩长宽的维度。常用的是Max Pooling的结构：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/T3B3QjS.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在区域中区最大值作为代表这个区域的信号。之后再次对结果进行相同的卷积和池化，进一步压缩信号。之后通过两个全连接层将信号传导给分类器进行分类预测。</p>
<h3 id="CNN常用结构-1"><a href="#CNN常用结构-1" class="headerlink" title="CNN常用结构"></a>CNN常用结构</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zugYmYR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>比较流行的<strong>CNN结构</strong>先是输入信号，经过卷积层进行卷积运算，然后经过池化压缩长宽的维度。常用的是Max Pooling的结构：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/T3B3QjS.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在区域中区最大值作为代表这个区域的信号。之后再次对结果进行相同的卷积和池化，进一步压缩信号。之后通过两个全连接层将信号传导给分类器进行分类预测。</p>
<h2 id="递归神经网络（RNN）"><a href="#递归神经网络（RNN）" class="headerlink" title="递归神经网络（RNN）"></a>递归神经网络（RNN）</h2><p>递归神经网络（Recurrent Neural Network）在自然语言处理和序列化信息分析方面能够给出不错的结果。如果说CNN是图像识别的代表性神经网络，那么RNN就是文字处理领域的“CNN”。</p>
<ul>
<li><strong>语言文字</strong>就是一个典型的<strong>序列化信号集</strong>，我们说出的每一句话之间，甚至每一个词之间都有先后关系的依赖，如果抛开字的先后顺序，我们的语言将会失去原本的含义。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/afEYtWN.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>假设现在有许多不同的数据信号，如果神经网络只是基于当前的输入信号进行结果的预测，那么就相当于无视了所谓的连续规则，其中必然会丢失重要的时序信息。就好比做菜，酱料A要比酱料B先放，否则就会导致串味的现象。因此一般的NN结构无法让机器了解数据之间的关联。</p>
<p><strong>那么要如何做到让计算机也具有处理连续信号的能力呢？</strong></p>
<ul>
<li>从人的角度出发，不难想到的方式就是记住先前处理过的信号，并将这些信号一同作为输入传递到当前的神经网络中。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/AUqu2Ss.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>我们将先前处理的结果存入记忆中，在分析当前信号时会产生新的记忆。由于记忆之间不会相互关联，因此我们可以直接将先前的记忆调用过来一起进行处理：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/D86UcOA.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如此一来往复多次，神经网络就能携带长期的序列信号进行处理了。<strong>总结之前的流程：</strong></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/MW1BRcu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN运作过程中，每次的结果都会被存储为一个State状态信号，并通过不断迭代传递到下一个乃至更远的神经网络中去。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/iQKtiQP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在RNN下一个时刻到来时，State状态同样会被存储成T+1时刻的State，但这是的 <strong>Y（t）</strong> 不再只是由 <strong>S（t+1）</strong> 来决定的，而是通过 <strong>S（t）</strong> 和 <strong>S（t+1）</strong> 共同处理 <strong>X(t+1)</strong> 得到的结果。因此这个State结构也可以用递回的方式来表示。</li>
</ul>
<h3 id="RNN常用结构"><a href="#RNN常用结构" class="headerlink" title="RNN常用结构"></a>RNN常用结构</h3><p>RNN的形式多种多样，一般需要根据处理的情况不同选择相应适合环境的模型进行建模。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/aZqWHqb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>通常可以看到以下几种：</p>
<ul>
<li>如果是用于<strong>分类</strong>的话，例如在判断一句话的情感取向，判断是positive或者negative的情况下，倾向于使用根据最终结点的结果来输出判断的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Noc6AFL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>描述</strong>的话，例如通过一些集成度高的特征信号（图片等）来产生一个描述性的句子或者序列的情况下，倾向于使用根据单一输入来逐步读取时序信息的RNN：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/2zP4G0h.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果是用于<strong>翻译</strong>的话，例如通过一段连续的输入信号来预测下一段连续输出信号的情况下，倾向于使用多对多输出的序列化RNN（Sequence-to-Sequence）：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LJSO3JG.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="LSTM-Long-Short-Term-Memory"><a href="#LSTM-Long-Short-Term-Memory" class="headerlink" title="LSTM(Long Short-Term Memory)"></a>LSTM(Long Short-Term Memory)</h2><p>RNN的网络在训练的时候会通过递归的方式传回之前网络学习到的记忆，从而使神经网络能够保留先前的信息。而传统的RNN在处理记忆单元的时候时常还是很容易 <strong>“遗忘”</strong> 重要信息的，因此我们需要一个更加强大的网络结构来帮我们锁住重要的过去式信息流，而最流行的结构也就是所谓的 <strong>LSTM</strong> 了。</p>
<p>那么传统的RNN模型究竟是为何会经不起<strong>长时间记忆</strong>的考验呢？这里用一个例子来说明：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Q6kwno6.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>假如我们所要分析的句子如上图所示，要想让机器知道我们吃的是 “红烧排骨” 而不是 “辣子鸡”，这时候神经网络就会将误差反向传递回去。</p>
</li>
<li><p>在反向传递的过程中，由于我们所要改变的句子成分在时序信息的最开始部分，因此需要经过很长的误差传递才能到达（也就是我们说的长记忆或久远记忆）。这个时候我们的误差在反向传递的过程中都会经由梯度在每一个神经网络层进行一个 Weight 权重的改变。而加入这个权重值是一个大于0小于1的数值，则反向传递的误差在经过每一次的传递过程就会损失一部分的信息，如此往复到了久远的网络层之后，这个误差就会因为信息太弱而 <strong>消失</strong> 了，这样我们的神经网络就无法回忆起重要的信息了，也就是所谓的梯度消失（Gradient Vanishing）。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/aNaKsMo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>而另一方面，如果这个权重值是一个大于1的数，在不断迭代的过程中就会让误差不断放大，最终达到无法修复的地步，也就是所谓的梯度爆炸（Gradient Exploding）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/cynIKSd.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>而LSTM网络就是利用了在RNN结构基础上加入了三个Gate来作为控制器，从而控制误差的传递和信息的更新的。这三个 <strong>Gate</strong> 分别为 <strong>Input Gate</strong> 、 <strong>Forget Gate</strong> 和 <strong>Output Gate</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VyjupUu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们可以将LSTM的输入分成两部分，一部分是从一开始就持续进行的信息累加（也就是所有时刻的信息加总，我们成可以想象成主线剧情）。另一部分就是每一个神经网络层单独拥有的信息部分（可以想象成支线剧情）。主线剧情随着神经层的传递不断累加信息，而直线剧情则是每一层的神经元将重要的信息通过不同的权重值传递给主线剧情，而不重要的部分则经由遗忘控制器（Forget Gate）来替换掉。输出控制则是用来规划每一个神经层传递到下一级的时候需要如何分配输出的权重问题。这些控制器都会接受反向传递的误差来动态调整权重值，从而使网络能够正常地运作。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hbppRzw.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="如何选择合适的模型"><a href="#如何选择合适的模型" class="headerlink" title="如何选择合适的模型"></a>如何选择合适的模型</h2><p>不同的神经网络结构能够将输入和输出转换成不同的形态，针对<strong>不同的Domain</strong>，我们就能够对模型进行选择。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/nAlg6qz.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如图所示：</p>
<ul>
<li><p>如果输入和输出信号是Vector，多用在分类和特征提取的时候，我们会选择使用Fully Connected Feedforward Network。</p>
</li>
<li><p>如果输入和输出信号是Matrix（例如图片或者多维度特征集合），我们多选用Convolutional Neural Network。</p>
</li>
<li><p>如果输入和输出信号是Sequence Vector（例如声音和文字），我们多选用Recurrent Neural Network。</p>
</li>
</ul>
<h1 id="神经网络非监督式学习实现Autoencoder"><a href="#神经网络非监督式学习实现Autoencoder" class="headerlink" title="神经网络非监督式学习实现Autoencoder"></a>神经网络非监督式学习实现Autoencoder</h1><p>在神经网络训练过程中，往往会需要输入大量的信息，而这些信息对于计算机的学习来说具有十分巨大的负担。想想人类的学习过程，如果一次性塞给我们大量的信息，不但达不到很好的学习效果，还会浪费大量的时间。</p>
<p>因此我们需要一个特殊的神经网络来将原本的信息进行压缩，提取其中最具有代表性的信息，这个网络就是所谓的<strong>编码器（encoder）</strong>。之后再通过放大压缩后的信息，重现原始资料的全部信息，也就是 <strong>解码（decoder）</strong> 的过程。而我们所需要做的就是取得编码器压缩之后的简要信息，送入神经网络进行学习，从而达到我们的目的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/SfOfLbo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>压缩和解压的过程共同构成自编码（Autoencoder）的行为，通过训练编码器和解码器的神经网络结构，依据每次压缩前和解压后数据的对比情况来判断压缩的好坏程度，并利用反向传递来修正误差，从而最大程度上的压缩和还原原始信号。由于从头到尾我们所需要的输入信息为原始信号的信息，整个过程不需要对应的标签信息（label），因此autoencoder属于非监督学习的方式。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BidenDF.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通常会使用到的部分是自编码的结果，也就是压缩过后的概括性讯息。我们建构的其他神经网络只需要对这些精髓的信息进行学习就行了。这样的方式不仅减少了神经网络的负担，还能达到很好的学习效果。</li>
</ul>
<p>自编码的思路和传统的主成分分析算法的精髓类似，都是试图从数据中抓住决定性的关键内容，来概括和分类数据的特征。相比于传统的降维算法中的PCA主成分分析方法，Autoencoder甚至能够取得更好的效果，因此也常被用来对原始数据进行<strong>降维</strong>。</p>
<h1 id="生成对抗网络（GAN）"><a href="#生成对抗网络（GAN）" class="headerlink" title="生成对抗网络（GAN）"></a>生成对抗网络（GAN）</h1><p>生成对抗网络（Generative Adversarial Net）不同于传统的FNN、CNN和RNN是将输入的数据和输出的结果通过某种关系联系起来的神经网络模型，GAN则是一种<strong>凭空生成结果</strong>的模型。</p>
<ul>
<li>当然所谓的 <strong>凭空</strong> 并不是真正意义上的<strong>无</strong>，而是通过一些随机的尝试（随机数组合）创造出一些东西。比如一张图片（像素集合）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/lOfWUK4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们可以把这个随机尝试生成图片的网络比喻成一名新手画家，他们根据自己的灵感用现有的技术生成一些画作。一开始可能有了灵感但是由于作画技术的限制，往往无法生成理想中的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/tU6ZZEW.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>于是这名画家就找到了自己的好朋友新手鉴赏家，可是因为新手鉴赏家本身不具备良好的分辨能力，因此往往给出错误的回答。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/a3YNuV0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这个时候就会有外部的干涉参与其中，通过一些标记好的资料来训练这名新手鉴赏家，让他一步步能够辨别画作的好坏。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ou0PBfm.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>最重要的是在训练新手鉴赏家的过程中，随着鉴赏技术不断成熟，鉴赏家开始对新手画家的一些作品做出正确的判断和反馈。这时新手画家就会从这个新手鉴赏家手中得到<strong>真正的有用的标签（label）</strong>，进而利用这些标签改变自己的网络，让自己能够画得更好。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PW7ll1Q.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>总结之前的流程，就是新手鉴赏家这个神经网络利用从外部监督得到的反馈提升自己，然后再利用自己去训练另外一个神经网络，随着新手画家神经网络的不断提升，鉴赏家网络得知自己的能力已经无法鉴赏该画作时，就再次求助外部反馈。就在这一次一次地<strong>对抗</strong>中，两个神经网络就会越来越强大。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/huvFBco.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在GAN网络中，新手画家就是我们的<strong>生成器（Generator）</strong>，新手鉴赏家就是所谓的<strong>Discriminator（辨别器）</strong>，画家的每一幅画都是通过不同的数字排列组合成的像素矩阵，也就是我们说的图片。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BtcBwwU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h2 id="GAN的应用"><a href="#GAN的应用" class="headerlink" title="GAN的应用"></a>GAN的应用</h2><p>GAN因为能够通过随机组合产生新的数据，因而常被用在数据的合成和生成新数据的方面。</p>
<ul>
<li>其中一个重要的例子就是数据序列的加减法：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7NxbFvF.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>图中的二次元人物是通过GAN神经网络的学习，然后利用描述性的选项组合，来生成不同特征的人物图像的一个神经网络网络应用。</p>
<h1 id="理解神经网络的“-黑盒子-”"><a href="#理解神经网络的“-黑盒子-”" class="headerlink" title="理解神经网络的“ 黑盒子 ”"></a>理解神经网络的“ 黑盒子 ”</h1><p>神经网络的成功之处在于它能够从输入和输出的数据中总结出一个抽象的算法函式，基于这个函式的关系我们就能够对未知的数据进行预测。</p>
<p>例如：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y = {ax + b \over 2}" style="border:none;"></p>
<p>这个就相当于一个已经训练好的神经网络模型，对于输入信号<code>X</code>通过网络的处理之后得到输出结果<code>Y</code>。</p>
<p>而神经网络建立的模型就像是把算法公式中所有参数进行一个<strong>封装</strong>，然后开放一个相应的<strong>接口(Interface)</strong>用于呼叫和取值。因此神经网络也被亲切地称之为 <strong>“ 黑匣子 ”</strong> 。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/U5riVAp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>神经网络一般分为三个部分，输入和输出都是人类能够理解的信息，而中间的部分就是所谓的<strong>盲区</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uZpZxdz.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果我们将神经网络的中间层注意拆解后会发现输出的事物往往会是我们看不懂的东西，这就是为什么神经网络 <strong>“黑”</strong> 的原因了。对于人而言，我们在记忆复杂的环境和事物时往往会用一些自己熟知的<strong>记号来标记事物</strong>，使得我们能够更加清楚地记得事物的特征。计算机也是一样的：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gdW7DwM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们知道神经网络处理的信息大都是数字集，通过神经层的分离可以看到这些数字集发生了改变，这些改变在人类看来无法理解，但事实上却是计算机利用自己的方式将这些事物通过它们捕捉到的特征信息转换成<strong>它们眼中的记号</strong>。也就是说计算机正在试图用自己能够理解的方式标记这些特征。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FF8SNDZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在神经网络中，我们称人们能够识别的<strong>特征</strong>记作<strong>Features</strong>，而机器转换后的<strong>特征标记</strong>记作<strong>Feature Representation</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ZrHPbGp.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>利用手写数字的特征来理解的话，神经网络的Feature Representation就是空间中不同区域的分布状况。不同的位置聚集了不同的数字集合，落在不同的区域内就说明该输入属于哪一个输出。也就是说计算机把我们熟知的<strong>数字（也就是Features）</strong> 用 <strong>空间坐标区域（也就是Feature Representation）</strong> 来表示。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/1GT46F0.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>理解神经网络的内部结构和Feature Representation的含义可以很好地利用 <strong>迁移学习（Transform Learning）</strong> 的方式来组合我们的神经网络，从而达到更好的效果。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/hE5VgF2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>例如我们已经训练好了从图片中解析物体的神经网络，它能够从图像的序列信息中提取关键的特征事物，此时只需要将输出层替换掉，再加入新的神经网络结构进行连接，就可以生成全新的模型。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/qslxK9t.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>新的神经网络重新训练之后就能够具有全新的功能，利用原先的网络优势来拓展生成新的<strong>特征标记</strong>，一定程度上减少了神经网络训练的复杂度。基于先前的图像提取，能够从图中得到事物的<strong>特征信息（Feature Representation）</strong>，再利用新的网络将这些信息进一步转换成表示事物价格的<strong>特征信息</strong>，如此一来神经网络的功能就得以演化了。</li>
</ul>
<h1 id="如何优化神经网络（Optimization）"><a href="#如何优化神经网络（Optimization）" class="headerlink" title="如何优化神经网络（Optimization）"></a>如何优化神经网络（Optimization）</h1><p>优化（Optimization）一直是人类领先于其他生物而在环境中不断成长的重要因素，机器也不例外，通过优化的方式自我更新才能不被复杂的环境所淘汰。</p>
<h2 id="神经网络梯度下降算法（Gradient-Descent）"><a href="#神经网络梯度下降算法（Gradient-Descent）" class="headerlink" title="神经网络梯度下降算法（Gradient Descent）"></a>神经网络梯度下降算法（Gradient Descent）</h2><p>神经网络能够自我学习自我更新不仅仅归功于它能够学习并记忆输入和输出的规律，最重要的是它能够根据学习的规律进行自我调整以让自身适应这个变化的环境。那么机器学习模块又是如何进行优化的呢？答案就是所谓的<strong>梯度下降</strong>了。</p>
<ul>
<li>先前说过神经网络的自我调整是基于结果的反馈，也就是所谓的误差来修正自己：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost = {(predicted - real)^2}" style="border:none;"></p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/jwReIP2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Cost函式表达的结果近似可以看成一条平滑的二次曲线，而在更高纬度的层面上就是一个<strong>弯曲的面</strong>，越是接近曲面的底部，误差的Cost就会越小。而梯度下降（Gradient Descent）就是在这个曲面中通过微分的方式找到一个能够向最低点移动的方向，并以此作为动力开始优化自己。当达到最低点时，求导的结果和二次曲线相切，这个时候梯度就消失了，也就是所谓的最佳化状态。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/RGjpuX3.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>然而按照理论而言，这样的方式也太容易得到想要的结果了，那么神经网络的优化（Optimization）也太神了吧，其实这一切是<strong>很难实现</strong>的。</p>
</li>
<li><p>不同于之前所看到的梯度下降曲面，我们生活中的信号往往需要有许多的维度来表示，尤其是复杂的信号（例如图片或者文字）。这些信号在低纬度的时候几乎无法将他们区别分类，因此我们只能将他们丢到更高的维度上面进行非线性分割。这时候就会存在一个问题了，随着维度的提高，我们所熟知的曲面渐渐变得不再平滑了：</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3UNJkcZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这样的曲面反映出一个关键问题就是<strong>优化的不确定性</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/4PmjIUv.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>在多维的复杂曲面中，我们能够找到不止一个梯度消失的点，而这些至低点并不都是我们所谓的<strong>最优解</strong>。当我们初始化的位置不同，我们的结果就会随着梯度下降（Gradient Descent）的优化模式寻找距离自己最近的一些至低点。如此一来<strong>不同的初始值</strong>就会很大程度上影响我们优化的结果。针对这个问题，目前比较好的解决方式就是给信号加上一个 <strong>动量（Momentum）</strong> 以至于在运动至最低点的时候，动量会趋势信号的Cost继续改变（此时梯度又恢复了）。如果我们设定的动量足以让信号摆脱当前的梯度曲面（说明曲面不够深，也就是所谓的局部最优解），信号就会继续去寻找一个更加<strong>难以摆脱的梯度曲面（更深）</strong>，如此一来就能够尽量靠近<strong>全局最优解</strong>。</li>
</ul>
<h1 id="如何评估神经网络的优越性"><a href="#如何评估神经网络的优越性" class="headerlink" title="如何评估神经网络的优越性"></a>如何评估神经网络的优越性</h1><p>机器学习的过程中，神经网络往往会存在一些问题，例如学习效率低，学习误差（loss）变化幅度摇摆不定，或是因为杂讯和信号太多没有办法找到有效的规律和结论。而这些问题可能来自<strong>数据</strong>、<strong>参数</strong>以及<strong>模型结构本身</strong>等各方面的因素。</p>
<h2 id="数据集评估"><a href="#数据集评估" class="headerlink" title="数据集评估"></a>数据集评估</h2><p>在评估数据和模型的吻合度上，我们需要对数据进行一个初步的认知，也就是确定数据集和结果之间的特征关系，也就是所谓的<strong>Features</strong>。这些Features能够很大程度地影响神经网络的学习效率。</p>
<ul>
<li>传统的机器学习算法通常会通过采用 <strong>Cross-Validation</strong> 的方式来对数据进行评估。也就是现将数据集依照6:2:2（不固定）的比例进行拆分，分别表示为<strong>训练集（Training Data）</strong>、<strong>验证集（Validating Data）</strong> 和 <strong>测试集（Testing Data）</strong> 三个部分。</li>
</ul>
<p>评估模型最终结果的好坏往往是测试集决定的，这里面会有训练的时候不曾出现过的输入信号，这也是对神经网络效能的一个<strong>考验</strong>。而要在学习的过程中让学习训练集的模型意识到不单单是要学好那些见过的部分，<strong>没见过的部分</strong>也需要充分地准备，这时候就会用到验证数据集的检验了。在训练完毕之后，我们重新划分3个资料集的比例和分布，就可以重新定义出新的训练资料了。在不断变换数据集的同时，我们可以对模型的<strong>参数进行更加科学的优化和分析</strong>。</p>
<ul>
<li>评价机器学习的方式（Evaluation Function）包括了<strong>误差（Error或Loss）</strong> 以及 <strong>精确度（Accuracy）</strong>，误差就是预测结果和实际结果的差值，而精确度就是在预测过程中的正确率了。</li>
</ul>
<p>有的时候在训练的时候往往结果让人满意，可是到了测试的时候结果却不尽人意，这又是为什么呢？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/BbwFVzg.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>原来在训练过程中，神经网络太过优秀了，以至于它将自身优化成为了完全符合这个输入数据的一个模型。而一旦我们测试的输入和训练样本差别很大，就会让模型无从下手，这种现象就是所谓的过拟合（Overfitting）。</p>
<ul>
<li>比较常用来解决Overfitting的方式为<strong>Dropout</strong>，也就是在训练的过程中随机舍弃掉一些数据，从而让自己的模型留有一些变通的空间，来适应突发的情况。</li>
</ul>
<h1 id="为什么要对特征进行标准化（Normalization）"><a href="#为什么要对特征进行标准化（Normalization）" class="headerlink" title="为什么要对特征进行标准化（Normalization）"></a>为什么要对特征进行标准化（Normalization）</h1><p>现实中的数据可能来自不同的地方，不同来源的数据有各自的取值范围。而在学习的过程中，这些取值范围往往<strong>差距悬殊</strong>，这样就会对训练产生障碍。想象一下，如果我们两个权重矩阵M1和M2,我们给M1一个三位数量级的输入参数，给M2一个一位数量级的输入参数，会发生什么事情呢？答案很明显，当我们改变M1的参数时，对于总体的影响是十分巨大的，而相比之下想要达到这样的差距，就必须对M2进行很大幅度的调整。</p>
<h2 id="如何标准化"><a href="#如何标准化" class="headerlink" title="如何标准化"></a>如何标准化</h2><p>延续之前的例子，如果这时候的误差值是：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Error = {predicted - real}" style="border:none;"></p>
<p>那么对这个误差我们应该确保对所有的权重矩阵（Weight Matrix）具有类似的跨度。</p>
<p>通常用于标准化（Normalization）的方法有两种：</p>
<ul>
<li><p>一种是<strong>最小-最大标准化（Minmax Normalization）</strong>。它会将所有的数据按照一个缩放比例转换到0和1的区间中。对单独的特征而言，这个权重是唯一的（全局适用）。</p>
</li>
<li><p>另一种方法是<strong>标准正规化（Standard Normalization）</strong>。它会将所有数据转换成平均值为0，标准差（Std）为1的数据。</p>
</li>
</ul>
<p>这样的标准化问题不但能够平衡数据间的波动和差异，还能提高学习的效率，让机器学习能够正常地平衡每一个特征变数的优化和调节。</p>
<h1 id="什么是批标准化（Batch-Normalization）"><a href="#什么是批标准化（Batch-Normalization）" class="headerlink" title="什么是批标准化（Batch Normalization）"></a>什么是批标准化（Batch Normalization）</h1><p>Batch Normalization和传统的正规化方式类似，都是为了将分散的数据统一成为一定的样式，也是优化机器学习的一种方法。之前讨论过为什么要对数据进行标准化，为的就是让训练的参数不特别偏袒某一个数据。从而让机器更好地学习多元的规律。</p>
<p>回忆之前的内容，我们为什么需要在输入的时候对我们的数据进行标准化呢？</p>
<ul>
<li>那是因为在训练过程中神经网络对偏差较大的数据很难平衡他们的权重。试想一下如果一个输入为1而一个输入为20：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/IVXm2jw.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>在经过一层神经网络运算之后，由于激励函数的关系两者的值会被投射到特殊的函数空间中，这个时候数据的差异就凸显了出来。以tanh为例，1的输入经过tanh计算后取值处于tanh函数的敏感部分（梯度最大）。而大数值20经过tanh计算后反而位于不敏感的部分（几乎水平）。这个时候的值对于神经网络而言已经不再重要了，因为无论怎么变化其数值也不会相差太多。就像是轻轻拍一下自己和重重打一下是一个感觉，这样的结果对于神经网络是致命的。</p>
</li>
<li><p>那么既然我们对输入层的网络进行了正规化（Normalization），那么又为何需要batch normalization呢？</p>
<ul>
<li>原来在hidden layer的部分也会存在这个问题，因为神经网络的隐藏层也同样使用了激励函数。</li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/NtDiKCR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>这个时候我们就是用Batch Normalization的方式将数据分成几个大小相同的Batch进行训练，在每次经过神经网络的全连接之后进行一次正规化，然后才送入激励函数中进行计算。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Hbz5FPL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>对于激励函数（Activation Function）而言，最佳的数据传递范围是下图红色的区域，也就是所谓的<strong>敏感区</strong>。而位于这些区间的数据更容易被传递到下一层网络中。而正规化的目的就是让更多的数据集中在这个敏感区中，这样可以防止数据呈现<strong>两极分化</strong>的状态，让神经网络的训练更有价值。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Ln2ehrr.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>与神经网络的反向传递类此，在进行了正向传递的正规化之后，我们会将结果利用一个线性的方式反向传递回来，这种方式为的是让机器自己学习正规化的有效程度，从而自我修正和改变。就相当于在神经网络中嵌套了另一个神经网络用以训练前一个神经网络的更新能力。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/J5f7DAa.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通过对比没是否有Batch Normalization的结果我们发现，Batch Normalization能够让训练过程中的数据更加具有连续性，同时也让数据在每层神经网络之间能够更好地传递下去。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TMKMdn4.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="如何判断特征的的好坏"><a href="#如何判断特征的的好坏" class="headerlink" title="如何判断特征的的好坏"></a>如何判断特征的的好坏</h1><p>机器学习的过程中，特征是我们的模型训练和测试的重要参照指标，好的特征往往能使得模型快速拟合资料的分布，也就能取得更好的预测结果。那么什么样的特征是真正有用的特征（Features）呢？</p>
<p>在分类问题中，没用的特征会为我们的分类带来不必要的计算和误导，以 <code>Iris Corpus</code> 为例。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/SwuicOP.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/nuEIhHL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>以花萼宽度的特征来看，两种花的分布大概能够满足如下的分布状况：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/aDkQTg8.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>可以看出在该特征的情况下，两种花的特征分布呈现一种趋于平衡的关系，如此就可以判断光凭这种特征是很难将花的品种区分开来的。因此我们称这样的特征为无意义的特征（不好的特征）。</li>
</ul>
<p>此外，如果我们改变特征的选取，转而采用 <strong>花瓣长度</strong> 来作为评判的特征，那么会如何分类呢？</p>
<ul>
<li>我们利用Python的可视化library <code>Matplotlib</code> 来观察特征的变化情况吧。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line">setosa, versicolor = 500, 500</div><div class="line">setosa_length = 1.5 + 0.4 * np.random.randn(setosa)</div><div class="line">versicolor_length = 4.5 + 1.2 * np.random.randn(versicolor)</div><div class="line"></div><div class="line">plt.hist([setosa_length, versicolor_length], stacked = True, color = [&apos;r&apos;, &apos;b&apos;])</div><div class="line">plt.xlabel(&apos;Petal Length&apos;)</div><div class="line">plt.ylabel(&apos;Numbers&apos;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/3DQQEpE.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>从图中可以看出，当花瓣长度大于等于3之后，我们基本可以断定这种花就是versicolor，相反当花瓣长度小于3的时候，我们就可以很大程度上断定花的种类就是setosa。这样能够明显区分不同事物的特征就是所谓的好的特征。</p>
</li>
<li><p>另外，当一种特征在特定的取值上难以区分类别的时候，我们就需要其他新的特征来辅助我们判断事物的种类，这也就是神经网络的特征集合的作用所在了。</p>
</li>
</ul>
<p>特征压缩的方式有很多，常用的包括之前提及的 <strong>Auto-encoder</strong> 等。总而言之，想要得到好的特征信息，我们就需要遵循以下几点：</p>
<ul>
<li>避免无意义的信息。</li>
<li>避免重复性的信息。</li>
<li>避免复杂的信息。</li>
</ul>
<h1 id="什么是激励-刺激函数（Activation-Function）"><a href="#什么是激励-刺激函数（Activation-Function）" class="headerlink" title="什么是激励/刺激函数（Activation Function）"></a>什么是激励/刺激函数（Activation Function）</h1><p>Activation Function是人工神经网络中的一个重要环节，想要探讨它的重要性，那么首先就需要知道为什么我们的神经网络离不开这个结构呢？其实在神经网络的训练过程中，许多问题我们往往无法用单纯的线性方式解决。这时候我们就需要借助Activation Function的帮助了。</p>
<p>那么什么样的模型表示才是线性的呢？</p>
<ul>
<li>所谓的线性方程（Linear Function）就是能够用一条直线反应出模型的变化趋势。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/B3t3yoO.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>比方说随着商品人气的升高，销量也持续不断地上涨。然而并不是所有喜欢这个商品的人都会购买它，因此在销售达到饱和的时候，即使人气还在不断上升，但是销量的增长却开始变慢，这个时候我们就无法用线性的方式表示这个趋势了。因此我们便会选择非线性的方式（NonLinear Function）表示我们的模型变化：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ShtfdUk.jpg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们可以用一个式子来统一描述神经网络的流程：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y = Wx" style="border:none;"></p>
<ul>
<li>而这个时候的模型就是线性的，我们需要借助Activation Function的力量来 <strong>“掰弯”</strong> 这个线性的模型。</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y = AF(Wx)" style="border:none;"></p>
<ul>
<li>新的模型表示式中的 <strong>AF</strong> 就是我们的Activation Function。其实 <strong>AF</strong> 的作用并没有想象的那么奇幻，它就是一些非线性方程的集合：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/m3ozi0z.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>通过非线性方程的转换，就可以把连续的输入信号在不同时刻进行不同程度的改变，使它们之间不再遵从线性关系的约束。</p>
</li>
<li><p>当然我们可以使用的Activation Function远不止上面的那些，我们甚至可以自己创造适合我们模型的激励函数。但是重要的一点是，这些函数必须是 <strong>可微分</strong> 的，也就是可以通过求导得到相应的梯度。原因是我们之后的Optimization的过程中会使用反向传递的方式更新模型的参数，而反向的核心步骤就是对<strong>原方程微分</strong>，这样才能完整地把误差传递回模型。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/wVrzICJ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如何选择合适的神经网络是训练一个好的模型的重要先决条件。那么应该怎么选择适度的Activation Function呢？</p>
<ul>
<li>在小的模型中，<strong>激励函数</strong>的影响往往没有那么明显，因此我们不需要做太多的考虑。相比之下在大型模型中，由于曾与曾之间的传递复杂度高，因此草率地选择Activation Function会导致<strong>梯度消失</strong>、<strong>梯度爆炸</strong>等问题。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/7vHMPnX.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>一些常见的神经网络结构推荐使用的激励函数也不同，这些关系到模型的特性和实际的应用场景。在CNN中我们推荐使用<strong>Relu</strong>作为层级之间的激励函数；而在RNN中我们则推荐使用<strong>Relu或者Tanh</strong>作为激励函数。</p>
<h1 id="什么是模型过拟合（Overfitting）"><a href="#什么是模型过拟合（Overfitting）" class="headerlink" title="什么是模型过拟合（Overfitting）"></a>什么是模型过拟合（Overfitting）</h1><p>在训练神经网路的过程中，我们有时会遇到这样的情况：在训练过程中我们对训练资料和预测结果的比对发现，模型的拟合效果非常优秀（也就是Accuracy很高）。而在我们使用测试资料再次试探我们的模型时，发现结果却不尽人意。这时候很可能的情况就是出现了<strong>过拟合（Overfitting）</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/lUfqDIv.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>以一个例子而言，通过机器学习训练后，我们可以用一条回归直线表示空间中分布的输入信号，这时候的误差范围取决于离直线最远的点。但是如果我们的机器仍不满足这个误差，想要继续降低它的时候，就会出现这个情况：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/xG5ZxCh.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>这时机器改变了原来的拟合线，转而开始依次调整每个点的距离，让回归线不再只是一条直线，而是一条设法穿过每一个点的曲线。这个时候的拟合度固然很高，但是却让模型变得越发不灵活。如果用在测试数据上，那么曲线比起原先的直线就<strong>更难拟合新的数据</strong>，这就是Overfitting的根本原因了。</p>
</li>
<li><p>在分类问题上的过拟合主要体现在曲线完美区分所有的数据点（下图圆点），这个时候加入新的数据（下图十字）后发现曲线很难将他们完全区隔开来，这种模型不是我们想要获得的。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/KSIz2uL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>那么既然过拟合会对模型的预测带来影响，要避免它的发生我们又应该怎么做呢？</p>
<p>缓解Overfitting的方式有这么几种：</p>
<ul>
<li>首先就是<strong>增加</strong>数据量</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/PSe3Gt2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>随着数据量的增加原先过拟合的曲线也会慢慢变得<strong>平滑</strong>起来，能够覆盖的范围就变大了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/TsJRH9M.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>其次就是利用正规化（Regularization）</li>
</ul>
<p>主要用于解决机器学习过拟合的正规化方法包括了 <strong>L1</strong> 和 <strong>L2</strong> 正规化。</p>
<p>针对机器学习，我们之前将这个过程简化成：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large y = Wx" style="border:none;"><br>而其中的 <strong>W</strong> 就是我们模型所要学习的参数，过拟合的出现就是模型对于 W 的值进行了太大幅度的调整。为了避免这个问题，我们会对这个变化进行一个惩罚，也就是约束的机制。原始的误差<strong>cost</strong>为：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large cost = (Wx - real y)^2" style="border:none;"><br>如果 W 变化太大，我们就让cost也跟着变大，也就是 L1 正规化：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large cost = (Wx - real y)^2 + abs(W)" style="border:none;"><br>L2 正规化和L1类似，只是在惩罚项的不同：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large cost = (Wx - real y)^2 + (W)^2" style="border:none;"><br>用这些方法我们就可以保证得到的模型曲线不会因为数据的关系而变得那么扭曲。</p>
<ul>
<li>最后是一种经常用在神经网络训练过程中的方式，叫做Dropout Regularization。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/YqPvzph.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在训练过程中，我们选择每次都忽略掉一些神经网络的神经元（Neuron）来使得我们的结果不会每次都过分依赖所有的数据信息，这样训练出来的模型就不容易出现Overfitting的情况。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/AkPuOK7.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<h1 id="L1-L2正规化"><a href="#L1-L2正规化" class="headerlink" title="L1 / L2正规化"></a>L1 / L2正规化</h1><p>之前提到了过拟合的问题会对模型的预测造成影响，模型往往会通过使用更精密的参数（指数更高的项）来拟合数据。而这些参数的数据虽然能够让模型更好地贴近测试数据，但是却无法灵活地反应测试数据以外的其他数据。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/CgZCB5l.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>图中比起红色的曲线，我们更希望通过蓝线来概括回归的特性。为了能够让模型不会学的那么“完美”，我们就会选择使用L1、L2正规化来约束神经网络参数的更新。</p>
</li>
<li><p>训练的过程中我们利用反向传递的误差来调整参数，而误差的值反应为：</p>
</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost(\theta) = [Y\theta(x) - Y] ^ 2" style="border:none;"></p>
<ul>
<li>L1、L2正规化就是在这个误差的情况下多加上了一个误差，也称作<strong>对真实结果的惩罚:</strong></li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost(\theta) = [Y\theta(x) - Y] ^ 2 + [\theta1 ^ 2 + \theta2 ^ 2 + ...]" style="border:none;"></p>
<p>或</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost(\theta) = [Y\theta(x) - Y] ^ 2 + [|\theta1| + |\theta2| + ...]" style="border:none;"></p>
<p>通俗的来说现在我们的误差不再是我们理解中的结果和真实值得差距了，还包括了<strong>新的误差项</strong>，也就是那些用来拟合的参数所拥有的<strong>权重大小</strong>。如果是对平方项的惩罚就是L2正规化，如果是绝对值则是L1正规化。</p>
<ul>
<li>那么这些惩罚又能对结果产生怎么样的影响呢？以L2正规化为例：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/VoTanaV.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>在训练过程中，通过减小误差来优化我们的神经网络，而其中<strong>非线性越强（指数越大）的参数</strong>往往会修改的越多。因为曲折的线条往往才是分离局部误差的关键，这个时候非线性强的项次就会凸现出来。而误差方程中的惩罚项此时就会对这个情况作出反击。在它看来，所有的指数项共同组成了一个团队，如果光是依靠那些能力强的参数改变效能是十分危险的，如果它们做错了，那么结果可能会非常糟糕。因此惩罚就是一个<strong>限制两极分化</strong>的最好途径。</p>
</li>
<li><p>在抑制过拟合的情况下，L1、L2正规化的优劣也各有不同：</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/0LrM13H.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>图中是我们模型的试图，假设此时只有横纵坐标两个输入特征，而蓝线表示我们学习的梯度曲线（等高线）。越靠近中心越是拟合原来的结果，误差就越小。而正规化的<strong>惩罚项</strong>就是图中粉色线条表示的区域，平方表示圆，而绝对值表示直线。这个时候模型为了保证两边的误差最小，那么就是求解<strong>两个曲面的交点位置</strong>。这样一来模型就不会一直向着蓝线梯度的中心点直奔而去了。</p>
</li>
<li><p>不难看出，使用L1正规化的时候，我们很可能得到的结果是坐落在某一个坐标轴上，此时其他坐标的特征就消失了。因此我们可以利用这一点来选择<strong>对结果贡献度最大的特征</strong>。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/YxQjCm7.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>但是L1的结果相对L2正规化而言较不稳定。如上图所示，我们训练的过程中梯度的变化时常发生，这个时候L1正规化可能会存在<strong>不止一个</strong>相对距离最短（也就是误差最小）的点。这也侧面说明了L1正规化的优化不稳定的问题。</p>
</li>
<li><p>为了控制正规化的强度会加入一些限制参数来平衡这个惩罚机制的强弱。</p>
</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost(\theta) = [Y\theta(x) - Y] ^ 2 + \lambda * \Sigma\theta i ^ p" style="border:none;"></p>
<ul>
<li>我们会利用Cross Validation的方式来训练和选取最佳的参数，从而得到更好的正规化结果。</li>
</ul>
<h1 id="如何加速神经网络"><a href="#如何加速神经网络" class="headerlink" title="如何加速神经网络"></a>如何加速神经网络</h1><p>不难想象，越是复杂的神经网络结构和越大的数据量，就会让神经网络的训练过程花费更多的时间。原因是计算量和复杂度太高了，可是在解决一些复杂问题时，我们所需要的结构恰恰又是以这样的形式出现，因此我们就需要一些特殊的方法来让神经网络的训练得到 <strong>优化和提升</strong>。</p>
<p>最基础的方法叫做SGD（Stochastic Gradient Descent）</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/MmdFv9K.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>未经SGD优化过神经网络训练通常是把整个资料集重复不断地全部喂给网络训练，这样在每次训练中消耗的资源会很大。通过SGD的优化后我们选择将整个资料集分成几个部分，一次将资料的一部分放入神经网络进行训练。虽然这样无法反应整体的资料特性，但是却能加速训练过程，同时保有相当高的准确率。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FXzK4yZ.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>除了SGD以外，还有一些神经网络的优化方式能够通过优化神经网络的参数，从而达到加速训练的效果。</p>
<ul>
<li>传统的参数更新方法是利用误差的反向传递，让参数的误差值乘上一个学习效率来进行更新的：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large W += -Learning\ rate * dx" style="border:none;"></p>
<p>而这种方法会让收敛的过程曲折无比，就像是一个喝醉的人摇摇晃晃地行走一般，在到达目的地的过程中往往需要走许多弯路。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Hkf06zD.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>为了防止这种不必要的更新误差，我们会选择使用 <strong>动量（Momentum）</strong> 的形式来优化误差更新方法。</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large m = b1 * m - Learning\ rate * dx" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large W += m" style="border:none;"></p>
<ul>
<li>动量的使用就仿佛给这个误差一个 <strong>向下冲的初始速度</strong>，让他在前进的时候有一个<strong>惯性</strong>的作用。打个比方也就是原先喝醉酒的人走到了一个下坡，他就会改变摇晃的行走方式，转而变成拥有向下冲的一个趋势。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/JPj4brY.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>与动量（Momentum）类似的优化方式还包括 <strong>AdaGrad</strong>，这种优化的方式是通过给予参数优化一个限制，让他在学习的过程中因为走弯路而受到一定的惩罚，从而减少这种行为的发生。</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large v += dx ^ 2" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large W += {-Learning\ rate * dx \over \sqrt{v}}" style="border:none;"></p>
<ul>
<li>AdaGrad的形式就仿佛给喝醉酒的人一双鞋子，在他摇晃前行的过程中由于鞋子的摩擦而脚疼，从而让他避开这种行走方式，转而走直线。</li>
</ul>
<p>那么不妨试想一下如果将动量和AdaGrad两者<strong>结合</strong>起来，效果是不是会更好呢？的确，结合了两者的方法被称为 <strong>RMSProp</strong>。</p>
<ul>
<li>RMSProp结合了两者的优势，从而共同优化神经网络的参数计算：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large v = b1 * v + (1 - b1) * dx ^ 2" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large W += {-Learning\ rate * dx \over \sqrt{v}}" style="border:none;"></p>
<ul>
<li>而在RMSProp保留两者的有点过程中，神经网络由于动量的加速和AdaGrad的惩罚限制，变得能够走出较为理想的直线了。但是可能不难发现，在结合两个优化形式的过程中，RMSProp似乎并没有完全地将二者进行合并，从公式中可以看出，它似乎抛弃了重复的学习更新作用项 <strong>dx</strong>。</li>
</ul>
<p>而 <strong>Adam</strong> 的优化方式则完全融合了动量（Momentum）和AdaGrad的数学形式，将他们完全融入神经网络的训练优化参数的过程中来。</p>
<ul>
<li>Adam的参数学习率公式如下：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large m = b1 * m + (1 - b1) * dx" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large v = b2 * v + (1 - b2) * dx ^ 2" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large W += {- Learning\ rate * m \over \sqrt{v}}" style="border:none;"></p>
<ul>
<li>就这样，在计算m时将动量优化考虑进去，在计算v时将AdaGrad优化考虑进去，而在最后计算参数的时候将m和v一起考虑进去，这样就能将两者完全结合近神经网络的优化过程中了。</li>
</ul>
<p>事实证明在大多数神经网络的训练过程中，<strong>Adam Optimizer</strong> 都能让网络迅速收敛，达到目标。</p>
<h1 id="如何处理不均衡数据"><a href="#如何处理不均衡数据" class="headerlink" title="如何处理不均衡数据"></a>如何处理不均衡数据</h1><p>如果在分类问题中，我们可能会遇到这样的情况：绝大多数的数据Label都偏向于其中的一种类别，而另外一种或是多种类别的成员数量则远远小于它。这样的数据就是我们说的<strong>不均衡</strong>的数据了。</p>
<p>用不均衡数据训练出来的模型思考模式很简单，永远都是猜多的那一方正确几率比较高，久而久之机器就学乖了，总是预测多数派的情况，这样的训练结果往往不是我们希望看到的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FPxoNvj.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>那么面对这样的数据要如何训练呢？</p>
<ul>
<li><p>第一种方式是对数据进行分层统计：一般情况下神经网络的训练集分布多为均匀分布，但是也可能存在一些特例，像是一开始比例不均匀，一边很大而另一边则很小的情况。这时候一开始的训练结果往往就会是我们说的不均衡情况，但是如果我们能够找到后阶段的数据集刚好相反的分布，那么就会让我们模型慢慢回归正常的预测模式。也就是所谓的以长远的目光看待数据。</p>
</li>
<li><p>第二种方式是改变评估的方式：通常我们会用到的评估数据模型的参数有 <strong>准确率（Accuracy）</strong> 和 <strong>误差（Cost）</strong>，但是这些评判标准换到了一个不均衡的数据中来看就显得不那么重要（因为大多数情况都是正确的，而且误差几乎为0）。因此我们选择更换我们的评估模式，改成使用Confusion Matrix来计算 <strong>精确率（Precision）</strong> 和 <strong>召回率（Recall）</strong> ，然后再利用这两者计算出 <strong>F1 Score（F-score）</strong>。</p>
</li>
</ul>
<p>以一个例子来说，假定我们的正类有10个，负类只有4个，此时我们的预测结果为10个正类被判断为10个正类，4个负类被判断为2个正类和2个负类。那么通过Confusion Matrix我们可以计算出TP（正类别猜正类别）、FP（负类别却猜是正类别）、TN、FN四个值。TP = 10，FP = 2，TN = 2，FN = 0;这时候的：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Precision = {TP \over {TP + FP}} = 0.833" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Recall = {TP \over {TP + FN}} = 1" style="border:none;"></p>
<p>因此F1 score可以表示成：</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large F1 = {2Precision * Recall \over {Precision + Recall}} = 90.9\%" style="border:none;"></p>
<ul>
<li><p>第三种方式就是重新组合数据，让数据保持均衡分布。例如砍掉一些数量较多的资料，让二者的数量保持在一个稳定的比例上，或者利用复制和组合的方式增加少数类别的资料数量，使他们比例重新稳定。</p>
</li>
<li><p>第四种方式是使用其他的机器学习方法：</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/az5MoF1.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>在面对不均衡的数据时，神经网络通常是束手无策的，而相比而言一些传统的机器学习算法则能够不受资料集的影响，从而做出正确的判断，比如决策树（Decision Tree）。由于在决策的过程中依赖的是输入数据的特性而非分布情况，因此决策树能够准确地对资料做出分类判断。</p>
<ul>
<li>最后的方式是改变传统的算法：</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/t4IyMmy.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>传统的激活函数算法有一个比较平衡的门槛值作为分类的区隔条件。例如sigmoid函数会以x = 0作为分界线，左边的分布为Label1，而右边的分布则为Label2。但是由于此时资料分布不均衡的情况下，导致坐落在右边的几率大大升高。那么我们就会对这个门槛值进行一个调整：</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ajk0WzL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如图所示，增大门槛值的x坐标，让他只有在<strong>极端条件</strong>（Y十分接近1）的时候才会判定为右边的分类结果（也就是概率较大的Label）。这样我们就能够比较完美地对预测进行一个权衡。</p>
<h1 id="强化学习（Reinforcement-Learning）"><a href="#强化学习（Reinforcement-Learning）" class="headerlink" title="强化学习（Reinforcement Learning）"></a>强化学习（Reinforcement Learning）</h1><h2 id="什么是强化学习"><a href="#什么是强化学习" class="headerlink" title="什么是强化学习"></a>什么是强化学习</h2><p>强化学习是一种让计算机自我学习的算法总结，是让计算机通过自己对环境的不断尝试和探索自我修正并适应的一个过程。有些时候（尤其是在复杂环境中）这样的学习方式比起人为的干预来得更为有效。</p>
<p>那么强化学习又是如何进行的呢？</p>
<ul>
<li><p>原来在计算机学习的过程中也需要以为好的导师。然而这位导师不会手把手告诉计算机应该如何行动，他的存在只是为计算机尝试的每一个行为进行<strong>打分（评价好坏）</strong>。因此计算机只需要记住那些能够得到较高分数的行为序列就能够在环境中更好地生存下去。</p>
</li>
<li><p>换句话说，强化学习就好比是机器自己在环境中手无寸铁地摸索，然后收集信息进行总结，最后得出结论并自我更新的过程。而这些在尝试中得到的信息就会成为我们所谓的监督式学习的数据了（Data &amp; Labels）。</p>
</li>
</ul>
<h2 id="强化学习的应用"><a href="#强化学习的应用" class="headerlink" title="强化学习的应用"></a>强化学习的应用</h2><ul>
<li><code>Alpha Go</code></li>
<li><code>Video Game</code></li>
<li><code>Image Recognition</code></li>
<li><code>Chatbot</code></li>
<li><code>Robot Controller</code></li>
</ul>
<h2 id="强化学习常见算法"><a href="#强化学习常见算法" class="headerlink" title="强化学习常见算法"></a>强化学习常见算法</h2><ul>
<li><p>通过价值（Reward）选择行为：</p>
<ul>
<li><code>Q Learning</code> </li>
<li><code>Sarsa</code> </li>
<li><code>Deep Q Network</code> </li>
</ul>
</li>
<li><p>直接选择行为：</p>
<ul>
<li><code>Policy Gradients</code></li>
</ul>
</li>
<li><p>自我假象环境并从中学习行为：</p>
<ul>
<li><code>Model based RL</code></li>
</ul>
</li>
</ul>
<h3 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q Learning"></a>Q Learning</h3><p>我们在现实中的行为都会有一个标准的规范，例如：父母常说的不写完作业就不能看电视。</p>
<p>Q Learning的方式和决策树（Decision Tree）类似，都是在一个特定的情形下对不同的决策进行概率的计算，然后继续延伸到下一个分支。每一个时刻的模型都可以用time state machine来表示。</p>
<ul>
<li>以上面的例子来说，假设现在处于写作业的状态，这个时候我们的环境告诉我们可以选择的行为是：1、继续写作业 2、去看电视。这个时候因为模型从未尝试过任何一个选择，它可能会选择看电视，然后继续看电视。就这样让状态一直走下去，直到被父母责骂后，环境就会反馈一个<strong>负面的分数</strong>（也就是被惩罚）。这个时候模型深刻理解了这一系列的动作产生的后果是让自己被环境淘汰，因而它会极力去改变这样的结果。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/uSSj0Ub.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Q Learning通过一个数据表（Table）来保存每一个state下获得的<strong>价值分数</strong>，而这些分数会随着每一次环境反馈的R（Reward）而做出改变。此时我处在写作业的state，而经过刚才的经验我得知了写作业比看电视带来的潜在收益更大一些，而此时Q表中记录的就是两个选择所带来的价值分数了，显然（S1，a1）小于（S2，a2），因此我决定选择写作业。一次迭代循环也就构成了Q Learning的学习过程。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/Qy0mM0S.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>了解了正向的决策过程，那么Q Learning的Table又是如何更新的呢？</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/5nU4opI.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>学习过程最开始的时候，我们会对Q表进行一个初始化，对每一个状态下的所有行为进行一个估计的价值分数。而此时状态为S1的时候，我们通过初始化的价值分数进行第一步行为的决策，然后到达S2状态。此时我们需要<strong>通过S2的状态好坏来给予S1的行为一个反馈</strong>，此时我们会假象自己选择了S2的不同行为，并得到了相应的奖励R。这个时候我们就能够通过：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Real(S1, a2) = R + \gamma * max(S2)" style="border:none;"></p>
<ul>
<li>来得到S1在环境反馈后真实的价值分数，这个时候就能够通过计算误差：</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Cost = Real(S1, a2) - Estimate(S1, a2)" style="border:none;"></p>
<ul>
<li>然后利用类似于Back-Propagation的方式将误差传递回去，进而利用学习效率更新原有的价值分数。</li>
</ul>
<p><strong>Tips</strong>：如果此时的S2并不是最终的结果，而且使用的Q Learning由限定为回合更新的话，那么此时的R并不会在这个时刻体现出来。因此S1更新所需要的Real（S1，a2）会来自之后所有state的结果总和，也就是一个<strong>迭代</strong>的过程。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ChJhgaL.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>以上是Q Learning的算法，可以看出Q Learning的神奇之处在于它将当前获得的奖励和下一步行为（也可以理解为衰减）的最大估计作为当前的现实。</p>
<p>公式中的参数：</p>
<ul>
<li><p>ε-greedy是一个调变参数，例如当ε = 0.9时，我们就会有90%的概率根据Q表的最佳解法进行行为选择；而10%的概率会随机选择行为。这样能让模型在拟合的同时还<strong>不忘探索更好的方法</strong>。</p>
</li>
<li><p>α是一个学习效率，介于0和1之间，能够调控当下对于误差的学习率。</p>
</li>
<li><p>γ则是对未来奖励的一个衰减值。假设我们的Q表分成很多个States，那么从第一个State开始就会累积今后的Reward值：</p>
</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Q(S1) = r2 + γQ(S2) = r2 + γ[r3 + Q(S3)] = ... = r2 + γ*r3 + γ^2r4 + γ^3r5+..." style="border:none;"></p>
<p>就如下图所示:</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gh6GdXl.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>因为γ是一个介于0和1的值，那么不妨想象一下这个时候的γ = 1，此时所有的r都被保留了下来，因此我们的模型就会考虑到当下行为对所有未来的状态所获得的奖励。另外如果γ = 0时，此时只有r2还存在，我们的模型就只考虑到下一步行为对此刻造成的奖励而已。以此类推，γ &lt; 1可以得知越往后的奖励对当下的行为决定得越浅，因此γ也被称为奖励的<strong>衰减值</strong>。</p>
<h3 id="Sarsa"><a href="#Sarsa" class="headerlink" title="Sarsa"></a>Sarsa</h3><p>强化学习中的Sarsa和Q Learning十分相近。Sarsa也是通过Q Table中的值来对下一步的行为做出估计的，数值越大行为的可能性就越大，Sarsa也是通过这种方式来从环境中获得Rewards的。与Q Learning不同之处在于它们对模型的<strong>更新方式</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/pU6baAu.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>与Q Learning不同的是，Sarsa在Q现实的计算过程中，不是通过<strong>潜在收益</strong>最大的奖励方式而选择行为的，而是基于<strong>当下最优条件</strong>来选择行为（去除max运算）。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8OHw8XD.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>从算法中可以看出除了去除了max的估计运算外，Sarsa和Q Learning几乎没有差别。而就是因为Sarsa这种 <strong>“说到做到”</strong> 的特点，它也被称为<strong>On-Policy（在线学习）</strong>；而Q Learning则被称为<strong>Off-Policy（离线学习）</strong>。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/5xTVSt2.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>有了MaxQ的运算辅助，Q Learning会根据最终奖励回传的潜在Rewards来估计当前的结果好坏，所以即使当前行为的分数是最高的，但是考虑到了潜在奖励的关系，模型可能还是会放弃选择该行为。而Sarsa相反则永远都是选择当前分数最高的行为来作为下一次的选择，进而一步步逼近结果。这样看来Q Learning在学习的过程中仍会尝试一些相对危险但是它认为可行的方法，因为它想要得到的永远是<strong>最佳解</strong>，而Sarsa则是尽可能地回避一切风险<strong>稳步求胜</strong>。</li>
</ul>
<h3 id="Sarsa-λ"><a href="#Sarsa-λ" class="headerlink" title="Sarsa(λ)"></a>Sarsa(λ)</h3><p>按照对模型的更新方式可以分为 <strong>单步更新</strong> 和 <strong>回合更新</strong>。而传统的Sarsa属于单步更新的模式，也就是只有得到奖励的那一次更新能够得到来自当前奖励的Reward，然后更新最后一个步骤，以此类推慢慢往前移动。显然这样的更新是很<strong>没有效率</strong>的。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/o1byGZm.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果选择回合更新的方式，那么在获得奖励之后，先前所有的决策都会得到更新。乍一看这样的模型似乎更符合我们的需要，但是事实真是如此吗？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/SabTOKb.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>有些时候我们的学习并不是完全朝着最终的目标笔直前行的，图中难免会走一些<strong>弯路</strong>，而这些不必要的行为如果也能够得到奖励，那么就不是我们所期望的结果了。</p>
</li>
<li><p>这个时候就需要使用Sarsa(λ)来帮助模型克服这样的问题了。Sarsa(λ)中的λ参数可以看做是一个反馈的衰减系数，和Sarsa公式中的γ差不多，能够根据更新的回合动态调整奖励的分配。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/LmeLXwR.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>当λ = 0时模型为单步更新，也就是所有的奖励都反馈在了最后一次的行为上。</li>
<li>当λ = 1时模型为回合更新，也就是奖励反馈在了途中的所有行为上，并且具有相同的权重分配。</li>
<li>而当λ介于0和1之间时，也就是我们的Sarsa(λ)的实现了。它能够以λ系数作为一个衰减，将<strong>靠近结果的行为定义成对结果越重要的部分</strong>，而越远离的行为则作用较小。按照这样的思路<strong>从奖励倒推回起点</strong>的更新方式显得更为的科学。</li>
</ul>
<h3 id="Deep-Q-Network（DQN）"><a href="#Deep-Q-Network（DQN）" class="headerlink" title="Deep Q Network（DQN）"></a>Deep Q Network（DQN）</h3><p>DQN的结构从名字来看就能够推测出个大概，它就是在原有的Neural Network的基础上加上了Q Learning的部分。之所以会有DQN的出现，是因为传统的Q Learning维护表格的方式存在一些瓶颈。即当我们决策的行为次数多到一定的程度，就很难使用Table来记录，就比如围棋（GO）。</p>
<ul>
<li>复杂的决策行为虽然无法使用Table来记录所有的可能性，却并不是不能解决的。在Deep Learning中的神经网络结构就能够很好地解决这个问题。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/gJPqdT9.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果能够通过状态来即时预测每一个对应行为的价值分数，那么我们就不需要维护所谓的Q Table了。而DQN正是利用了这样的方法，通过将当前状态和对应的行为输入神经网络，让网络结构分析后得到相应的行为（类似分类）。这样的话我们<strong>只需要维护一个网络结构</strong>就能够解决所有的决策问题，最后再用强化学习的方法来选择动作。</li>
</ul>
<p>那么我们又是如何来训练我们的神经网络结构从而拟合强化学习的模型呢？</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/44IfOak.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>通过网络预测的结果和Q Learning通过Reward得出的最终结果的误差值可以用来反向传递给Neural Network模型。</li>
</ul>
<p>当然即使是这样，我们也只是在大量数据中重现了Q Leanring的性能，那么DQN究竟有哪些<strong>过人之处</strong>呢？</p>
<h4 id="Experience-Replay"><a href="#Experience-Replay" class="headerlink" title="Experience Replay"></a>Experience Replay</h4><p>根据强化学习的更新模式分为On-Policy和Off-Policy两种方式。而Q Learing就属于Off-Policy的一种，除了敢于尝试最佳化意外，它还能够学习<strong>自己实践</strong>的经历，也可以学习<strong>别人记录下来的经历</strong>，甚至是<strong>过去</strong>的经验。而这也是DQN的运用之一：</p>
<ul>
<li>DQN有个记忆库用来记录之前的经历，也可以加入其它网络尝试的经历。在训练的过程中，我们可以随机抽取一些记忆库中的经历来<strong>重新学习（复习）</strong> ，通过这样抽样的离散型<strong>打乱了经历的相关性</strong>，也让网络的<strong>更新更有效率</strong>。</li>
</ul>
<h4 id="Fixed-Q-target"><a href="#Fixed-Q-target" class="headerlink" title="Fixed Q-target"></a>Fixed Q-target</h4><p>Fixed Q-target也是一种打乱经历相关性的方法。每次训练过程中在得到Reward计算Q现实的 <code>Q&#39;</code> 和 预测行为的 <code>Q</code> 估计都是使用同一个神经网络预测得到的，这样一来网络的训练数据间就拥有了一定程度的<strong>相关性</strong>。 </p>
<p><img src="https://i.imgur.com/l9sK7uL.png" alt=""></p>
<p>Fixed Q-target的做法是用一个结构相同，但是参数是<strong>几个训练流程前</strong>的数据的神经网络来进行Q现实的预测。这么做的好处是利用一个较慢的网络来进行现实的预测，从而打破数据间的依赖，让更新更有效率。同时放慢的现实估计能够根据几轮的观察来评估预测的结果，提高了可调性范围，也让Q估计的模型看得更远（更有远见）。</p>
<h3 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h3><p>如果按照对行为的选择方式，强化学习可以分为<strong>基于价值</strong>和<strong>基于概率</strong>两种方式。之前的Q Learning、Sarsa和DQN都是基于计算行为的价值来预测下一步的动作，但是如果动作是一个<strong>大范围的连续区域</strong>，那么通过价值的计算来选择动作就变得十分复杂而且难以实现（需要维护大量的价值和行为的匹配关系）。因此Policy Gradient的方式解决了这个问题，它不再是通过计算价值来选择行为，而是通过预测行为的<strong>概率</strong>来直接输出对应的动作，而这点与神经网络的行为十分类似。</p>
<p>我们都知道神经网络的训练是通过反向传递误差来修正隐藏层的权重值得。那么如果没有了价值的计算，我们的误差又是什么呢？</p>
<ul>
<li>答案是<strong>没有误差</strong>。在训练Policy Gradient的神经网络时，我们是直接通过概率选择行为的，因此我们没有一个明确的值表示行为的对于错。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/KaamI8n.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>如果以一个例子来看：输出的结果是所有行为的one-hot vector——<strong>[0.1, 0.2, 0.1, 0.4, 0.2]</strong>，那么很显然下一次选择的行为很可能就会是第4个动作（不是绝对的）。这样一来通过动作获得的奖励（Reward），我们就能够判断行为发生的可靠性，也就是好坏。有了这个标准，我们就会在下一次预测的时候 <strong>改变这个行为出现的概率</strong> 。如果是好的行为，那么下一次输出就可能变成 <strong>[0.1, 0.1, 0.1, 0.5, 0.2]</strong> ；反之增加的幅度就会被衰减。</li>
</ul>
<h3 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h3><p>Actor-Critic的强化学习方式可以根据名称分为<strong>两个部分</strong>，分别时Actor和Critic。两部分分别结合了Policy Gradient和Value Based RL的优势之处。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/FBRPa59.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>Acotr部分是采用了Policy Gradient对于动作的选择优势，因为是一个基于概率的模型，因此能够输出一个连续范围内的行为。</p>
</li>
<li><p>Critic部分是采用了Q Learning以及其他传统的Value-Based RL的更新方式，通过单步更新的方式让模型的学习更有效率。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/tqm2LcU.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>Actor-Critic的方式和GAN神经网络十分相似，它是通过Actor部分的Policy Gradient神经网络来生成动作（相当与Generator），而利用Critic来判断行为的好坏，进而做出反馈（相当于Discriminator）。</p>
</li>
<li><p>Critic通过自己的神经网络学习环境、行为和Reward之间的关系（通过价值），然后对Actor每一步产生的行为做出<strong>即时的判断</strong>，进而通过模型学习到的行为潜在价值来单步更新Actor网络。</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/8JSc3fn.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>当然事物总有它的利与弊，Actor-Critic虽然能够解决Policy Gradient的单步更新问题，却无法很好的改善行为的<strong>连续性判断</strong>。Actor-Critic的两个神经网络都是基于一个连续动作的每一步进行更新（单步），这样的话就<strong>无法掌控行为之间的潜在关系</strong>，模型看待问题就显得<strong>相对片面</strong>，甚至学不到东西。</li>
</ul>
<p>为此，Google Deepmind团队通过将Actor-Critic和DQN的精髓结合起来，开发了全新的 <strong>Deep Deterministic Policy Gradient（DDPG）</strong> 成功解决了这个问题。</p>
<h3 id="Deep-Deterministic-Policy-Gradient-DDPG"><a href="#Deep-Deterministic-Policy-Gradient-DDPG" class="headerlink" title="Deep Deterministic Policy Gradient(DDPG)"></a>Deep Deterministic Policy Gradient(DDPG)</h3><p>从Actor-Critic延伸而来的DDPG强化学习算法，能够让强化学习在连续的行为上得到更好的学习效果。</p>
<p>我们可以将Deep Deterministic Policy Gradient结构分成三个部分：Deep + Deterministic + Policy Gradient。</p>
<ul>
<li><p><strong>Deep</strong>：DDPG利用了DQN中<strong>Experience Replay</strong>和<strong>Fixed Q-target</strong>的概念，通过随机筛选的方式新型重复学习以及利用两个神经网络分别估计Q现实和Q估计。将传统的Value Based RL提升到了DQN的效率范围。</p>
</li>
<li><p><strong>Deterministic</strong>：传统的Policy Gradient结构输出的结果为一个连续的动作区间（例如 <strong>[0.1, 0.1, 0.6…]</strong>），然后随机选择一个作为动作的输出。而Deterministic则是鄙弃了这种繁琐的输出方式，转而只输出决策完的单一动作，这样对于模型的更新更有效率。</p>
</li>
<li><p><strong>DDPG</strong>：在结合了前两者的功能之后，Policy Gradient在连续行为的处理上就能更加得心应手了：</p>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ipgbAqh.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>图中的Actor负责通过一个动作估计网络来预测当前的行为，并通过Deterministic输出一个特定的行为。同理根据DQN的思想另一个预测动作现实的网络也会根据较早期的输出一个真实的行为。</p>
</li>
<li><p>另一方面，对于Critic而言也是使用两个神经网络作为现实和估计的预测结构。但是不同的是，此时的输入除了从环境中得到的观测值意外，还包括了从Actor得到的<strong>上一个时间点输出的行为</strong>。咦？这种思想好像很眼熟？没错，这就和我们熟悉的RNN（Recurrent Neural Network）思想类似。都是通过<strong>将上一个状态值保留给下一个时刻进行学习的方法</strong>。有了这个结构的辅助，在训练连续行为的时候就能够很好地把握行为的<strong>相关性</strong>了。</p>
</li>
</ul>
<h3 id="Asynchronous-Advantage-Actor-Critic-A3C"><a href="#Asynchronous-Advantage-Actor-Critic-A3C" class="headerlink" title="Asynchronous Advantage Actor-Critic(A3C)"></a>Asynchronous Advantage Actor-Critic(A3C)</h3><p>A3C是一种用来提升强化学习效率的一种算法，它的精髓是能够让强化学习的模型通过分裂从而在同一个时刻学习不同的经验，然后总结之后得到完整的学习结果，这也是其中Asynchronous的含义。</p>
<p>假设现在为了获得Reward我们有16中不同的行为方式能够选择，那么不妨想想我们能够将这16中行为分成4<em>4的状态<em>*分散</em></em>放置在一个同样的环境中。让它们自我学习，最后将结果也就是学习的经验汇总到一个统一的网络中进行更新，这样就能大大地提升学习效率了。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/h29rcR1.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>如果计算机拥有多核心处理特性，那么A3C绝对是提升训练效率的一个方式。类似于多线程的概念，能够在同一时刻平行地处理多种可能性，而A3C的强化学习模组使用的是Actor-Critic，能够在异步有效更新Actor的行为状态，然后<strong>汇总</strong>到统一的模型中，模型会总结完所有异步状态的结果，整合之后再<strong>将这个秘籍（加总的结果）传递给每一个子模型（一个类似Map-Reduce的概念）</strong>。</p>
<h2 id="如何根据问题选择强化学习方法"><a href="#如何根据问题选择强化学习方法" class="headerlink" title="如何根据问题选择强化学习方法"></a>如何根据问题选择强化学习方法</h2><p>我们可以通过分类的方式来区分不同的强化学习。</p>
<h3 id="对环境的反馈"><a href="#对环境的反馈" class="headerlink" title="对环境的反馈"></a>对环境的反馈</h3><p>通过<strong>对环境的反馈</strong>可以分为两大类：</p>
<ul>
<li><strong>理解环境（Model-Based RL）</strong></li>
<li><strong>不理解环境（Model-Free RL）</strong></li>
</ul>
<p>如果我们的模型从一开始就没有打算去理解环境的本质，而只是一味地依靠尝试从环境中获得反馈来得以生存。那么就属于不理解环境的类型；相反，如果模型从一开始就试图理解环境的本质，那么就能自行对环境进行建模。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/YFFvN8t.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>试想一下，如果只是单纯地依靠环境给予的反馈来决定下一步的行为，那么所有的行为所造成的后果就会直接作用在模型本身。如果所采取的行为<strong>一直没有办法适应环境</strong>，那么模型就会一步步走向崩溃。</p>
</li>
<li><p>而如果是能够理解环境的强化学习模型（Model-Based），它能够实现根据了解到的环境数据对整个环境系统新型建模（虚拟环境）。然后在虚拟的环境中进行训练，最后模型不但能够在虚拟环境中适应，还能够迁移到真实的环境中去。</p>
</li>
</ul>
<p>除了能够建立虚拟环境来模拟学习过程以外，Model-Based RL还有一个优点是Model-Free RL所羡慕的，那就是<strong>想象力</strong>。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/QrUQivk.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li><p>Model-Free RL模型只能够一步一步按照环境给予的参数来思考下一步的动作，无法跳脱反馈信息的控制。因而只能<strong>按部就班</strong>循序渐进。而Model-Based RL由于已经理解了环境的本质，因此除了能够接受来自环境的反馈以外，还能够通过想象来同时<strong>预测多种行为的可能后果</strong>，最后选择一个模型觉得最佳的结果。这样就不必受到反馈信息的牵制了。</p>
</li>
<li><p>想象一下如果我们想要让一只猫到达一个特定的目标，那么我们可能需要在路线上摆好食物来引诱它。而Model-Free RL的方式就是相当于在每一步朝着正确目标的方向上摆上和步数相同的事物，这样就能够一步步<strong>逼近最终目标</strong>。但是如果是Model-Based RL的做法，它可能不会完全按照事物摆设的路线去逼近最终目标，而是不断地<strong>尝试其他新的可能性</strong>，最终找到一个最佳（距离最短）的路径作为模型的训练目标。这也是为什么<strong>Alpha Go</strong>能够下出人们所无法理解的路数了，因为在它看来目标是获胜，而为了达到这个目标可能有更加简单的方式。</p>
</li>
</ul>
<h3 id="对行为的选择方式"><a href="#对行为的选择方式" class="headerlink" title="对行为的选择方式"></a>对行为的选择方式</h3><p>通过<strong>对行为的选择方式</strong>也可以分为两大类：</p>
<ul>
<li><strong>基于概率（Policy-Based RL）</strong></li>
<li><strong>基于价值（Value-Based RL）</strong></li>
</ul>
<p>基于概率的方法输出的值是所有动作的概率，然后根据概率做出行动，因此比较<strong>灵活</strong>。所有的行动都有可能被选到，只是概率大的动作被选中的情况比较多罢了。但是基于价值的方式则不痛，它的输出是所有动作对结果做出的贡献度（也就是价值）。这样的话只有<strong>价值最高</strong>的那个动作才会被选中。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/O2CPKEo.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>我们现实环境中的决策往往不会是单一的一个动作，而是一连串连续的动作（Sequential Action），下一个动作的行为是基于上一个动作的结果而决定的。这样的情况下就不能使用基于价值的方式了，因为没有办法依靠单次的行为给出准确的价值分数。而基于概率的方式就变得尤为重要，因为我们可以使用<strong>条件概率分布</strong>来表示现在的动作被选中的几率大小。</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/vaCjrKe.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>那么基于概率和基于价值的方式又有哪些强化学习的算法呢？</p>
<ul>
<li><p>基于概率的方式有：</p>
<ul>
<li><code>Policy Gradients</code></li>
</ul>
</li>
<li><p>基于价值的方式有：</p>
<ul>
<li><code>Q Learning</code></li>
<li><code>Sarsa</code></li>
</ul>
</li>
<li><p>还有结合两者优势而得到的方法：</p>
<ul>
<li><code>Actor-Critic</code></li>
</ul>
</li>
</ul>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/zFyW1EM.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<ul>
<li>Actor-Critic顾名思义分为<strong>两个部分</strong>，Actor的部分通过概率计算做出下一步动作，而Critic根据做出的动作对结果的贡献评估价值分数。如此一来就把Policy-based和Value-based的功能整合在了一起，加速了学习过程。</li>
</ul>
<h3 id="对模型的更新方式"><a href="#对模型的更新方式" class="headerlink" title="对模型的更新方式"></a>对模型的更新方式</h3><p>通过<strong>对模型的更新方式</strong>也可以分为两大类：</p>
<ul>
<li><strong>回合更新（Monte-Carlo update）</strong></li>
<li><strong>单步更新（Temporal-Difference update）</strong></li>
</ul>
<p>回合更新指的是当学习开始到达到目的的一<strong>整个过程</strong>结束后才开始更新我们模型的行为准则；而单步更新则是学习的过程中根据不同的决策<strong>动态即时地</strong>更新模型的参数。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ynjt7Gj.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>回合更新的强化学习方法包括：</p>
<ul>
<li><code>最原始的Policy Gradients</code></li>
<li><code>Monte-Carlo Learning</code></li>
</ul>
<p>单步更新的方法则有：</p>
<ul>
<li><code>Q Learning</code></li>
<li><code>Sarsa</code></li>
<li><code>升级版的Policy Gradients</code></li>
</ul>
<p>比起回合更新而言，单步更新更有效率，因此普遍的强化学习都是使用单步更新的方式。</p>
<h3 id="学习的模式"><a href="#学习的模式" class="headerlink" title="学习的模式"></a>学习的模式</h3><p>通过<strong>模型学习的不同模式</strong>也可以分为两大类：</p>
<ul>
<li><strong>在线学习（On-Policy）</strong></li>
<li><strong>离线学习（Off-Policy）</strong></li>
</ul>
<p>在线学习指的是必须由待训练的模型<strong>自行进入环境学习</strong>，所有的决策都是由模型自己决定的。而离线学习则是可以选择模型自己进入环境学习，亦或者是通过<strong>总结别人的经验来学习</strong>。同时离线学习也<strong>不需要强制使学习和更新同步</strong>，换句话说就是可以先在环境中尝试各种行为，记录下环境的反馈，到了<strong>适当的时机（不需要环境）</strong>在通过这些数据更新自己的模型。</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.imgur.com/ideLIpf.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>比较典型的在线学习方式有：</p>
<ul>
<li><code>Sarsa</code></li>
<li><code>Sarsa(λ)</code></li>
</ul>
<p>而典型的离线学习方法有:</p>
<ul>
<li><code>Q Learning</code></li>
<li><code>Deep Q Network</code></li>
</ul>
<p>LICENCE： 图片摘录自网络引擎，未经授权请勿用于盈利性活动<br>更多详细内容 ： <a href="https://morvanzhou.github.io/" target="_blank" rel="external">Link</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人对于机器学习这项技术具有强烈的兴趣，但是网络上的文献鱼龙混杂，很难找到真正适合入门级别的新手观看。前一阵子无意间在网络上看到了&lt;a href=&quot;https://morvanzhou.github.io/tutorials/machine-learning/&quot; targe
    
    </summary>
    
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Reinforcement Learning" scheme="http://yoursite.com/tags/Reinforcement-Learning/"/>
    
  </entry>
  
</feed>
